
@incollection{ullman_chapter_1996,
	title = {Chapter 9: Visual cognition and visual routines},
	isbn = {978-0-262-28535-3},
	url = {https://ieeexplore.ieee.org/document/6302831},
	abstract = {This chapter contains sections titled: Perceiving “Inside” and “Outside”, Spatial Analysis by Visual Routines, Conclusions and Open Problems, The Elemental Operations, The Assembly and Storage of Routines, Routines and Recognition},
	pages = {263--315},
	booktitle = {High-level vision: Object recognition and visual cognition},
	publisher = {{MIT} Press},
	author = {Ullman, Shimon},
	urldate = {2023-06-23},
	date = {1996},
	doi = {10.7551/mitpress/3496.003.0011},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\inkpe\\Zotero\\storage\\N3ZUJ5CF\\6302831.html:text/html;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\RBCUT3YQ\\Visual-Cognition-and-Visual-Routines.html:text/html;Ullman '96 VisCog and Visual Routines Ch.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\388R7AEY\\Ullman '96 VisCog and Visual Routines Ch.pdf:application/pdf;ullman9.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\8GZ2RHXE\\ullman9.pdf:application/pdf},
}

@article{de_leeuw_jspsych_2023,
	title = {{jsPsych}: Enabling an open-source collaborative ecosystem of behavioral experiments},
	volume = {8},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.05351},
	doi = {10.21105/joss.05351},
	shorttitle = {{jsPsych}},
	abstract = {It is common practice to research human behavior using experiments that participants can complete online. Researchers use a variety of methodological approaches to conduct these studies. Some of this research can be done with survey instruments, for which there are many software options. However, much of the research in psychology and human behavior requires tasks that rely on precise measurement of stimulus presentation and response timing, specific kinds of randomization, procedures that adjust based on the responses that are given, and interactive content. {jsPsych} is a {JavaScript} library that allows researchers to build the types of experiments that historically could only be run in a lab setting, and run them on any device that has a web browser.},
	pages = {5351},
	number = {85},
	journaltitle = {Journal of Open Source Software},
	shortjournal = {Journal of Open Source Software},
	author = {De Leeuw, Joshua R. and Gilbert, Rebecca A. and Luchterhandt, Björn},
	urldate = {2023-06-23},
	date = {2023-05-11},
	langid = {english},
	keywords = {{justForCitation}},
	file = {De Leeuw et al. - 2023 - jsPsych Enabling an Open-Source CollaborativeEcos.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\QID89SLJ\\De Leeuw et al. - 2023 - jsPsych Enabling an Open-Source CollaborativeEcos.pdf:application/pdf},
}

@article{macklin_unified_2014,
	title = {Unified particle physics for real-time applications},
	volume = {33},
	issn = {0730-0301, 1557-7368},
	url = {https://dl.acm.org/doi/10.1145/2601097.2601152},
	doi = {10.1145/2601097.2601152},
	abstract = {We present a unified dynamics framework for real-time visual effects. Using particles connected by constraints as our fundamental building block allows us to treat contact and collisions in a unified manner, and we show how this representation is flexible enough to model gases, liquids, deformable solids, rigid bodies and cloth with two-way interactions. We address some common problems with traditional particle-based methods and describe a parallel constraint solver based on position-based dynamics that is efficient enough for real-time applications.},
	pages = {1--12},
	number = {4},
	journaltitle = {{ACM} Transactions on Graphics},
	shortjournal = {{ACM} Trans. Graph.},
	author = {Macklin, Miles and Müller, Matthias and Chentanez, Nuttapong and Kim, Tae-Yong},
	urldate = {2023-06-22},
	date = {2014-07-27},
	langid = {english},
	keywords = {cloth simulation, fluid simulation, position-based dynamics, simulation, two-way fluid coupling, unified solver},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\ZZYLJU5S\\Macklin et al. - 2014 - Unified particle physics for real-time application.pdf:application/pdf},
}

@article{marino_role_2005,
	title = {The role of closure in defining the “objects” of object-based attention},
	volume = {67},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03193547},
	doi = {10.3758/BF03193547},
	abstract = {Many recent studies have concluded that the underlying units of visual attention are often discrete objects whose boundaries constrain the allocation of attention. However, relatively few studies have explored the particular stimulus cues that determine what counts as an “object” of attention. We explore this issue in the context of the two-rectangles stimuli previously used by many investigators. We first show, using both spatial-cuing and divided-attention paradigms, that same-object advantages occur even when the ends of the two rectangles are not drawn. This is consistent with previous reports that have emphasized the importance of individual contours in guiding attention, and our study shows that such effects can occur in displays that also contain grouping cues. In our divided-attention experiment, however, this contour-driven same-object advantage was significantly weaker than that obtained with the standard stimulus, with the added cue of closure—demonstrating that contour-based processes are not the whole story. These results confirm and extend the observation that same-object advantages can be observed even without full-fledged objects. At the same time, however, these studies show that boundary closure—one of the most important cues to objecthood per se—can directly influence attention. We conclude that object-based attention is not an all-or-nothing phenomenon; object-based effects can be independently strengthened or weakened by multiple cues to objecthood.},
	pages = {1140--1149},
	number = {7},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Marino, Alexandria C. and Scholl, Brian J.},
	urldate = {2023-06-22},
	date = {2005-10-01},
	langid = {english},
	keywords = {Catch Trial, Chonomic Bulletin, Divided Attention, Paradi, Visual Attention},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\WGSWNANH\\Marino and Scholl - 2005 - The role of closure in defining the “objects” of o.pdf:application/pdf},
}

@article{sprote_visual_2016,
	title = {Visual perception of shape altered by inferred causal history},
	volume = {6},
	rights = {2016 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep36245},
	doi = {10.1038/srep36245},
	abstract = {One of the main functions of vision is to represent object shape. Most theories of shape perception focus exclusively on geometrical computations (e.g., curvatures, symmetries, axis structure). Here, however, we find that shape representations are also profoundly influenced by an object’s causal origins: the processes in its past that formed it. Observers placed dots on objects to report their perceived symmetry axes. When objects appeared ‘complete’—created entirely by a single generative process—responses closely approximated the object’s geometrical axes. However, when objects appeared ‘bitten’—as if parts had been removed by a distinct causal process—the responses deviated significantly from the geometrical axes, as if the bitten regions were suppressed from the computation of symmetry. This suppression of bitten regions was also found when observers were not asked about symmetry axes but about the perceived front and back of objects. The findings suggest that visual shape representations are more sophisticated than previously appreciated. Objects are not only parsed according to what features they have, but also to how or why they have those features.},
	pages = {1--11},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Spröte, Patrick and Schmidt, Filipp and Fleming, Roland W.},
	urldate = {2020-05-07},
	date = {2016-11-08},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\FIAYSXAY\\Spröte et al. - 2016 - Visual perception of shape altered by inferred cau.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\X8I7Z7JP\\srep36245.html:text/html},
}

@article{guan_seeing_2020,
	title = {Seeing what’s possible: Disconnected visual parts are confused for their potential wholes},
	volume = {149},
	issn = {1939-2222, 0096-3445},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xge0000658},
	doi = {10.1037/xge0000658},
	shorttitle = {Seeing what’s possible},
	abstract = {Perception research traditionally investigates how actual states of the world are seen— how we perceive the shapes, colors, and locations that objects actually have. By contrast, everyday life provokes us to consider possible states of the world that have not yet (and may not ever) actually obtain. When assembling furniture or completing a jigsaw puzzle, for example, we may appreciate not only the particular shapes of individual objects but also their potential to combine into new objects with distinct shapes of their own. What is the nature of this experience? Here, we explore how visual processing extracts not only what objects are but also what they could become. In 7 experiments inspired by the puzzle game Tetris, subjects responded to a particular target within a stream of distracting “tetrominoes”; surprisingly, subjects false-alarmed more often to pairs of tetrominoes that could create their target than to pairs of tetrominoes that couldn’t— essentially confusing possible objects for real ones. This pattern held for several types of objects and transformations, could not be explained by various forms of response bias, and persisted even when shape information was completely incidental to the task. We suggest that possible states of the world are not only contemplated in deliberate reflection but also automatically represented by more basic mechanisms of perception and attention.},
	pages = {590--598},
	number = {3},
	journaltitle = {Journal of Experimental Psychology: General},
	shortjournal = {Journal of Experimental Psychology: General},
	author = {Guan, Chenxiao and Firestone, Chaz},
	urldate = {2020-05-02},
	date = {2020-03},
	langid = {english},
	file = {Guan and Firestone - 2020 - Seeing what’s possible Disconnected visual parts .pdf:C\:\\Users\\inkpe\\Zotero\\storage\\JIBVWKJ2\\Guan and Firestone - 2020 - Seeing what’s possible Disconnected visual parts .pdf:application/pdf},
}

@article{chen_perception_2016,
	title = {The Perception of History: Seeing Causal History in Static Shapes Induces Illusory Motion Perception},
	volume = {27},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797616628525},
	doi = {10.1177/0956797616628525},
	shorttitle = {The Perception of History},
	abstract = {The perception of shape, it has been argued, also often entails the perception of time. A cookie missing a bite, for example, is seen as a whole cookie that was subsequently bitten. It has never been clear, however, whether such observations truly reflect visual processing. To explore this possibility, we tested whether the perception of history in static shapes could actually induce illusory motion perception. Observers watched a square change to a truncated form, with a “piece” of it missing, and they reported whether this change was sudden or gradual. When the contours of the missing piece suggested a type of historical “intrusion” (as when one pokes a finger into a lump of clay), observers actually saw that intrusion occur: The change appeared to be gradual even when it was actually sudden, in a type of transformational apparent motion. This provides striking phenomenological evidence that vision involves reconstructing causal history from static shapes.},
	pages = {923--930},
	number = {6},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Chen, Yi-Chia and Scholl, Brian J.},
	urldate = {2020-05-02},
	date = {2016-06-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\NKD7P39R\\Chen and Scholl - 2016 - The Perception of History Seeing Causal History i.pdf:application/pdf},
}

@article{scholl_objects_2001,
	title = {Objects and attention: the state of the art},
	volume = {80},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027700001529},
	doi = {10.1016/S0010-0277(00)00152-9},
	series = {Objects and Attention},
	shorttitle = {Objects and attention},
	abstract = {What are the units of attention? In addition to standard models holding that attention can select spatial regions and visual features, recent work suggests that in some cases attention can directly select discrete objects. This paper reviews the state of the art with regard to such ‘object-based’ attention, and explores how objects of attention relate to locations, reference frames, perceptual groups, surfaces, parts, and features. Also discussed are the dynamic aspects of objecthood, including the question of how attended objects are individuated in time, and the possibility of attending to simple dynamic motions and events. The final sections of this review generalize these issues beyond vision science, to other modalities and fields such as auditory objects of attention and the infant's ‘object concept’.},
	pages = {1--46},
	number = {1},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Scholl, Brian J},
	urldate = {2020-05-02},
	date = {2001-06-01},
	langid = {english},
	keywords = {Attention, Objects, State of the art},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\3UCH24PA\\Scholl - 2001 - Objects and attention the state of the art.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\ZK8CQWUM\\S0010027700001529.html:text/html},
}

@article{mccloskey_etal_1983,
	title = {Intuitive physics: The straight-down belief and its origin},
	volume = {9},
	issn = {1939-1285, 0278-7393},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0278-7393.9.4.636},
	doi = {10.1037/0278-7393.9.4.636},
	shorttitle = {Intuitive physics},
	pages = {636--649},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	shortjournal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {{McCloskey}, Michael and Washburn, Allyson and Felch, Linda},
	urldate = {2020-01-23},
	date = {1983},
	langid = {english},
	file = {McCloskey et al. - 1983 - Intuitive physics The straight-down belief and it.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\GAVA9NXT\\McCloskey et al. - 1983 - Intuitive physics The straight-down belief and it.pdf:application/pdf;McCloskeyetal1983.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\8NC2SCJ3\\McCloskeyetal1983.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\KKKVAJ5W\\16967950_Intuitive_physics_The_straight-down_belief_and_its_origin.html:text/html},
}

@article{eagleman_human_2008,
	title = {Human time perception and its illusions},
	volume = {18},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438808000548},
	doi = {10.1016/j.conb.2008.06.002},
	series = {Cognitive neuroscience},
	abstract = {Why does a clock sometimes appear stopped? Is it possible to perceive the world in slow motion during a car accident? Can action and effect be reversed? Time perception is surprisingly prone to measurable distortions and illusions. The past few years have introduced remarkable progress in identifying and quantifying temporal illusions of duration, temporal order, and simultaneity. For example, perceived durations can be distorted by saccades, by an oddball in a sequence, or by stimulus complexity or magnitude. Temporal order judgments of actions and sensations can be reversed by the exposure to delayed motor consequences, and simultaneity judgments can be manipulated by repeated exposure to nonsimultaneous stimuli. The confederacy of recently discovered illusions points to the underlying neural mechanisms of time perception.},
	pages = {131--136},
	number = {2},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Eagleman, David M},
	urldate = {2020-10-03},
	date = {2008-04-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\LLYV9SJN\\Eagleman - 2008 - Human time perception and its illusions.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\KFVLVYI2\\S0959438808000548.html:text/html},
}

@article{mccloskey_alone_1983,
	title = {Intuitive physics},
	volume = {248},
	issn = {0036-8733},
	url = {https://www.jstor.org/stable/24968881},
	pages = {122--131},
	number = {4},
	journaltitle = {Scientific American},
	author = {{McCloskey}, Michael},
	urldate = {2020-09-29},
	date = {1983},
	note = {Publisher: Scientific American, a division of Nature America, Inc.},
	file = {McCloskey - 1983 - Intuitive Physics.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\UT2A2FB7\\McCloskey - 1983 - Intuitive Physics.pdf:application/pdf},
}

@article{phillips_veiled_2020,
	title = {The Veiled Virgin illustrates visual segmentation of shape by cause},
	rights = {Copyright © 2020 the Author(s). Published by {PNAS}.. https://creativecommons.org/licenses/by/4.0/This open access article is distributed under Creative Commons Attribution License 4.0 ({CC} {BY}).},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/early/2020/05/13/1917565117},
	doi = {10.1073/pnas.1917565117},
	abstract = {{\textless}p{\textgreater}Three-dimensional (3D) shape perception is one of the most important functions of vision. It is crucial for many tasks, from object recognition to tool use, and yet how the brain represents shape remains poorly understood. Most theories focus on purely geometrical computations (e.g., estimating depths, curvatures, symmetries). Here, however, we find that shape perception also involves sophisticated inferences that parse shapes into features with distinct causal origins. Inspired by marble sculptures such as Strazza’s \textit{The Veiled Virgin} (1850), which vividly depict figures swathed in cloth, we created composite shapes by wrapping unfamiliar forms in textile, so that the observable surface relief was the result of complex interactions between the underlying object and overlying fabric. Making sense of such structures requires segmenting the shape based on their causes, to distinguish whether lumps and ridges are due to the shrouded object or to the ripples and folds of the overlying cloth. Three-dimensional scans of the objects with and without the textile provided ground-truth measures of the true physical surface reliefs, against which observers’ judgments could be compared. In a virtual painting task, participants indicated which surface ridges appeared to be caused by the hidden object and which were due to the drapery. In another experiment, participants indicated the perceived depth profile of both surface layers. Their responses reveal that they can robustly distinguish features belonging to the textile from those due to the underlying object. Together, these findings reveal the operation of visual shape-segmentation processes that parse shapes based on their causal origin.{\textless}/p{\textgreater}},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Phillips, Flip and Fleming, Roland W.},
	urldate = {2020-05-16},
	date = {2020-05-15},
	langid = {english},
	pmid = {32414926},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\Z9T7W397\\Phillips and Fleming - 2020 - The Veiled Virgin illustrates visual segmentation .pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\I6AZ5FHQ\\926295.html:text/html},
}

@article{brenner_searching_2020,
	title = {Searching for Strangely Shaped Cookies – Is Taking a Bite Out of a Cookie Similar to Occluding Part of It?},
	issn = {0301-0066},
	url = {https://doi.org/10.1177/0301006620983729},
	doi = {10.1177/0301006620983729},
	abstract = {Does recognizing the transformations that gave rise to an object’s retinal image contribute to early object recognition? It might, because finding a partially occluded object among similar objects that are not occluded is more difficult than finding an object that has the same retinal image shape without evident occlusion. If this is because the occlusion is recognized as such, we might see something similar for other transformations. We confirmed that it is difficult to find a cookie with a section missing when this was the result of occlusion. It is not more difficult to find a cookie from which a piece has been bitten off than to find one that was baked in a similar shape. On the contrary, the bite marks help detect the bitten cookie. Thus, biting off a part of a cookie has very different effects on visual search than occluding part of it. These findings do not support the idea that observers rapidly and automatically compensate for the ways in which objects’ shapes are transformed to give rise to the objects’ retinal images. They are easy to explain in terms of detecting characteristic features in the retinal image that such transformations may hide or create.},
	pages = {0301006620983729},
	journaltitle = {Perception},
	shortjournal = {Perception},
	author = {Brenner, Eli and Hurtado, Sergio Sánchez and Arias, Elena Alvarez and Smeets, Jeroen B. J. and Fleming, Roland W.},
	urldate = {2021-01-07},
	date = {2020-12-30},
	langid = {english},
	note = {Publisher: {SAGE} Publications Ltd {STM}},
	keywords = {{HasNote}, object perception, serial processing, shape perception, transformations, visual search},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\SUNRK5EE\\Brenner et al. - 2020 - Searching for Strangely Shaped Cookies – Is Taking.pdf:application/pdf},
}

@article{rosenberg_sustaining_2013,
	title = {Sustaining visual attention in the face of distraction: a novel gradual-onset continuous performance task},
	volume = {75},
	issn = {1943-393X},
	doi = {10.3758/s13414-012-0413-x},
	shorttitle = {Sustaining visual attention in the face of distraction},
	abstract = {Sustained attention is a fundamental aspect of human cognition and has been widely studied in applied and clinical contexts. Despite a growing understanding of how attention varies throughout task performance, moment-to-moment fluctuations are often difficult to assess. In order to better characterize fluctuations in sustained visual attention, in the present study we employed a novel continuous performance task ({CPT}), the gradual-onset {CPT} ({gradCPT}). In the {gradCPT}, a central face stimulus gradually transitions between individuals at a constant rate (1,200 ms), and participants are instructed to respond to each male face but not to a rare target female face. In the distractor-present version, the background distractors consist of scene images, and in the distractor-absent condition, of phase-scrambled scene images. The results confirmed that the {gradCPT} taxes sustained attention, as vigilance decrements were observed over the task's 12-min duration: Participants made more commission errors and showed increasingly variable response latencies ({RTs}) over time. Participants' attentional states also fluctuated from moment to moment, with periods of higher {RT} variability being associated with increased likelihood of errors and greater speed-accuracy trade-offs. In addition, task performance was related to self-reported mindfulness and the propensity for attention lapses in everyday life. The {gradCPT} is a useful tool for studying both low- and high-frequency fluctuations in sustained visual attention and is sensitive to individual differences in attentional ability.},
	pages = {426--439},
	number = {3},
	journaltitle = {Attention, Perception \& Psychophysics},
	shortjournal = {Atten Percept Psychophys},
	author = {Rosenberg, Monica and Noonan, Sarah and {DeGutis}, Joseph and Esterman, Michael},
	date = {2013-04},
	pmid = {23299180},
	keywords = {Attention, Visual Perception, Humans, Reaction Time, Female, Male, Young Adult, Adolescent, Analysis of Variance, Arousal, Individuality},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\N4GMCXCH\\Rosenberg et al. - 2013 - Sustaining visual attention in the face of distrac.pdf:application/pdf},
}

@article{kaiser_judgments_1985,
	title = {Judgments of natural and anomalous trajectories in the presence and absence of motion},
	volume = {11},
	issn = {1939-1285(Electronic),0278-7393(Print)},
	doi = {10.1037/0278-7393.11.1-4.795},
	abstract = {Investigated whether people can select as correct natural trajectories over anomalous ones when presented with the actual on-going event (motion conditions) or static representations of the event (no-motion condition). In 3 experiments, 90 female and 70 male undergraduates and 32 female and 28 male 5th graders responded to a curved tube problem developed by M. {McCluskey} et al (see record 1981-29478-001). Results indicate that adults benefited from the motion information in these stimuli, choosing the correct path more often in the motion condition. Adult males performed better than females in both conditions; this gender effect could not be attributed to formal instruction in physics. Only in the no-motion condition did any males prefer a path that reflected an impetus model of motion. Some females chose a curvilinear path in the motion condition, and in the no-motion condition the curvilinear path was their most often selected alternative. Fifth-grade Ss demonstrated no effect for gender, and their path preferences resembled those of adult males. Children's responses failed to demonstrate a preference for those curvilinear paths that reflect an impetus-based approach to the problem. Adults' performance in the no-motion condition was not enhanced by instructions to employ mental imagery of the event. (13 ref) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {795--803},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Kaiser, Mary K. and Proffitt, Dennis R. and Anderson, Kenneth},
	date = {1985},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {{HasNote}, Motion Perception, Human Sex Differences, Age Differences, Perceptual Development},
	file = {Kaiser et al. - 1985 - Judgments of natural and anomalous trajectories in.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\IBMBS9P8\\Kaiser et al. - 1985 - Judgments of natural and anomalous trajectories in.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\JP4YNI6V\\1986-11428-001.html:text/html},
}

@article{selst_visual_1995,
	title = {Visual operations involved in within-figure processing},
	volume = {2},
	issn = {1350-6285, 1464-0716},
	url = {http://www.tandfonline.com/doi/abs/10.1080/13506289508401720},
	doi = {10.1080/13506289508401720},
	pages = {1--34},
	number = {1},
	journaltitle = {Visual Cognition},
	shortjournal = {Visual Cognition},
	author = {Selst, Mark Van and Jolicoeur, Pierre},
	urldate = {2021-10-25},
	date = {1995-03},
	langid = {english},
	file = {Selst and Jolicoeur - 1995 - Visual operations involved in within-figure proces.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\ZV7HHH76\\Selst and Jolicoeur - 1995 - Visual operations involved in within-figure proces.pdf:application/pdf},
}

@article{mccloskey_curvilinear_1980,
	title = {Curvilinear motion in the absence of external forces: Naïve beliefs about the motion of objects},
	volume = {210},
	rights = {1980 by the American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/210/4474/1139},
	doi = {10.1126/science.210.4474.1139},
	shorttitle = {Curvilinear Motion in the Absence of External Forces},
	abstract = {University students were asked to draw the path a moving object would follow in several different situations. Over half of the students, including many who had taken physics courses, evidenced striking misconceptions about the motion of objects. In particular, many students believed that even in the absence of external forces, objects would move in curved paths.},
	pages = {1139--1141},
	number = {4474},
	journaltitle = {Science},
	author = {{McCloskey}, Michael and Caramazza, Alfonso and Green, Bert},
	urldate = {2021-07-31},
	date = {1980-12-05},
	langid = {english},
	pmid = {17831469},
	note = {Publisher: American Association for the Advancement of Science
Section: Reports},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\7BFUCFYH\\Mccloskey et al. - 1980 - Curvilinear Motion in the Absence of External Forc.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\974JPJYM\\1139.html:text/html},
}

@article{shepard_perceptual-cognitive_1994,
	title = {Perceptual-cognitive universals as reflections of the world},
	volume = {1},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03200759},
	doi = {10.3758/BF03200759},
	abstract = {The universality, invariance, and elegance of principles governing the universe may be reflected in principles of the minds that have evolved in that universe—provided that the mental principles are formulated with respect to the abstract spaces appropriate for the representation of biologically significant objects and their properties. (1)Positions andmotions of objects conserve theirshapes in the geometrically fullest and simplest way when represented as points and connecting geodesic paths in the six-dimensional manifold jointly determined by the Euclidean group of three-dimensional space and the symmetry group of each object. (2)Colors of objects attain constancy when represented as points in a three-dimensional vector space in which each variation in natural illumination is cancelled by application of its inverse from the three-dimensional linear group of terrestrial transformations of the invariant solar source. (3)Kinds of objects support optimal generalization and categorization when represented, in an evolutionarily shaped space of possible objects, as connected regions with associated weights determined by Bayesian revision of maximum-entropy priors.},
	pages = {2--28},
	number = {1},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Shepard, Roger N.},
	urldate = {2021-07-31},
	date = {1994-03-01},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\TXMYATTQ\\Shepard - 1994 - Perceptual-cognitive universals as reflections of .pdf:application/pdf},
}

@article{ullman_mind_2017,
	title = {Mind games: Game engines as an architecture for intuitive physics},
	volume = {21},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661317301134},
	doi = {10.1016/j.tics.2017.05.012},
	shorttitle = {Mind Games},
	pages = {649--665},
	number = {9},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Ullman, Tomer D. and Spelke, Elizabeth and Battaglia, Peter and Tenenbaum, Joshua B.},
	urldate = {2021-07-30},
	date = {2017-09},
	langid = {english},
	file = {Ullman et al. - 2017 - Mind Games Game Engines as an Architecture for In.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\V9U8BJJS\\Ullman et al. - 2017 - Mind Games Game Engines as an Architecture for In.pdf:application/pdf},
}

@article{gold_origins_1995,
	title = {Origins of ruminative thought: Trauma, incompleteness, nondisclosure, and suppression},
	volume = {25},
	issn = {1559-1816},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1559-1816.1995.tb02617.x},
	doi = {10.1111/j.1559-1816.1995.tb02617.x},
	shorttitle = {Origins of Ruminative Thought},
	abstract = {The purpose of this paper is to discuss theories of the origin of ruminative thought. We begin by providing a working definition of rumination, separating rumination from other forms of cognitive activity and distinguishing ruminations from ordinary memories. Then, we review what we believe are the major categories of theory that attempt to account for the existence and nature of rumination. These include theories of traumatization, incompleteness, nondisclosure, and thought suppression. Ruminations may originate for a number of reasons, but it seems they may continue because of our attempts to control them. Evidence from studies on thought suppression suggests that the suppression of unwanted thoughts may in fact fuel the very emotions and thoughts we are trying to avoid. Thought suppression may set up a state in which we not only increase the amount we think about an unwanted thought, but potentially also sharpen our emotional reaction to those thoughts.},
	pages = {1245--1261},
	number = {14},
	journaltitle = {Journal of Applied Social Psychology},
	author = {Gold, Daniel B. and Wegner, Daniel M.},
	urldate = {2023-05-30},
	date = {1995},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1559-1816.1995.tb02617.x},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\U9ZM4YBP\\Gold and Wegner - 1995 - Origins of Ruminative Thought Trauma, Incompleten.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\X9QS27HG\\j.1559-1816.1995.tb02617.html:text/html},
}

@article{chen_causal_2021,
	title = {The causal future: The influence of shape features caused by external transformation on visual attention},
	volume = {21},
	issn = {1534-7362},
	url = {https://jov.arvojournals.org/article.aspx?articleid=2778017},
	doi = {10.1167/jov.21.11.17},
	shorttitle = {The causal future},
	pages = {17},
	number = {11},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Chen, Yunyun and Wang, Yuying and Guo, Sen and Zhang, Xuemin and Yan, Bihua},
	urldate = {2022-09-19},
	date = {2021-10-25},
	langid = {english},
	file = {Chen et al. - 2021 - The causal future The influence of shape features.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\TVFXFC3V\\Chen et al. - 2021 - The causal future The influence of shape features.pdf:application/pdf},
}

@article{jacobs_learning_2000,
	title = {Learning to perceive the relative mass of colliding balls: The effects of ratio scaling and feedback},
	volume = {62},
	issn = {0031-5117, 1532-5962},
	url = {http://link.springer.com/10.3758/BF03212135},
	doi = {10.3758/BF03212135},
	shorttitle = {Learning to perceive the relative mass of colliding balls},
	pages = {1332--1340},
	number = {7},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Jacobs, David M. and Michaels, Claire F. and Runeson, Sverker},
	urldate = {2022-03-23},
	date = {2000-10},
	langid = {english},
	keywords = {Mass Judgements},
	file = {Jacobs et al. - 2000 - Learning to perceive the relative mass of collidin.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\9RFATZ5E\\Jacobs et al. - 2000 - Learning to perceive the relative mass of collidin.pdf:application/pdf},
}

@article{hamrick_inferring_2016,
	title = {Inferring mass in complex scenes by mental simulation},
	volume = {157},
	issn = {0010-0277},
	url = {http://www.sciencedirect.com/science/article/pii/S0010027716302025},
	doi = {10.1016/j.cognition.2016.08.012},
	abstract = {After observing a collision between two boxes, you can immediately tell which is empty and which is full of books based on how the boxes moved. People form rich perceptions about the physical properties of objects from their interactions, an ability that plays a crucial role in learning about the physical world through our experiences. Here, we present three experiments that demonstrate people’s capacity to reason about the relative masses of objects in naturalistic 3D scenes. We find that people make accurate inferences, and that they continue to fine-tune their beliefs over time. To explain our results, we propose a cognitive model that combines Bayesian inference with approximate knowledge of Newtonian physics by estimating probabilities from noisy physical simulations. We find that this model accurately predicts judgments from our experiments, suggesting that the same simulation mechanism underlies both peoples’ predictions and inferences about the physical world around them.},
	pages = {61--76},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Hamrick, Jessica B. and Battaglia, Peter W. and Griffiths, Thomas L. and Tenenbaum, Joshua B.},
	urldate = {2020-09-02},
	date = {2016-12-01},
	langid = {english},
	keywords = {Learning, {HasNote}, Inference, Mental simulation, Physical reasoning, Probabilistic simulation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\M2PDWKWB\\Hamrick et al. - 2016 - Inferring mass in complex scenes by mental simulat.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\42HV3GWH\\S0010027716302025.html:text/html},
}

@article{egly_shifting_1994,
	title = {Shifting visual attention between objects and locations: evidence from normal and parietal lesion subjects},
	volume = {123},
	issn = {0096-3445},
	doi = {10.1037//0096-3445.123.2.161},
	shorttitle = {Shifting visual attention between objects and locations},
	abstract = {Space- and object-based attention components were examined in neurologically normal and parietal-lesion subjects, who detected a luminance change at 1 of 4 ends of 2 outline rectangles. One rectangle end was precued (75\% valid); on invalid-cue trials, the target appeared at the other end of the cued rectangle or at 1 end of the uncued rectangle. For normals, the cost for invalid cues was greater for targets in the uncued rectangle, indicating an object-based component. Both right- and left-hemisphere patients showed costs that were greater for contralesional targets. For right-hemisphere patients, the object cost was equivalent for contralesional and ipsilesional targets, indicating a spatial deficit, whereas the object cost for left-hemisphere patients was larger for contralesional targets, indicating an object deficit.},
	pages = {161--177},
	number = {2},
	journaltitle = {Journal of Experimental Psychology. General},
	shortjournal = {J Exp Psychol Gen},
	author = {Egly, R. and Driver, J. and Rafal, R. D.},
	date = {1994-06},
	pmid = {8014611},
	keywords = {Attention, Humans, Reaction Time, Female, Male, Middle Aged, Neuropsychological Tests, Orientation, Psychomotor Performance, Cues, Pattern Recognition, Visual, Mental Recall, Aging, Brain Damage, Chronic, Dominance, Cerebral, Parietal Lobe},
	file = {Egly et al. - Shifting Visual Attention Between Objects and Loca.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\H67GY4R5\\Egly et al. - Shifting Visual Attention Between Objects and Loca.pdf:application/pdf},
}

@article{chen_solving_2015,
	title = {Solving the paradox between same-object advantage and different-object advantage},
	volume = {115},
	issn = {0042-6989},
	url = {https://www.sciencedirect.com/science/article/pii/S0042698915002758},
	doi = {10.1016/j.visres.2015.08.008},
	abstract = {The same-object advantage ({SOA}) effect is usually cited as evidence for object-based attention. However, the different-object advantage ({DOA}) effect, which appears to be the opposite of the {SOA} effect, has also been reported by some researchers. The present study was designed to resolve this apparent inconsistency. As the {SOA} effect has been well documented, here we focus on exploring when and why the {DOA} effect occurs. With a series of four experiments, we manipulated the identicality between two targets and found the {SOA} effect when the targets were different but the {DOA} effect when they were identical. These results demonstrate that the presence of {SOA} vs. {DOA} effects can be critically determined by the identicality between targets. Moreover, Experiment 4 provides direct evidence for our hypothesis that the {DOA} effect arises from the benefit of placing two identical targets in distinct objects (e.g., rectangles) that can help the differentiation between targets.},
	pages = {128--134},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Chen, Hui and Huang, Liqiang},
	urldate = {2023-06-22},
	date = {2015-10-01},
	langid = {english},
	keywords = {Object-based attention, Different-object advantage, Same-object advantage, Token individuation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\BZSLQYHX\\Chen and Huang - 2015 - Solving the paradox between same-object advantage .pdf:application/pdf;ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\73PS7VTD\\Chen and Huang - 2015 - Solving the paradox between same-object advantage .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\C9BCNAVW\\S0042698915002758.html:text/html;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\FLZTKCUZ\\S0042698915002758.html:text/html},
}

@article{battaglia_simulation_2013,
	title = {Simulation as an engine of physical scene understanding},
	volume = {110},
	rights = {©  . Freely available online through the {PNAS} open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/110/45/18327},
	doi = {10.1073/pnas.1306572110},
	abstract = {In a glance, we can perceive whether a stack of dishes will topple, a branch will support a child’s weight, a grocery bag is poorly packed and liable to tear or crush its contents, or a tool is firmly attached to a table or free to be lifted. Such rapid physical inferences are central to how people interact with the world and with each other, yet their computational underpinnings are poorly understood. We propose a model based on an “intuitive physics engine,” a cognitive mechanism similar to computer engines that simulate rich physics in video games and graphics, but that uses approximate, probabilistic simulations to make robust and fast inferences in complex natural scenes where crucial information is unobserved. This single model fits data from five distinct psychophysical tasks, captures several illusions and biases, and explains core aspects of human mental models and common-sense reasoning that are instrumental to how humans understand their everyday world.},
	pages = {18327--18332},
	number = {45},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Battaglia, Peter W. and Hamrick, Jessica B. and Tenenbaum, Joshua B.},
	urldate = {2021-07-30},
	date = {2013-11-05},
	langid = {english},
	pmid = {24145417},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {{HasNote}},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\RLCIARSJ\\Battaglia et al. - 2013 - Simulation as an engine of physical scene understa.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\P9CEUHJY\\18327.html:text/html},
}

@article{kubricht_intuitive_2017,
	title = {Intuitive physics: Current research and controversies},
	volume = {21},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661317301262},
	doi = {10.1016/j.tics.2017.06.002},
	shorttitle = {Intuitive Physics},
	abstract = {Early research in the field of intuitive physics provided extensive evidence that humans succumb to common misconceptions and biases when predicting, judging, and explaining activity in the physical world. Recent work has demonstrated that, across a diverse range of situations, some biases can be explained by the application of normative physical principles to noisy perceptual inputs. However, it remains unclear how knowledge of physical principles is learned, represented, and applied to novel situations. In this review we discuss theoretical advances from heuristic models to knowledge-based, probabilistic simulation models, as well as recent deep-learning models. We also consider how recent work may be reconciled with earlier findings that favored heuristic models.},
	pages = {749--759},
	number = {10},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Kubricht, James R. and Holyoak, Keith J. and Lu, Hongjing},
	urldate = {2020-09-19},
	date = {2017-10-01},
	langid = {english},
	keywords = {intuitive physics, Review-like, computation, mental simulation, misconceptions, probabilistic simulation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\F3AMKLNS\\Kubricht et al. - 2017 - Intuitive Physics Current Research and Controvers.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\5YJKI5KP\\S1364661317301262.html:text/html},
}

@article{firestone_seeing_2017,
	title = {Seeing physics in the blink of an eye},
	volume = {17},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/17.10.203},
	doi = {10.1167/17.10.203},
	abstract = {People readily understand visible objects and events in terms of invisible physical forces, such as gravity, friction, inertia, and momentum. For example, we can appreciate that certain objects will balance, slide, fall, bend or break. This ability has historically been associated with sophisticated higher-level reasoning, but here we explore the intriguing possibility that such physical properties (e.g. whether a tower of blocks will topple) are extracted during rapid, automatic, visual processing. We did so by exploring both the timecourse of such processing and its consequences for visual awareness. Subjects saw hundreds of block-towers for variable masked durations and rated each tower's stability; later, they rated the same towers again, without time pressure. We correlated these limited-time and unlimited-time impressions of stability to determine when such correlations peak — asking, in other words, how long it takes to form a "complete" physical intuition. Remarkably, stability impressions after even very short exposures (e.g. 100ms) correlated just as highly with unlimited-time judgments as did impressions formed after exposures an order-of-magnitude longer (e.g. 1000ms). Moreover, these immediate physical impressions were accurate, agreeing with physical simulations — and doing so equally well at 100ms as with unlimited time. Next, we exploited inattentional blindness to ask whether stability is processed not only quickly, but also spontaneously and in ways that promote visual awareness. While subjects attended to a central stimulus, an unexpected image flashed in the periphery. Subjects more frequently noticed this image if it was an unstable tower (vs. a stable tower), even though these two towers were just the same image presented upright or inverted. Thus, physical scene understanding is fast, automatic, and attention-grabbing: such impressions are fully extracted in (an exposure faster than) the blink of an eye, and a scene's stability is automatically prioritized in determining the contents of visual awareness. Meeting abstract presented at {VSS} 2017},
	pages = {203},
	number = {10},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Firestone, Chaz and Scholl, Brian},
	urldate = {2023-06-22},
	date = {2017-08-31},
	keywords = {{MehStudy}, {IncompleteStudy}-{OnlyAbstract}},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\LB74J844\\article.html:text/html},
}

@misc{simonyan_very_2015,
	title = {Very deep convolutional networks for large-scale image recognition},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution ﬁlters, which shows that a signiﬁcant improvement on the prior-art conﬁgurations can be achieved by pushing the depth to 16–19 weight layers. These ﬁndings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the ﬁrst and the second places in the localisation and classiﬁcation tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	number = {{arXiv}:1409.1556},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2023-06-22},
	date = {2015-04-10},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1409.1556 [cs]},
	keywords = {{justForCitation}, Computer Science - Computer Vision and Pattern Recognition},
	file = {Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\WU8XK8PJ\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf},
}

@article{palan_prolificacsubject_2018,
	title = {Prolific.ac—A subject pool for online experiments},
	volume = {17},
	issn = {2214-6350},
	url = {https://www.sciencedirect.com/science/article/pii/S2214635017300989},
	doi = {10.1016/j.jbef.2017.12.004},
	abstract = {The number of online experiments conducted with subjects recruited via online platforms has grown considerably in the recent past. While one commercial crowdworking platform – Amazon’s Mechanical Turk – basically has established and since dominated this field, new alternatives offer services explicitly targeted at researchers. In this article, we present www.prolific.ac and lay out its suitability for recruiting subjects for social and economic science experiments. After briefly discussing key advantages and challenges of online experiments relative to lab experiments, we trace the platform’s historical development, present its features, and contrast them with requirements for different types of social and economic experiments.},
	pages = {22--27},
	journaltitle = {Journal of Behavioral and Experimental Finance},
	shortjournal = {Journal of Behavioral and Experimental Finance},
	author = {Palan, Stefan and Schitter, Christian},
	urldate = {2021-07-30},
	date = {2018-03-01},
	langid = {english},
	keywords = {{justForCitation}, Online experiment, Prolific, Subject pool},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\ACYFLCYE\\Palan and Schitter - 2018 - Prolific.ac—A subject pool for online experiments.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\8AZKFT9E\\S2214635017300989.html:text/html},
}

@article{firestone_cognition_2016,
	title = {Cognition does not affect perception: Evaluating the evidence for “top-down” effects},
	volume = {39},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X15000965/type/journal_article},
	doi = {10.1017/S0140525X15000965},
	shorttitle = {Cognition does not affect perception},
	abstract = {What determines what we see? In contrast to the traditional “modular” understanding of perception, according to which visual processing is encapsulated from higher-level cognition, a tidal wave of recent research alleges that states such as beliefs, desires, emotions, motivations, intentions, and linguistic representations exert direct, top-down inﬂuences on what we see. There is a growing consensus that such effects are ubiquitous, and that the distinction between perception and cognition may itself be unsustainable. We argue otherwise: None of these hundreds of studies – either individually or collectively – provides compelling evidence for true top-down effects on perception, or “cognitive penetrability.” In particular, and despite their variety, we suggest that these studies all fall prey to only a handful of pitfalls. And whereas abstract theoretical challenges have failed to resolve this debate in the past, our presentation of these pitfalls is empirically anchored: In each case, we show not only how certain studies could be susceptible to the pitfall (in principle), but also how several alleged top-down effects actually are explained by the pitfall (in practice). Moreover, these pitfalls are perfectly general, with each applying to dozens of other top-down effects. We conclude by extracting the lessons provided by these pitfalls into a checklist that future work could use to convincingly demonstrate top-down effects on visual perception. The discovery of substantive top-down effects of cognition on perception would revolutionize our understanding of how the mind is organized; but without addressing these pitfalls, no such empirical report will license such exciting conclusions.},
	pages = {e229},
	journaltitle = {Behavioral and Brain Sciences},
	shortjournal = {Behav Brain Sci},
	author = {Firestone, Chaz and Scholl, Brian J.},
	urldate = {2023-06-22},
	date = {2016},
	langid = {english},
	keywords = {{justForCitation}},
	file = {Firestone and Scholl - 2016 - Cognition does not affect perception Evaluating t.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\IMBBKM3H\\Firestone and Scholl - 2016 - Cognition does not affect perception Evaluating t.pdf:application/pdf},
}

@article{de_leeuw_jspsych_2015,
	title = {{jsPsych}: A {JavaScript} library for creating behavioral experiments in a web browser},
	volume = {47},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/s13428-014-0458-y},
	doi = {10.3758/s13428-014-0458-y},
	shorttitle = {{jsPsych}},
	abstract = {Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces {jsPsych}, a {JavaScript} library for the development of Web-based experiments. {jsPsych} formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. {jsPsych} then executes these descriptions automatically, handling the flow from one task to another. The {jsPsych} library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org.},
	pages = {1--12},
	number = {1},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behav Res},
	author = {De Leeuw, Joshua R.},
	urldate = {2023-06-22},
	date = {2015-03-01},
	langid = {english},
	keywords = {{justForCitation}, Amazon Mechanical Turk, {JavaScript}, Online experiments},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\7JLXE94R\\de Leeuw - 2015 - jsPsych A JavaScript library for creating behavio.pdf:application/pdf},
}

@article{chen_when_2019,
	title = {When is object-based attention not based on objects?},
	volume = {45},
	issn = {1939-1277},
	doi = {10.1037/xhp0000657},
	abstract = {Some studies using methods introduced by Egly, Driver, and Rafal (1994) to measure object-based attention have shown surprising effects of object orientation. Rectangles oriented horizontally produce evidence for object-based attention, whereas vertical rectangles do not. We explore these differences using a two-letter comparison task. Across all the experiments, responses are faster when the targets are arranged horizontally rather than vertically. The horizontal advantage persists when the rectangles are removed, demonstrating its independence from object-based attention. Furthermore, responses are faster for vertically configured targets when they are within the same rectangle. This effect only arises when the rectangle orientation is informative about the target configuration orientation. This same-object advantage would normally be attributed to object-based attention, but the same pattern of data emerged when the rectangles were replaced with a salient orientation cue. The rectangles can apparently serve as a cue, making the cuing effect appear to be an object-based attention effect. However, the cuing effect can also be triggered by a horizontal bar in the center of the display. Thus participants can adopt an attentional set for a horizontal orientation independently of stimulus location. Results from comparison tasks that might have been attributed to object-based attention could instead be due to a combination of a horizontal advantage and an orientation set cost. Although these results lead to a diminished role for object-based attention, they also call for a better understanding of how an attentional set can be adopted without selecting either locations or objects. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
	pages = {1062--1082},
	number = {8},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Chen, Zhe and Cave, Kyle R.},
	date = {2019},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {{WantToRead}, Visual Attention, Test Construction, Responses, Spatial Orientation (Perception)},
	file = {Chen and Cave - 2019 - When is object-based attention not based on object.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\JDJZYYRV\\Chen and Cave - 2019 - When is object-based attention not based on object.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\UA8DUW3G\\2019-22466-001.html:text/html},
}

@misc{bi_perception_2021,
	title = {Perception of soft materials relies on physics-based object representations: Behavioral and computational evidence},
	rights = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial}-{NoDerivs} 4.0 International), {CC} {BY}-{NC}-{ND} 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.05.12.443806v1},
	doi = {10.1101/2021.05.12.443806},
	shorttitle = {Perception of soft materials relies on physics-based object representations},
	abstract = {When encountering objects, we readily perceive not only low-level properties (e.g., color and orientation), but also seemingly higher-level ones – including aspects of physics (e.g., mass). Perhaps nowhere is this contrast more salient than in the perception of soft materials such as cloths: the dynamics of these objects (including how their three-dimensional forms vary) are determined by their physical properties such as stiffness, elasticity, and mass. Here we hypothesize that the perception of cloths and their physical properties must involve not only image statistics, but also abstract object representations that incorporate ”intuitive physics”. We provide behavioral and computational evidence for this hypothesis. We find that humans can visually match the stiffness of cloths with unfamiliar textures from the way they undergo natural transformations (e.g. flapping in the wind) across different scenarios. A computational model that casts cloth perception as mental physics simulation explains important aspects of this behavior.},
	publisher = {{bioRxiv}},
	author = {Bi, Wenyan and Shah, Aalap D. and Wong, Kimberly W. and Scholl, Brian and Yildirim, Ilker},
	urldate = {2023-06-22},
	date = {2021-05-13},
	langid = {english},
	note = {Pages: 2021.05.12.443806
Section: New Results},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\7HKQKWLN\\Bi et al. - 2021 - Perception of soft materials relies on physics-bas.pdf:application/pdf},
}

@incollection{adelson_lightness_2000,
	location = {Cambridge, {MA}, {US}},
	edition = {2},
	title = {Lightness perception and lightness illusions},
	abstract = {A gray surface in sunlight may have much higher luminance than it has in the shade, but it still looks gray. To achieve the task of “lightness constancy,” the visual system must discount the illumination and other viewing conditions and estimate the reflectance. Many different physical situations, such as shadows, filters, or haze, can be combined to form a single, simple mapping from luminance to reflectance. The net effect of the viewing conditions, including additive and multiplicative effects, may be termed an “atmosphere.” An “atmospheric transfer function” maps reflectance into luminance. To correctly estimate lightness, a visual system must determine a “lightness transfer function” that performs the inverse. Human lightness computation is imperfect, but performs well in most natural situations. Lightness illusions can reveal the inner workings of the estimation process, which may involve low-level, mid-level, and high-level mechanisms. Mid-level mechanisms, involving contours, junctions, and grouping, appear to be critical in explaining many lightness phenomena},
	pages = {339--351},
	booktitle = {The New Cognitive Neurosciences},
	publisher = {{MIT} Press},
	author = {Adelson, Edward H},
	date = {2000},
	langid = {english},
	file = {Adelson (2000) Lightness perception and lightness .pdf:C\:\\Users\\inkpe\\Zotero\\storage\\J3R3Z3G4\\Adelson (2000) Lightness perception and lightness .pdf:application/pdf},
}

@article{wong_seeing_2023,
	title = {Seeing soft materials draped over objects: A case study of intuitive physics in perception, attention, and memory},
	volume = {34},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/09567976221109194},
	doi = {10.1177/09567976221109194},
	shorttitle = {Seeing Soft Materials Draped Over Objects},
	abstract = {We typically think of intuitive physics in terms of high-level cognition, but might aspects of physics also be extracted during lower-level visual processing? Might we not only think about physics, but also see it? We explored this using multiple tasks in online adult samples with objects covered by soft materials—as when you see a chair with a blanket draped over it—where you must account for the physical interactions between cloth, gravity, and object. In multiple change-detection experiments (n = 200), observers from an online testing marketplace were better at detecting image changes involving underlying object structure versus those involving only the superficial folds of cloths—even when the latter were more extreme along several dimensions. And in probe-comparison experiments (n = 100), performance was worse when both probes (vs. only one) appeared on image regions reflective of underlying object structure (equating visual properties). This work collectively shows how vision uses intuitive physics to recover the deeper underlying structure of scenes.},
	pages = {111--119},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychological Science},
	author = {Wong, Kimberly W. and Bi, Wenyan and Soltani, Amir A. and Yildirim, Ilker and Scholl, Brian J.},
	urldate = {2023-06-05},
	date = {2023-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
	keywords = {{justForCitation}},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\EXFCSP4K\\Wong et al. - 2023 - Seeing Soft Materials Draped Over Objects A Case .pdf:application/pdf},
}

@incollection{ellis_finished_1938,
	location = {London},
	title = {On finished and unfinished tasks},
	url = {http://content.apa.org/books/11496-025},
	pages = {300--314},
	booktitle = {A Source Book of Gestalt Psychology},
	publisher = {Kegan Paul, Trench, Trubner \& Company},
	author = {Zeigarnik, Bluma},
	editor = {Ellis, Willis D.},
	urldate = {2023-06-05},
	date = {1938},
	langid = {english},
	doi = {10.1037/11496-025},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\X88XHA5V\\2007-10344-025.html:text/html;Zeigarnik - 1938 - On finished and unfinished tasks..pdf:C\:\\Users\\inkpe\\Zotero\\storage\\82CJZ4C7\\Zeigarnik - 1938 - On finished and unfinished tasks..pdf:application/pdf},
}

@article{syrek_unfinished_2014,
	title = {Unfinished tasks foster rumination and impair sleeping—Particularly if leaders have high performance expectations},
	volume = {19},
	issn = {1939-1307},
	doi = {10.1037/a0037127},
	abstract = {This study examines the relationship between time pressure and unfinished tasks as work stressors on employee well-being. Relatively little is known about the effect of unfinished tasks on well-being. Specifically, excluding the impact of time pressure, we examined whether the feeling of not having finished the week’s tasks fosters perseverative cognitions and impairs sleep. Additionally, we proposed that leader performance expectations moderate these relationships. In more detail, we expected the detrimental effect of unfinished tasks on both rumination and sleep would be enhanced if leader expectations were perceived to be high. In total, 89 employees filled out online diary surveys both before and after the weekend over a 5-week period. Multilevel growth modeling revealed that time pressure and unfinished tasks impacted rumination and sleep on the weekend. Further, our results supported our hypothesis that unfinished tasks explain unique variance in the dependent variables above and beyond the influence of time pressure. Moreover, we found the relationship between unfinished tasks and both rumination and sleep was moderated by leader performance expectations. Our results emphasize the importance of unfinished tasks as a stressor and highlight that leadership, specifically in the form of performance expectations, contributes significantly to the strength of this relationship. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
	pages = {490--499},
	journaltitle = {Journal of Occupational Health Psychology},
	author = {Syrek, Christine J. and Antoni, Conny H.},
	date = {2014},
	note = {Place: {US}
Publisher: Educational Publishing Foundation},
	keywords = {Expectations, Job Performance, Leadership, Rumination (Cognitive Process), Sleep},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\LGY8I3YC\\2014-24213-001.html:text/html;Syrek and Antoni - 2014 - Unfinished tasks foster rumination and impair slee.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\VZE65M4W\\Syrek and Antoni - 2014 - Unfinished tasks foster rumination and impair slee.pdf:application/pdf},
}

@article{gao_psychophysics_2009,
	title = {The psychophysics of chasing: A case study in the perception of animacy},
	volume = {59},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/S0010028509000188},
	doi = {10.1016/j.cogpsych.2009.03.001},
	shorttitle = {The psychophysics of chasing},
	abstract = {Psychologists have long been captivated by the perception of animacy – the fact that even simple moving shapes may appear to engage in animate, intentional, and goal-directed movements. Here we report several new types of studies of a particularly salient form of perceived animacy: chasing, in which one shape (the ‘wolf’) pursues another shape (‘the sheep’). We first demonstrate two new cues to perceived chasing – chasing subtlety (the degree to which the wolf deviates from perfectly ‘heat-seeking’ pursuit) and directionality (whether and how the shapes ‘face’ each other). We then use these cues to show how it is possible to assess the objective accuracy of such percepts, and to distinguish the immediate perception of chasing from those more subtle (but nevertheless real) types of ‘stalking’ that cannot be readily perceived. We also report several methodological advances. Previous studies of the perception of animacy have faced two major challenges: (a) it is difficult to measure perceived animacy with quantitative precision; and (b) task demands make it difficult to distinguish perception from higher-level inferences about animacy. We show how these challenges can be met, at least in our case study of perceived chasing, via tasks based on dynamic visual search (the Find-the-Chase task) and a new type of interactive display (the Don’t-Get-Caught! task).},
	pages = {154--179},
	number = {2},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Gao, Tao and Newman, George E. and Scholl, Brian J.},
	urldate = {2023-06-05},
	date = {2009-09-01},
	langid = {english},
	keywords = {Intention, {justForCitation}, Event perception, Chasing, Goal-directed behavior, Perception of animacy},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\KNE9IUQU\\Gao et al. - 2009 - The psychophysics of chasing A case study in the .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\364A4H5J\\S0010028509000188.html:text/html},
}

@article{moot_fear_1988,
	title = {Fear of failure and the Zeigarnik effect},
	volume = {63},
	issn = {0033-2941},
	doi = {10.2466/pr0.1988.63.2.459},
	pages = {459--464},
	number = {2},
	journaltitle = {Psychological Reports},
	shortjournal = {Psychological Reports},
	author = {Moot, S. A. and Teevan, R. C. and Greenfeld, N.},
	date = {1988-10},
	pmid = {3222411},
	keywords = {Memory, Humans, Adult, Mental Recall, Motivation, Achievement, Fear},
	file = {Moot et al. - 1988 - Fear of failure and the Zeigarnik effect.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\F2CLGW8T\\Moot et al. - 1988 - Fear of failure and the Zeigarnik effect.pdf:application/pdf},
}

@article{martin_recall_1964,
	title = {Recall of completed and interrupted tasks by achievers and underachievers},
	volume = {55},
	issn = {1939-2176},
	doi = {10.1037/h0040038},
	abstract = {The relation between high-school achievement and the Zeigarnik effect (greater recall of incompleted than of completed tasks) was studied. Ss performed 12 paper-and-pencil tasks, ½ of which were interrupted, under 2 levels of instruction-induced motivation. Recall of tasks was compared for achievers (above group median {IQ} and above median grade-point total) and underachievers (above median {IQ} but below median grade-point total). The achievers recalled more incompleted tasks and showed a greater Zeigarnik effect. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {314--316},
	journaltitle = {Journal of Educational Psychology},
	author = {Martin, James G. and Davidson, Judy},
	date = {1964},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Recall (Learning), Academic Achievement, High Schools},
	file = {Martin and Davidson - 1964 - Recall of completed and interrupted tasks by achie.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\V6LNTX75\\Martin and Davidson - 1964 - Recall of completed and interrupted tasks by achie.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\6YPQVYVP\\1965-08586-001.html:text/html},
}

@incollection{eitam_motivated_2013,
	location = {New York, {NY}, {US}},
	title = {Motivated remembering: Remembering as accessibility and accessibility as motivational relevance},
	isbn = {978-0-19-973001-8},
	series = {Oxford library of psychology},
	shorttitle = {Motivated remembering},
	abstract = {This chapter presents a novel framework that integrates motivational relevance and accessibility and outlines its implications for the study of memory. The authors first review a recent analysis of motivation (Higgins, 2012) and a recent framework linking motivational relevance and accessibility (Eitam \& Higgins, 2010). The authors then propose and demonstrate that knowledge activation and recall of information—whether implicit or explicit, and regardless of the type of that information (semantic, episodic, autobiographical, or procedural)—are affected by the motivational relevance of that information at the time retrieval is attempted or measured. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {463--475},
	booktitle = {The Oxford Handbook of Social Cognition},
	publisher = {Oxford University Press},
	author = {Eitam, Baruch and Miele, David B. and Higgins, E. Tory},
	date = {2013},
	keywords = {Memory, Human Information Storage, Motivation, Retention, Lexical Access},
	file = {Eitam et al. - 2013 - Motivated remembering Remembering as accessibilit.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\RV7MJ5FM\\Eitam et al. - 2013 - Motivated remembering Remembering as accessibilit.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\ZC9KKPUA\\2013-34444-022.html:text/html},
}

@article{nguyen_rotating_2024,
	title = {Rotating objects cue spatial attention via the perception of frictive surface contact},
	volume = {242},
	issn = {00100277},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0010027723002895},
	doi = {10.1016/j.cognition.2023.105655},
	abstract = {We report a new attentional cueing effect, which shows how attention models the physical force of friction. Most objects we see are in frictive contact with a ‘floor’, such that clockwise rotation causes rightward movement and counterclockwise rotation leftward movement. Is this regularity encoded in spatial orienting responses? In Experiment 1, seeing a clockwise-rotating ‘wheel’ produced faster responses to subsequent targets appearing on the right vs. left (and vice versa for counterclockwise rotation). Thus, when viewing a lone rotating wheel, we orient attention toward where we predict it will move next, assuming frictive floor contact. But what happens if the rotating wheel is seen touching another visible surface? In Experiment 2, rotational cueing was stronger for wheels touching a visible floor, was abolished for wheels near but not touching another surface, and reversed for wheels touching a ceiling. We conclude that the visual system makes an assumption of frictive floor contact, and rapidly analyzes visual cues to frictive contact with other surfaces, in order to orient attention toward where objects are likely to move next.},
	pages = {105655},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Nguyen, Hong B. and Van Buren, Benjamin},
	urldate = {2023-12-10},
	date = {2024-01},
	langid = {english},
	keywords = {{HasNote}},
	file = {Nguyen and Van Buren - 2024 - Rotating objects cue spatial attention via the per.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\GSDEFB7U\\Nguyen and Van Buren - 2024 - Rotating objects cue spatial attention via the per.pdf:application/pdf},
}

@article{todd_visual_1982,
	title = {Visual perception of relative mass in dynamic events},
	volume = {11},
	issn = {0301-0066},
	url = {https://doi.org/10.1068/p110325},
	doi = {10.1068/p110325},
	abstract = {Two experiments are reported which examine how the dynamic property of relative mass in collision events is specified by kinematic properties of a visual motion display. In most cases observers are accurate at detecting the ?heavier? of two objects, although they do not take advantage of the completely general optic information that is available. Instead, they rely on limited information that breaks down at extreme values of elasticity and relative initial velocity. In addition, observers appear to utilize different information for relative mass with different types of collisions. It is suggested that reliance on such limited information may be appropriate for perceivers operating in the restricted context of a terrestrial environment.},
	pages = {325--335},
	number = {3},
	journaltitle = {Perception},
	shortjournal = {Perception},
	author = {Todd, James T and Warren, William H},
	urldate = {2023-12-26},
	date = {1982-06-01},
	note = {Publisher: {SAGE} Publications Ltd {STM}},
	keywords = {{HasNote}},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\PS6RTIY4\\Todd and Warren - 1982 - Visual Perception of Relative Mass in Dynamic Even.pdf:application/pdf},
}

@article{tsuchiya_continuous_2005,
	title = {Continuous flash suppression reduces negative afterimages},
	volume = {8},
	issn = {1546-1726},
	doi = {10.1038/nn1500},
	abstract = {Illusions that produce perceptual suppression despite constant retinal input are used to manipulate visual consciousness. Here we report on a powerful variant of existing techniques, continuous flash suppression. Distinct images flashed successively at ∼10 Hz into one eye reliably suppress an image presented to the other eye. The duration of perceptual suppression is at least ten times greater than that produced by binocular rivalry. Using this tool we show that the strength of the negative afterimage of an adaptor was reduced by half when it was perceptually suppressed by input from the other eye. The more completely the adaptor was suppressed, the more strongly the afterimage intensity was reduced. Paradoxically, trial-to-trial visibility of the adaptor did not correlate with the degree of reduction. Our results imply that formation of afterimages involves neuronal structures that access input from both eyes but that do not correspond directly to the neuronal correlates of perceptual awareness. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1096--1101},
	number = {8},
	journaltitle = {Nature Neuroscience},
	author = {Tsuchiya, Naotsugu and Koch, Christof},
	date = {2005},
	note = {Place: United Kingdom
Publisher: Nature Publishing Group},
	keywords = {Visual Perception, Neurons, Afterimage, Retina},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\DPUHSIU7\\2005-08819-005.html:text/html},
}

@misc{wood_object_2024,
	title = {Object permanence in newborn chicks is robust against opposing evidence},
	url = {http://arxiv.org/abs/2402.14641},
	abstract = {Newborn animals have advanced perceptual skills at birth, but the nature of this initial knowledge is unknown. Is initial knowledge flexible, continuously adapting to the statistics of experience? Or can initial knowledge be rigid and robust to change, even in the face of opposing evidence? We address this question through controlled-rearing experiments on newborn chicks. First, we reared chicks in an impoverished virtual world, where objects never occluded one another, and found that chicks still succeed on object permanence tasks. Second, we reared chicks in a virtual world in which objects teleported from one location to another while out of view: an unnatural event that violates the continuity of object motion. Despite seeing thousands of these violations of object permanence, and not a single non-violation, the chicks behaved as if object permanence were true, exhibiting the same behavior as chicks reared with natural object permanence events. We conclude that object permanence develops prenatally and is robust to change from opposing evidence.},
	number = {{arXiv}:2402.14641},
	publisher = {{arXiv}},
	author = {Wood, Justin N. and Ullman, Tomer D. and Wood, Brian W. and Spelke, Elizabeth S. and Wood, Samantha M. W.},
	urldate = {2024-02-28},
	date = {2024-02-22},
	eprinttype = {arxiv},
	eprint = {2402.14641 [q-bio]},
	keywords = {Interesting, Quantitative Biology - Neurons and Cognition, irresistibility, irresistible},
	file = {arXiv.org Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\97K6PB4C\\2402.html:text/html;Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\7RKCELWM\\Wood et al. - 2024 - Object permanence in newborn chicks is robust agai.pdf:application/pdf},
}

@article{tse_volume_1999,
	title = {Volume completion},
	volume = {39},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/S0010028599907156},
	doi = {10.1006/cogp.1999.0715},
	abstract = {The visual system completes image fragments into larger regions when those fragments are taken to be the visible portions of an occluded object. Kellman and Shipley (1991) argued that this “amodal” completion is based on the way that the contours of image fragments “relate.” Contours relate when their imaginary extensions intersect at an obtuse or right angle. However, it is shown here that contour relatability is neither necessary nor sufficient for completion to take place. Demonstrations that go beyond traditional examples of overlapping flat surfaces reveal that “mergeable” volumes, rather than relatable contours, are the critical elements in completion phenomena. A volume is defined as a 3-D enclosure. Typically, this refers to a surface plus the inside that it encloses. Two volumes are mergeable when their unbounded visible surfaces are relatable or the insides enclosed by those surfaces can completely merge. Two surfaces are relatable when their visible portions can be extended into occluded space along the trajectories defined by their respective curvatures so that they merge into a common surface. A volume-based account of amodal completion subsumes surface completion as a special case and explains examples that neither a contour- nor a surface-based account can explain.},
	pages = {37--68},
	number = {1},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Tse, Peter Ulric},
	urldate = {2024-12-24},
	date = {1999-08-01},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\99C5ETJX\\S0010028599907156.html:text/html},
}

@article{yildirim_perceiving_2016,
	title = {Perceiving fully occluded objects via physical simulation},
	volume = {38},
	url = {https://escholarship.org/uc/item/0cp7162x},
	abstract = {Conventional theories of visual object recognition treat objectseffectively as abstract, arbitrary patterns of image features.They do not explicitly represent objects as physical entities inthe world, with physical properties such as three-dimensionalshape, mass, stiffness, elasticity, surface friction, and so on.However, for many purposes, an object’s physical existence iscentral to our ability to recognize it and think about it. Thisis certainly true for recognition via haptic perception, i.e., per-ceiving objects by touch, but even in the visual domain an ob-ject’s physical properties may directly determine how it looksand thereby how we recognize it. Here we show how a physi-cal object representation can allow the solution of visual prob-lems, like perceiving an object under a cloth, that are other-wise difficult to accomplish without extensive experience, andwe provide behavioral and computational evidence that peoplecan use such a representation.},
	number = {0},
	journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Yildirim, Ilker and Siegel, Max H. and Tenenbaum, Joshua B.},
	urldate = {2024-12-24},
	date = {2016},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\Z5EJXDEK\\Yildirim et al. - 2016 - Perceiving Fully Occluded Objects via Physical Sim.pdf:application/pdf},
}

@article{ullman_draping_2019,
	title = {Draping an elephant: Uncovering children’s reasoning about cloth-covered objects},
	volume = {41},
	url = {https://escholarship.org/uc/item/76w0v9f1},
	shorttitle = {Draping an Elephant},
	abstract = {Humans have an intuitive understanding of physics. They canpredict how a physical scene will unfold, and reason about howit came to be. Adults may rely on such a physical representa-tion for visual reasoning and recognition, going beyond visualfeatures and capturing objects in terms of their physical prop-erties. Recently, the use of draped objects in recognition wasused to examine adult object representations in the absence ofmany common visual features. In this paper we examine youngchildren’s reasoning about draped objects in order to examinethe develop of physical object representation. In addition, weargue that a better understanding of the development of theconcept of cloth as a physical entity is worthwhile in and ofitself, as it may form a basic ontological category in intuitivephysical reasoning akin to liquids and solids. We use two ex-periments to investigate young children’s (ages 3–5) reasoningabout cloth-covered objects, and find that they perform signif-icantly above chance (though far from perfectly) indicating arepresentation of physical objects that can interact dynamicallywith the world. Children’s success and failure pattern is similaracross the two experiments, and we compare it to adult behav-ior. We find a small effect, which suggests the specific featuresthat make reasoning about certain objects more difficult maycarry into adulthood.},
	number = {0},
	journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Ullman, Tomer D. and Kosoy, Eliza and Yildrim, Ilker and Soltani, Amir A. and Siegel, Max and Tenenbaum, Joshua B. and Spelke, Elizabeth S.},
	urldate = {2024-12-24},
	date = {2019},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\CZ68YX84\\Ullman et al. - 2019 - Draping an Elephant Uncovering Children’s Reasoni.pdf:application/pdf},
}

@article{barsingerhorn_possibilities_2012,
	title = {On possibilities for action: The past, present and future of affordance research},
	volume = {3},
	issn = {2082-7598},
	url = {http://www.scopus.com/inward/record.url?scp=84894054135&partnerID=8YFLogxK},
	shorttitle = {On possibilities for action},
	abstract = {We give a historical overview of the development of almost 50 years of empirical research on the affordances in the past and in the present. Defined by James Jerome Gibson in the early development of the Ecological Approach to Perception and Action as the prime of perception and action, affordances have become a rich topic of investigation in the fields of human movement science and experimental psychology. The methodological origins of the empirical research performed on affordances can be traced back to the mid 1980's and the works of Warren (1984, 1988) and Michaels (1988). Most of the research in Ecological Psychology performed since has focused on the actualization of discretely defined actions, the perception of action boundaries, the calculation of pi-numbers, and the measurement of response times. The research efforts have resulted in advancements in the understanding of the dynamic nature of affordances, affordances in a social context and the importance of calibration for perception of affordances. Although affordances are seen as an instrumental part of the control of action most studies investigating affordances do not pay attention to the control of the action. We conclude that affordances are still primarily treated as a utility to select behaviour, which creates a conceptual barrier that hinders deeper understanding of affordances. A focus on action-boundaries has largely prevented advancement in other aspects of affordances, most notably an integrative understanding of the role of affordances in the control of action.},
	pages = {54--69},
	number = {2},
	journaltitle = {Avant},
	author = {Barsingerhorn, Annemiek D. and Zaal, Frank T.J.M. and Smith, Joanne and Pepping, Gert Jan},
	urldate = {2025-01-04},
	date = {2012-12},
	keywords = {Action boundary, Action selection, Ecological psychology, Experimental psychology, Perception-action},
}

@article{belledonne_navigational_2022,
	title = {Navigational affordances are automatically computed during scene perception: Evidence from behavioral change blindness and a computational model of active attention},
	volume = {22},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.22.14.4128},
	doi = {10.1167/jov.22.14.4128},
	shorttitle = {Navigational affordances are automatically computed during scene perception},
	abstract = {Scene perception poses a major computational challenge: how does the mind, at a glance, selectively capture actionable content about our surroundings? Here, we argue that attention, via implicit or default tasks such as navigation, influence which regions of the scene are selectively processed. In the context of a change detection task over realistic indoor scenes that had no overt relationship to navigation, we measured how changes in geometry resulting in a difference to shortest paths to the exit affected performance in comparison to trials with path preserving changes. We controlled for low-level visual features by creating pairs of trails with identical starting conditions except for the exit location such that the same change in geometry caused a difference in pathing for only one instance. Despite having no cues for navigation, subjects nevertheless detected changes impacting pathing more readily. However, the current literature on scene perception is incapable of explaining such phenomena, currently forming two disparate bodies of research: work exploring representational targets in cognitive neuroscience and change blindness, characterizing selective processing. Here, we present a unified account via an active attention architecture that guides perception to prioritize aspects of the world relevant to an observer’s goals. In the context of indoor scenes, this architecture uses hypothesis testing to quantify changes in the observer’s goals, i.e. shortest paths to exits, resulting from perceptual updates to distinct spatial “trackers” that evenly divide scene geometry. The greater the impact of updates on pathing, the more computational resources and geometric level-of-detail invested for those trackers. Indeed, for the behavioral experiment, estimated attention explains why some changes are more readily detected: Increased detection rate falls from greater amounts of goal-driven perceptual processing to trackers containing path-modifying differences. These results verify the presence and role of navigational affordances as an implicit goal driving scene perception.},
	number = {14},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Belledonne, Mario and Bao, Yihan and Yildirim, Ilker},
	urldate = {2025-01-04},
	date = {2022-12-05},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\H478FZPT\\article.html:text/html},
}

@article{belledonne_automatic_2021,
	title = {Automatic computation of navigational affordances explains selective processing of geometry in scene perception: behavioral and computational evidence},
	volume = {43},
	url = {https://escholarship.org/uc/item/4jk572xw},
	shorttitle = {Automatic computation of navigational affordances explains selective processing of geometry in scene perception},
	abstract = {One of the more surprising findings in visual cognition is the apparent sparsity of our scene percepts. Yet, scene perception also enables planning and navigation, which require a detailed, structured analysis of the scene geometry, including exit locations and the obstacles along the way. Here, we hypothesize that computation of navigational affordances (e.g., paths to an exit) is a “default” task in the mind, and that task induces selective analysis of the scene geometry most relevant to computing these affordances. In an indoor scene setting, we show that observers more readily detect changes if these changes impact shortest paths to visible exits. We show that behavioral detection rates are explained by a new model of attention that makes heterogeneous-precision inferences about the scene geometry, relative to how its different regions impact navigational affordance computation. This work provides a formal window into the contents of our scene percepts.},
	number = {43},
	journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Belledonne, Mario and Yildirim, Ilker},
	urldate = {2025-01-04},
	date = {2021},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\A7HHLP9W\\Belledonne and Yildirim - 2021 - Automatic computation of navigational affordances .pdf:application/pdf},
}

@article{bonner_coding_2017,
	title = {Coding of navigational affordances in the human visual system},
	volume = {114},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.1618228114},
	doi = {10.1073/pnas.1618228114},
	abstract = {A central component of spatial navigation is determining where one can and cannot go in the immediate environment. We used {fMRI} to test the hypothesis that the human visual system solves this problem by automatically identifying the navigational affordances of the local scene. Multivoxel pattern analyses showed that a scene-selective region of dorsal occipitoparietal cortex, known as the occipital place area, represents pathways for movement in scenes in a manner that is tolerant to variability in other visual features. These effects were found in two experiments: One using tightly controlled artificial environments as stimuli, the other using a diverse set of complex, natural scenes. A reconstruction analysis demonstrated that the population codes of the occipital place area could be used to predict the affordances of novel scenes. Taken together, these results reveal a previously unknown mechanism for perceiving the affordance structure of navigable space.},
	pages = {4793--4798},
	number = {18},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Bonner, Michael F. and Epstein, Russell A.},
	urldate = {2025-01-04},
	date = {2017-05-02},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\ZWGHUCKL\\Bonner and Epstein - 2017 - Coding of navigational affordances in the human vi.pdf:application/pdf},
}

@article{chong_evolution_2020,
	title = {On the evolution of a radical concept: affordances according to gibson and their subsequent use and development},
	volume = {15},
	issn = {1745-6916},
	url = {https://doi.org/10.1177/1745691619868207},
	doi = {10.1177/1745691619868207},
	shorttitle = {On the Evolution of a Radical Concept},
	abstract = {James J. Gibson, the founder of ecological psychology, introduced a radical empiricist approach to perception and action centered on direct perception in naturalistic environments that was counter to popular representational views of his time. This direct perception approach and the associated introduction of the affordance concept have been extremely influential in several fields of study. However, since its inception, the affordance concept has evolved in a manner such that it now deviates significantly from Gibson’s original intention. This review follows use of the affordance concept by four sets of influential experimental psychologists: Gibson, Donald Norman, Mike Tucker and Rob Ellis, and Daniel Bub and Michael Masson. Particular attention is paid to the manner in which they applied the concept and the contributions provided by each set of researchers. The primary goal of this review is to determine what cognitive psychologists can take away from developments within the field and what considerations should be taken into account when using the term affordance. Having a more thorough understanding of the factors that led to the concept of affordance and its recent reformulations will better equip cognitive psychologists and, by extension, human factors researchers to further advance the study of perception–action relations.},
	pages = {117--132},
	number = {1},
	journaltitle = {Perspectives on Psychological Science},
	shortjournal = {Perspect Psychol Sci},
	author = {Chong, Isis and Proctor, Robert W.},
	urldate = {2025-01-04},
	date = {2020-01-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
}

@article{fodor_how_1981,
	title = {How direct is visual perception?: Some reflections on Gibson's “ecological approach”},
	volume = {9},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/0010027781900093},
	doi = {10.1016/0010-0277(81)90009-3},
	shorttitle = {How direct is visual perception?},
	pages = {139--196},
	number = {2},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Fodor, J. A. and Pylyshyn, Z. W.},
	urldate = {2025-01-04},
	date = {1981-04-01},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\49L7D2SU\\0010027781900093.html:text/html},
}

@article{gibson_new_1967,
	title = {New reasons for realism},
	volume = {17},
	issn = {1573-0964},
	url = {https://doi.org/10.1007/BF00485025},
	doi = {10.1007/BF00485025},
	abstract = {Both the psychology of perception and the philosophy of perception seem to show a new face when the process is considered at its own level, distinct from that of sensation. Unfamiliar conceptions in physics, anatomy, physiology, psychology, and phenomenology are required to clarify the separation and make it plausible. But there have been so many dead ends in the effort to solve the theoretical problems of perception that radical proposals may now be acceptable. Scientists are often more conservative than philosophers of science. I end, therefore, as I began, with a plea for help.},
	pages = {162--172},
	number = {1},
	journaltitle = {Synthese},
	shortjournal = {Synthese},
	author = {Gibson, James J.},
	urldate = {2025-01-04},
	date = {1967-01-01},
	langid = {english},
	keywords = {Radical Proposal, Theoretical Problem, Unfamiliar Conception},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\FPWY6LC3\\Gibson - 1967 - New reasons for realism.pdf:application/pdf},
}

@article{harel_early_2022,
	title = {Early electrophysiological markers of navigational affordances in scenes},
	volume = {34},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn_a_01810},
	doi = {10.1162/jocn_a_01810},
	abstract = {Scene perception and spatial navigation are interdependent cognitive functions, and there is increasing evidence that cortical areas that process perceptual scene properties also carry information about the potential for navigation in the environment (navigational affordances). However, the temporal stages by which visual information is transformed into navigationally relevant information are not yet known. We hypothesized that navigational affordances are encoded during perceptual processing and therefore should modulate early visually evoked \{{ERPs}\}, especially the scene-selective P2 component. To test this idea, we recorded \{{ERPs}\} from participants while they passively viewed computer-generated room scenes matched in visual complexity. By simply changing the number of doors (0 doors, 1 door, 2 doors, 3 doors), we were able to systematically vary the number of pathways that afford movement in the local environment, while keeping the overall size and shape of the environment constant. We found that rooms with 0 doors evoked a higher P2 response than rooms with three doors, consistent with prior research reporting higher P2 amplitude to closed relative to open scenes. Moreover, we found P2 amplitude scaled linearly with the number of doors in the scenes. Navigability effects on the \{{ERP}\} waveform were also observed in a multivariate analysis, which showed significant decoding of the number of doors and their location at earlier time windows. Together, our results suggest that navigational affordances are represented in the early stages of scene perception. This complements research showing that the occipital place area automatically encodes the structure of navigable space and strengthens the link between scene perception and navigation.},
	pages = {397--410},
	number = {3},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Harel, Assaf and Nador, Jeffery D. and Bonner, Michael F. and Epstein, Russell A.},
	urldate = {2025-01-04},
	date = {2022-02-01},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\K79YYM3X\\Harel et al. - 2022 - Early Electrophysiological Markers of Navigational.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\D8HBI3GT\\Early-Electrophysiological-Markers-of-Navigational.html:text/html},
}

@article{jolicoeur_curve_1986,
	title = {Curve tracing: A possible basic operation in the perception of spatial relations},
	volume = {14},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/BF03198373},
	doi = {10.3758/BF03198373},
	shorttitle = {Curve tracing},
	abstract = {The two experiments in this study suggest that fast internal tracing of curves is employed by the visual system in the perception of certain shape properties and spatial relations. The experimental task in the first experiment was to determine, as rapidly as possible, whether two Xs lay on the same curve or on different curves in a visual display. Mean response time for “same” responses increased monotonically with increasing distance along the curve between the Xs. The task in the second experiment was to decide either that a curve joining two Xs was unbroken or that the curve had a gap. Decision times again increased as the length of the curve joining the Xs was increased. The results of both experiments suggest that people can trace curves in a visual display internally at high speed (the average rate of tracing was about 40° of visual angle per second). Curve tracing may be an important visual process used to integrate information from different parts of a visual display.},
	pages = {129--140},
	number = {2},
	journaltitle = {Memory \& Cognition},
	shortjournal = {Memory \& Cognition},
	author = {Jolicoeur, Pierre and Ullman, Shimon and Mackay, Marilynn},
	urldate = {2025-01-04},
	date = {1986-03-01},
	langid = {english},
	keywords = {Basic Pattern, Exposure Duration, Response Time, Spatial Relation, Visual Display},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\YQYA9IDI\\Jolicoeur et al. - 1986 - Curve tracing A possible basic operation in the p.pdf:application/pdf},
}

@article{jolicoeur_visual_1991,
	title = {Visual curve tracing properties},
	volume = {17},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.17.4.997},
	abstract = {Ss decided whether 2 dots were on the same curve or 2 different curves, and the curvature of the curves or the proximity of other (distractor) curves to the target curve was varied. Response time increased as the arc length of the curve connecting the 2 dots increased, suggesting that the curve was traced to perform the task. Tracing rate was faster for low- than high-curvature contours and was increasingly slower as distractor contours were increasingly proximal to the traced curve. Proximity results were predicted by a model in which response time depends on the ratio of the distance between the dots and the distance between adjacent lines. Curve tracing operations used to integrate information along contours are sensitive to several properties of the contours. The implications of the sensitivity of tracing operations to these curve properties are discussed. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {997--1022},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Jolicoeur, Pierre and Ullman, Shimon and Mackay, Marilynn},
	date = {1991},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Tracking, Stimulus Parameters},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\YFM97JWW\\doiLanding.html:text/html},
}

@article{mccormick_capturing_1992,
	title = {Capturing visual attention and the curve tracing operation},
	volume = {18},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.18.1.72},
	abstract = {The hypothesis that orienting visual attention is an important component of visual curve tracing was investigated. Ss examined a visual display and decided as quickly as possible whether 2 dots were on the same or different curves. The rate of tracing was determined by measuring the effects of curve distance on response time. Attention was directed to a curve by momentarily presenting it at a higher luminance. Directing attention to a curve that had 2 dots on it resulted in faster tracing rates with large benefits in overall response time. Directing attention to a distractor curve resulted in slower tracing rates and sizable costs in overall response times. Two alternative nonattentional explanations (eye movements and visible persistence) were examined and rejected. The role of attention in curve tracing is discussed in terms of the selective nature of curve tracing. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {72--89},
	number = {1},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {{McCormick}, Peter A. and Jolicoeur, Pierre},
	date = {1992},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Attention, Reaction Time, Visual Attention, Visual Tracking},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\8XNWHH6B\\doiLanding.html:text/html},
}

@article{pringle_mental_1988,
	title = {Mental curve tracing with elementary stimuli},
	volume = {14},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.14.4.716},
	abstract = {It has been proposed that certain spatial relations are determined by an operation, or "visual routine," that can trace along a boundary (Ullman, 1984), as supported by Jolicoeur, Ullman, \& Mackay's (1986) finding that the time required to determine if 2 Xs are on the same curve increased monotonically with the separation of the Xs along that curve. In the present study the generality of the curve tracing hypothesis was explored across 4 experiments by using elementary stimuli that eliminated interweaving curves, displaced the fixation point away from the curves and target Xs, and provided a simple alternative to curve tracing—namely, determining whether or not the Xs fell on the same side of the figure. In Exps 1 and 2, Ss were instructed to decide if the 2 Xs fell on same or different curves. Mean reaction time ({RT}) for same trials increased monotonically with the distance separating the Xs. In Exps 3 and 4 alternatives to curve tracing were tested. For same trials the evidence strongly favored curve tracing. However, different trials were apparently solved on the basis of judgmental processes operating in parallel with curve tracing. Curve tracing rates fluctuated across experiments and seemed to be partially governed by the width of the "pathway" provided for the trace. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {716--728},
	number = {4},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Pringle, Richard and Egeth, Howard E.},
	date = {1988},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Imagery, Spatial Perception, Visual Displays},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\2HAWN5TJ\\doiLanding.html:text/html},
}

@article{ullman_against_1980,
	title = {Against direct perception},
	volume = {3},
	issn = {1469-1825, 0140-525X},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/abs/against-direct-perception/D40D5E642E146073D2076031488C4459},
	doi = {10.1017/S0140525X0000546X},
	abstract = {Central to contemporary cognitive science is the notion that mental processes involve computations defined over internal representations. This view stands in sharp contrast to the “direct approach” to visual perception and cognition, whose most prominent proponent has been J.J. Gibson. In the direct theory, perception does not involve computations of any sort; it is the result of the direct pickup of available information. The publication of Gibson's recent book (Gibson 1979) offers an opportunity to examine his approach, and, more generally, to contrast the theory of direct perception with the computational/representational view. In the first part of the present article (Sections 2–3) the notion of “direct perception” is examined from a theoretical standpoint, and a number of objections are raised. Section 4 is a “case study”: the problem of perceiving the three-dimensional shape of moving objects is examined. This problem, which has been extensively studied within the immediate perception framework, serves to illustrate some of the inherent shortcomings of that approach. Finally, in Section 5, an attempt is made to place the theory of direct perception in perspective by embedding it in a more comprehensive framework.},
	pages = {373--381},
	number = {3},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Ullman, S.},
	urldate = {2025-01-04},
	date = {1980-09},
	langid = {english},
	keywords = {artificial intelligence, computational models, direct perception, ecological optics, Gibsonian theory, information pickup, visual representation},
}

@article{ullman_visual_1984,
	title = {Visual routines},
	volume = {18},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/0010027784900234},
	doi = {10.1016/0010-0277(84)90023-4},
	abstract = {This paper examines the processing of visual information beyond the creation of the early representations. A fundamental requirement at this level is the capacity to establish visually abstract shape properties and spatial relations. This capacity plays a major role in object recognition, visually guided manipulation, and more abstract visual thinking. For the human visual system, the perception of spatial properties and relations that are complex from a computational standpoint nevertheless often appears deceivingly immediate and effortless. The proficiency of the human system in analyzing spatial information far surpasses the capacities of current artificial systems. The study of the computations that underlie this competence may therefore lead to the development of new more efficient methods for the spatial analysis of visual information. The perception of abstract shape properties and spatial relations raises fundamental difficulties with major implications for the overall processing of visual information. It will be argued that the computation of spatial relations divides the analysis of visual information into two main stages. The first is the bottom-up creation of certain representations of the visible environment. The second stage involves the application of process called ‘visual routines’ to the representations constructed in the first stage. These routines can establish properties and relations that cannot be represented explicitly in the initial representations. Visual routines are composed of sequences of elemental operations. Routines for different properties and relations share elemental operations. Using a fixed set of basic operations, the visual system can assemble different routines to extract an unbounded variety of shape properties and spatial relations.
Résumé
Cet article porte sur le traitement de l'information visuelle apre`s la cre´ation des premie`res repre´sentations. La capacite´de de´terminer visuellement les proprie´te´s formelles absraites et les relations spatiales esl un pre´requisa`ce niveau. Cette capacite´joue un role majeur dans la reconnaissance d'objet, dans les manipulations guide´es par la vision ainsi que dans la pense´e visuelle plus abstraite. Pour le syste`me visuel humain, la perception des proprie´te´s spatiales et des relations complexes au point de vue calcui apparait trompeusement imme´diate et facile. L'efficacite´du syste`me humain pour analyser l'information spatiale surpasse de loin les capacite´s des syste`mes artificiels utilise´s pour l'analyse spatiale de l'information visuelle. La perception des propriete´s de forme abstraite et des relations spatiales soule`ve des difficulte´es fondamentales avec des conse´quences importantes pour le traitement ge´ne´ral de l'information visuelle. Les auteurs de´fendent l'ide´e que le calcul des relations spatiales se´pare l'analyse de l'infformation visuelle en deux stades principaux. Au cours du premier se cre´ent, de bas en haut, certaines repre´sentations de l'environnement visible. Au cours du second des processus dits ‘routines visuelles’ s'appliquent aux repre´sentations issues du premier stade. Ces routines peuvent reve`ler des proprie´te´s et des relations qui n'e´taient pas repre´sente´es de façon explicite dans les repre´sentations initiales. Les routines visuelles sont compose´es de se´quences d'ope´rationse´le´mentaires conjointes pour les diffe´rentes proprie´te´s et relations. En utilisant une se´rie fixe d'ope´rations de base, le syste`me visuel peut assembler diffe´rentes routines pour extraire une suite illimite´e de proprie´te´s de forme et de relations spatiales. A un niveau plus de´taille´, on sugge`re un certain nombre d'ope´rations de base, en se fondant essentiellement sur leur utilite´potentielle et, en partie, sur des preuves empiriques. Ces ope´rations incluent le changement du centre de traitement, l'indexationa`une localisation d'un observateur exte´rieur, des' activations limite´es, le tracage de frontie`res et des marquages. Les auteurs posent le proble`me de l'assemblage de ces ope´rationse´le´mentaires en routines visuelles signifiantes.},
	pages = {97--159},
	number = {1},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Ullman, Shimon},
	urldate = {2025-01-04},
	date = {1984-12-01},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\SBHV8IKZ\\0010027784900234.html:text/html},
}

@article{warren_perceiving_1984,
	title = {Perceiving affordances: Visual guidance of stair climbing},
	volume = {10},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.10.5.683},
	shorttitle = {Perceiving affordances},
	abstract = {Three experiments investigated "affordances" in visual guidance of stair climbing with 54 male college students. An affordance was defined as the functional utility of an object for an animal with certain action capabilities. Exp I tested the hypothesis that the perceptual category boundary between climbable and unclimbable risers corresponds to critical riser height. 24 Ss were divided into a short group (mean height 5 ft 4.4 in) and a tall group (mean height 6 ft 2.7 in). The results demonstrate that both groups judged stairways as unclimbable at a riser height in proportion to their leg lengths. Exp {II}, conducted with 6 male college students, empirically determined the optimal riser height by measuring energy expenditure during climbing. Results indicate that the riser height requiring minimum energy expenditure was just over one-fourth of leg length for both short (mean height 5 ft 3.2 in) and tall (mean height 6 ft 4.3 in) climbers. Exp {III}, conducted with 24 Ss, tested the hypothesis that perceptual preference for riser height would correspond to the optimal riser height obtained in Exp {II}. It is concluded that perception for the control of action reflects the underlying dynamics of the animal–environment system. (90 ref) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {683--703},
	number = {5},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Warren, William H.},
	date = {1984},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Perceptual Motor Processes, Energy Expenditure, Walking},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\EPZAR2JD\\doiLanding.html:text/html},
}

@article{warren_information_2021,
	title = {Information is where you find it: Perception as an ecologically well-posed problem},
	volume = {12},
	issn = {2041-6695},
	url = {https://doi.org/10.1177/20416695211000366},
	doi = {10.1177/20416695211000366},
	shorttitle = {Information Is Where You Find It},
	abstract = {Texts on visual perception typically begin with the following premise: Vision is an ill-posed problem, and perception is underdetermined by the available information. If this were really the case, however, it is hard to see how vision could ever get off the ground. James Gibson’s signal contribution was his hypothesis that for every perceivable property of the environment, however subtle, there must be a higher order variable of information, however complex, that specifies it—if only we are clever enough to find them. Such variables are informative about behaviorally relevant properties within the physical and ecological constraints of a species’ niche. Sensory ecology is replete with instructive examples, including weakly electric fish, the narwal’s tusk, and insect flight control. In particular, I elaborate the case of passing through gaps. Optic flow is sufficient to control locomotion around obstacles and through openings. The affordances of the environment, such as gap passability, are specified by action-scaled information. Logically ill-posed problems may thus, on closer inspection, be ecologically well-posed.},
	pages = {20416695211000366},
	number = {2},
	journaltitle = {i-Perception},
	author = {Warren, William H.},
	urldate = {2025-01-04},
	date = {2021-03-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\YFUCPFQZ\\Warren - 2021 - Information Is Where You Find It Perception as an.pdf:application/pdf},
}

@article{warren_visual_1987,
	title = {Visual guidance of walking through apertures: Body-scaled information for affordances},
	volume = {13},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.13.3.371},
	shorttitle = {Visual guidance of walking through apertures},
	abstract = {A necessary condition for visually guided action is that an organism perceive what actions are afforded by a given environmental situation. Warren (1984) proposed that an affordance such as the climbability of a stairway is determined by the fit between properties of the environment and the organism and can be characterized by optimal points, where action is most comfortable or efficient, and critical points, where a phase transition to a new action occurs. Perceiving an affordance, then, implies perceiving the relation between the environment and the observer's own action system. The present study is an extension of this analysis to the visual guidance of walking through apertures. We videotaped large and small subjects walking through apertures of different widths to determine empirically the critical aperture-to-shoulder-width ratio (A/S) marking the transition from frontal walking to body rotation. These results were compared with perceptual judgments of "passability" under static and moving viewing conditions. Finally, we tested the hypothesis that such judgments are based on intrinsic or body-scaled information specifying aperture width as a ratio of the observer's eyeheight. We conclude (a) that the critical point in free walking occurs at A/S = 1.30, (b) that static monocular information is sufficient for judging passability, and (c) that the perception of passability under such conditions is based on body-scaled eyeheight information. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {371--383},
	number = {3},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Warren, William H. and Whang, Suzanne},
	date = {1987},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Spatial Orientation (Perception), Walking, Body Size, Perceptual Motor Coordination},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\YFXV78HD\\doiLanding.html:text/html},
}

@article{hafri_melting_2022,
	title = {Melting ice with your mind: Representational momentum for physical states},
	volume = {33},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/09567976211051744},
	doi = {10.1177/09567976211051744},
	shorttitle = {Melting Ice With Your Mind},
	abstract = {When a log burns, it transforms from a block of wood into a pile of ash. Such state changes are among the most dramatic ways objects change, going beyond mere changes of position or orientation. How does the mind represent changes of state? A foundational result in visual cognition is that memory extrapolates the positions of moving objects—a distortion called representational momentum. Here, five experiments (N = 400 adults) exploited this phenomenon to investigate mental representations in state space. Participants who viewed objects undergoing state changes (e.g., ice melting, logs burning, or grapes shriveling) remembered them as more changed (e.g., more melted, burned, or shriveled) than they actually were. This pattern extended to several types of state changes, went beyond their low-level properties, and even adhered to their natural trajectories in state space. Thus, mental representations of objects actively incorporate how they change—not only in their relation to their environment, but also in their essential qualities.},
	pages = {725--735},
	number = {5},
	journaltitle = {Psychological Science},
	shortjournal = {Psychological Science},
	author = {Hafri, Alon and Boger, Tal and Firestone, Chaz},
	urldate = {2025-01-09},
	date = {2022-05-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications Inc},
	file = {Submitted Version:C\:\\Users\\inkpe\\Zotero\\storage\\7U8DFV75\\Hafri et al. - 2022 - Melting Ice With Your Mind Representational Momen.pdf:application/pdf},
}

@article{mitko_when_2020,
	title = {When it all falls down: the relationship between intuitive physics and spatial cognition},
	volume = {5},
	issn = {2365-7464},
	url = {https://doi.org/10.1186/s41235-020-00224-7},
	doi = {10.1186/s41235-020-00224-7},
	shorttitle = {When it all falls down},
	abstract = {Our intuitive understanding of physical dynamics is crucial in daily life. When we fill a coffee cup, stack items in a refrigerator, or navigate around a slippery patch of ice, we draw on our intuitions about how physical interactions will unfold. What mental machinery underlies our ability to form such inferences? Numerous aspects of cognition must contribute - for example, spatial thinking, temporal prediction, and working memory, to name a few. Is intuitive physics merely the sum of its parts - a collection of these and other related abilities that we apply to physical scenarios as we would to other tasks? Or does physical reasoning rest on something extra - a devoted set of mental resources that takes information from other cognitive systems as inputs? Here, we take a key step in addressing this question by relating individual differences on a physical prediction task to performance on spatial tasks, which may be most likely to account for intuitive physics abilities given the fundamentally spatial nature of physical interactions. To what degree can physical prediction performance be disentangled from spatial thinking? We tested 100 online participants in an “Unstable Towers” task and measures of spatial cognition and working memory. We found a positive relationship between intuitive physics and spatial skills, but there were substantial, reliable individual differences in physical prediction ability that could not be accounted for by spatial measures or working memory. Our findings point toward the separability of intuitive physics from spatial cognition.},
	pages = {24},
	number = {1},
	journaltitle = {Cognitive Research: Principles and Implications},
	shortjournal = {Cognitive Research: Principles and Implications},
	author = {Mitko, Alex and Fischer, Jason},
	urldate = {2025-01-09},
	date = {2020-05-19},
	keywords = {Working memory, Intuitive physics, Mental rotation, Individual differences, Paper folding},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\QEDJZD6F\\Mitko and Fischer - 2020 - When it all falls down the relationship between i.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\SNXF36BU\\s41235-020-00224-7.html:text/html},
}

@article{fleming_getting_2019,
	title = {Getting “fumpered”: Classifying objects by what has been done to them},
	volume = {19},
	rights = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/article.aspx?doi=10.1167/19.4.15},
	doi = {10.1167/19.4.15},
	shorttitle = {Getting “fumpered”},
	pages = {15},
	number = {4},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Fleming, Roland W. and Schmidt, Filipp},
	urldate = {2025-01-09},
	date = {2019-04-05},
	langid = {english},
	file = {Fleming and Schmidt - 2019 - Getting “fumpered” Classifying objects by what ha.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\925KYTG3\\Fleming and Schmidt - 2019 - Getting “fumpered” Classifying objects by what ha.pdf:application/pdf},
}

@article{schmidt_identifying_2018,
	title = {Identifying shape transformations from photographs of real objects},
	volume = {13},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0202115},
	doi = {10.1371/journal.pone.0202115},
	abstract = {An important task of human visual cognition is to make inferences about properties of objects. One such property is an object's causal history: what happened to the object in its past (e.g., “this paper has been folded”). There is relatively little research on whether and how we make such inferences. We took photographs of objects from six different materials (‘wax’, ‘aluminum foil’, ‘gold foil’, ‘chicken wire’, ‘putty’, ‘cardboard’) transformed by one of four shape-altering transformations (‘folded’, ‘bent’, ‘crumpled’, ‘twisted’). By varying execution of transformation and viewpoint, we obtained 30 images of each material/transformation combination (720 images). We asked different groups of participants to: (1) name transformations and materials, (2) rate images with respect to the extent they belonged to each transformation or material class, and (3) classify images into the four transformation classes. Our results show that participants can infer transformations from object shape–with accuracy being modulated by object material. This inference of causal history from observed object shape shows that we can distinguish between intrinsic (material) and extrinsic (transformation) properties of the object. The separation of observed shape features by their causal origin (‘shape scission’) presumably involves both perceptual and cognitive abilities.},
	pages = {e0202115},
	number = {8},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Schmidt, Filipp and Fleming, Roland W.},
	urldate = {2025-01-09},
	date = {2018-08-16},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Sensory perception, Vision, Material properties, Glass, Texture, Aluminum, Principal component analysis, Waxes},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\SV5HJKW2\\Schmidt and Fleming - 2018 - Identifying shape transformations from photographs.pdf:application/pdf},
}

@article{leyton_inferring_1989,
	title = {Inferring causal history from shape},
	volume = {13},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1303_2},
	doi = {10.1207/s15516709cog1303_2},
	abstract = {The shape of an object often seems to tell us something about the object's history; that is, the processes of growth, pushing, stretching, resistance, indentation, and so on, that formed the object. A theory is offered here of how people are able to infer the causal history of natural objects such as clouds, tumors, embryos, leaves, geological formations, and the like. Two inference problems are examined: the first is the inference of causal history from a single shape. It is claimed that this inference consists of two simple and yet powerful rules, based upon the symmetry and curvature structure of the shapes. When these two rules are applied to a large collection of shapes, it is found that the resulting causal histories accord remarkably well with intuition. The second inference problem is the recovery of intervening causal history between two successive shapes that are known to be two stages in the development of the same object. This type of inference is manifested, for example, when a doctor compares two X-rays, taken a month apart, of the same tumor, and is able to conjecture the intervening growth. It is found that a grammar of only six operations is sufficient to generate the later shape from the earlier one via psychologically meaningful process-extrapolations. Finally, a basic heuristic by which human beings seem to infer complex temporal relations between different processes in the past is proposed, and investigated in detail.},
	pages = {357--387},
	number = {3},
	journaltitle = {Cognitive Science},
	author = {Leyton, Michael},
	urldate = {2025-01-10},
	date = {1989},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog1303\_2},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\MU8TKT98\\s15516709cog1303_2.html:text/html},
}

@article{beller_looking_2022,
	title = {Looking into the past: Eye-tracking mental simulation in physical inference},
	volume = {44},
	url = {https://escholarship.org/uc/item/7gk617ss},
	shorttitle = {Looking into the past},
	abstract = {Mental simulation is a powerful cognitive capacity that underlies people's ability to draw inferences about what happened in the past from the present. Recent work suggests that eye-tracking can be used as a window through which one can study the process of mental simulation in intuitive physics tasks. In our experiment, participants have to figure out in which of three holes a ball was dropped in a virtual Plinko box. We develop a computational model of human intuitive physical reasoning in Plinko that runs repeated simulations in a noisy physics simulator in order to infer in which hole the ball was dropped. We evaluate our model's behavior against multiple human data signals: trial judgments, response times, and eye-movement data. We find that a model that sequentially samples simulations while balancing uncertainty and reward best explains the patterns of participant behavior we observe in these three signals.},
	number = {44},
	journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Beller, Ari and Xu, Yingchen and Linderman, Scott and Gerstenberg, Tobias},
	urldate = {2025-01-12},
	date = {2022},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\8Y5WWNVV\\Beller et al. - 2022 - Looking into the past Eye-tracking mental simulat.pdf:application/pdf},
}

@article{mitko_dedicated_2024,
	title = {A dedicated mental resource for intuitive physics},
	volume = {27},
	issn = {2589-0042},
	url = {https://www.cell.com/iscience/abstract/S2589-0042(23)02684-6},
	doi = {10.1016/j.isci.2023.108607},
	number = {1},
	journaltitle = {{iScience}},
	shortjournal = {{iScience}},
	author = {Mitko, Alex and Navarro-Cebrián, Ana and Cormiea, Sarah and Fischer, Jason},
	urldate = {2025-01-27},
	date = {2024-01-19},
	pmid = {38222113},
	note = {Publisher: Elsevier},
	keywords = {Cognitive neuroscience, Physics, Neuroscience},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\W74V452A\\Mitko et al. - 2024 - A dedicated mental resource for intuitive physics.pdf:application/pdf},
}

@article{rolfs_visual_2013,
	title = {Visual adaptation of the perception of causality},
	volume = {23},
	issn = {0960-9822},
	url = {https://www.sciencedirect.com/science/article/pii/S096098221201490X},
	doi = {10.1016/j.cub.2012.12.017},
	abstract = {We easily recover the causal properties of visual events, enabling us to understand and predict changes in the physical world. We see a tennis racket hitting a ball and sense that it caused the ball to fly over the net; we may also have an eerie but equally compelling experience of causality if the streetlights turn on just as we slam our car’s door. Both perceptual [1] and cognitive [2] processes have been proposed to explain these spontaneous inferences, but without decisive evidence one way or the other, the question remains wide open [3, 4, 5, 6, 7, 8]. Here, we address this long-standing debate using visual adaptation—a powerful tool to uncover neural populations that specialize in the analysis of specific visual features [9, 10, 11, 12]. After prolonged viewing of causal collision events called “launches” [1], subsequently viewed events were judged more often as noncausal. These negative aftereffects of exposure to collisions are spatially localized in retinotopic coordinates, the reference frame shared by the retina and visual cortex. They are not explained by adaptation to other stimulus features and reveal visual routines in retinotopic cortex that detect and adapt to cause and effect in simple collision stimuli.},
	pages = {250--254},
	number = {3},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Rolfs, Martin and Dambacher, Michael and Cavanagh, Patrick},
	urldate = {2025-02-02},
	date = {2013-02-04},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\8SRMKQ8N\\S096098221201490X.html:text/html;Submitted Version:C\:\\Users\\inkpe\\Zotero\\storage\\8Y3H2X7S\\Rolfs et al. - 2013 - Visual Adaptation of the Perception of Causality.pdf:application/pdf},
}

@article{watkins_constructive_2008,
	title = {Constructive and unconstructive repetitive thought},
	volume = {134},
	issn = {0033-2909},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2672052/},
	doi = {10.1037/0033-2909.134.2.163},
	abstract = {The author reviews research showing that repetitive thought ({RT}) can have
                    constructive or unconstructive consequences. The main unconstructive
                    consequences of {RT} are (a) depression, (b) anxiety, and (c) difficulties in
                    physical health. The main constructive consequences of {RT} are (a) recovery from
                    upsetting and traumatic events, (b) adaptive preparation and anticipatory
                    planning, (c) recovery from depression, and (d) uptake of health-promoting
                    behaviors. Several potential principles accounting for these distinct
                    consequences of {RT} are identified within this review: (a) the valence of thought
                    content, (b) the intrapersonal and situational context in which {RT} occurs, and
                    (c) the level of construal (abstract vs. concrete processing) adopted during {RT}.
                    Of the existing models of {RT}, it is proposed that an elaborated version of the
                    control theory account provides the best theoretical framework to account for
                    its distinct consequences.},
	pages = {163--206},
	number = {2},
	journaltitle = {Psychological Bulletin},
	shortjournal = {Psychological Bulletin},
	author = {Watkins, Edward R.},
	urldate = {2025-02-02},
	date = {2008-03},
	pmid = {18298268},
	pmcid = {PMC2672052},
	file = {PubMed Central Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\GVQC8562\\Watkins - 2008 - Constructive and Unconstructive Repetitive Thought.pdf:application/pdf},
}

@article{kurby_segmentation_2008,
	title = {Segmentation in the perception and memory of events},
	volume = {12},
	issn = {1364-6613},
	doi = {10.1016/j.tics.2007.11.004},
	abstract = {People make sense of continuous streams of observed behavior in part by segmenting them into events. Event segmentation seems to be an ongoing component of everyday perception. Events are segmented simultaneously at multiple timescales, and are grouped hierarchically. Activity in brain regions including the posterior temporal and parietal cortex and lateral frontal cortex increases transiently at event boundaries. The parsing of ongoing activity into events is related to the updating of working memory, to the contents of long-term memory, and to the learning of new procedures. Event segmentation might arise as a side effect of an adaptive mechanism that integrates information over the recent past to improve predictions about the near future.},
	pages = {72--79},
	number = {2},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Kurby, Christopher A. and Zacks, Jeffrey M.},
	date = {2008-02},
	pmid = {18178125},
	pmcid = {PMC2263140},
	keywords = {Memory, Humans, Social Perception, Brain, Magnetic Resonance Imaging, Automatism, Electroencephalography, Life Change Events},
	file = {Accepted Version:C\:\\Users\\inkpe\\Zotero\\storage\\9D5JIDVT\\Kurby and Zacks - 2008 - Segmentation in the perception and memory of event.pdf:application/pdf},
}

@article{weigelt_finding_2019,
	title = {Finding peace of mind when there still is so much left undone—A diary study on how job stress, competence need satisfaction, and proactive work behavior contribute to work-related rumination during the weekend},
	volume = {24},
	issn = {1939-1307},
	doi = {10.1037/ocp0000117},
	abstract = {Unfinished work tasks have been identified as a significant job-related stressor in recent occupational stress research. Extending this research, we examine how and when not finishing one’s tasks by the end of the work week affects work-related rumination at the weekend. Drawing on control theory, we examined competence need satisfaction as a mediating mechanism that links unfinished tasks at the end of the work week to work-related rumination at the weekend. Furthermore, we scrutinized whether proactive work behavior within the work week may neutralize the detrimental effects of unfinished tasks on competence need satisfaction and rumination. Using diary methodology, we collected weekly observations from 58 employees at the beginning and at the end of the work week over a period of 12 consecutive weeks, yielding 377 matched observations. Multilevel modeling analyses provided evidence for the assumed indirect effect at the intraindividual level. Higher levels of unfinished tasks were associated with lower levels of competence need satisfaction during the weekend. Competence need satisfaction, in turn, was negatively related to work-related rumination. Proactive work behavior attenuated the detrimental effects of unfinished tasks on competence need satisfaction and rumination at the weekend. These results imply that proactive work behavior facilitates switching off mentally during the weekend as it may restore competence need satisfaction in the face of unfinished tasks. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
	pages = {373--386},
	number = {3},
	journaltitle = {Journal of Occupational Health Psychology},
	author = {Weigelt, Oliver and Syrek, Christine J. and Schmitt, Antje and Urbach, Tina},
	date = {2019},
	note = {Place: {US}
Publisher: Educational Publishing Foundation},
	keywords = {Test Construction, Job Performance, Diary Measure, Job Satisfaction, Need Satisfaction, Occupational Stress, Professional Competence},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\GH943IHF\\Weigelt et al. - 2019 - Finding peace of mind when there still is so much .pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\ET2S64FX\\2018-22653-001.html:text/html},
}

@article{ruan_one-away_2024,
	title = {The one-away effect: The pursuit of mere completion},
	volume = {50},
	issn = {1537-5277},
	doi = {10.1093/jcr/ucad030},
	shorttitle = {The one-away effect},
	abstract = {A series of controlled studies found that consumers counter-normatively prefer something nearly complete over something complete. We call this phenomenon the “one-away effect” because we find that when consumers are, for example, one stamp away from completing a punch card loyalty program, they value the card more than a completed card. This is because their valuation of the one-away card is influenced by their anticipation of merely completing the card, which generates its own utility, apart from the card’s end-reward (a free coffee). To wit, the prospective utility of performing the final action that fulfills completion increases consumers’ valuation of the one-away card. Our findings suggest that consumers are motivated to complete goals, tasks, and sets not only to obtain their end-rewards, but also because merely completing things is intrinsically motivating and can be a goal in and of itself. We discuss the theoretical and practical implications of the one-away effect, as well as the general notion of mere completion. ({PsycInfo} Database Record (c) 2024 {APA}, all rights reserved)},
	pages = {945--961},
	number = {5},
	journaltitle = {Journal of Consumer Research},
	author = {Ruan, Bowen and Polman, Evan and Tanner, Robin J.},
	date = {2024},
	note = {Place: United Kingdom
Publisher: Oxford University Press},
	keywords = {Goals, Consumer Behavior, Loyalty},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\73XZ65AI\\2024-51100-005.html:text/html},
}

@article{radvansky_across_2012,
	title = {Across the event horizon},
	volume = {21},
	issn = {1467-8721},
	doi = {10.1177/0963721412451274},
	abstract = {The stream of action in life, virtual environments, film, and narratives is parsed into events. This parsing has consequences for memory. The transition from one event to another can impede memory in some ways but improve it in others. Whether impairment or improvement occurs depends on the nature of the information and how it is later remembered. The Event Horizon Model of comprehension and memory goes beyond more traditional accounts of the influence of context on cognition to explain these phenomena. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {269--272},
	number = {4},
	journaltitle = {Current Directions in Psychological Science},
	author = {Radvansky, Gabriel A.},
	date = {2012},
	note = {Place: {US}
Publisher: Sage Publications},
	keywords = {Memory, Cognition, Models, Retention, Comprehension},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\28WP3LEC\\2012-20348-011.html:text/html},
}

@article{ongchoco_visual_2023,
	title = {Visual event boundaries restrict anchoring effects in decision-making},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2303883120},
	doi = {10.1073/pnas.2303883120},
	abstract = {Research on higher-level thought has revealed many principles of reasoning and decision-making but has rarely made contact with how we perceive the world in the first place. Here we show how a lower-level property of perception—the spontaneous and task-irrelevant segmentation of continuous visual stimulation into discrete events—can restrict one of the most notorious biases in decision-making: numerical anchoring. Subjects walked down a long room in an immersive three dimensional (3D) animation and then made a numerical judgment (e.g., of how much a suitcase is worth, or of how many hours of community service a minor crime deserved). Critically, some subjects passed through a doorway (a visual event boundary) during their virtual walk, while others did not—equating time, distance traveled, and visual complexity. The anchoring manipulation was especially innocuous, not appearing to be part of the experiment at all. Before the online trial began, subjects reported the two-digit numerical value from a visually distorted “{CAPTCHA}” (“to verify that you are human”)—where this task-irrelevant anchor was either low (e.g., 29) or high (e.g., 92). With no doorway, we observed reliable anchoring effects: Higher {CAPTCHA} values produced higher estimates. With the doorway, however, such effects were attenuated or even eliminated. This generalized across tasks involving item valuations, factual questions, and legal judgments and in tests of both incidental and explicit anchoring. This demonstrates how spontaneous visual event segmentation can have profound consequences for higher-level thought.},
	pages = {e2303883120},
	number = {44},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Ongchoco, Joan Danielle K. and Walter-Terrill, Robert and Scholl, Brian J.},
	urldate = {2025-02-02},
	date = {2023-10-31},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\PQFU7PNB\\Ongchoco et al. - 2023 - Visual event boundaries restrict anchoring effects.pdf:application/pdf},
}

@article{macleod_zeigarnik_2020,
	title = {Zeigarnik and von Restorff: The memory effects and the stories behind them},
	volume = {48},
	issn = {1532-5946},
	doi = {10.3758/s13421-020-01033-5},
	shorttitle = {Zeigarnik and von Restorff},
	abstract = {Two of the best known eponymous phenomena in memory research were carried out as dissertations in the same era at the same university, each supervised by an influential researcher working within the Gestalt framework. Both examined the influence of unexpected events on memory. Bluma Zeigarnik (Psychologische Forschung, 9, 1–85, 1927) first reported that memory is better for interrupted tasks than for completed tasks, a phenomenon long known as the Zeigarnik effect. Hedwig von Restorff (Psychologische Forschung, 18, 299–342, 1933) first reported that memory is better for isolated than for non-isolated pieces of information, a phenomenon long known as the von Restorff effect. In this article, I present: (1) a biographical sketch of the researcher behind each phenomenon, (2) a description of their dissertation research, and (3) an evaluation of the current status of each phenomenon. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {1073--1088},
	number = {6},
	journaltitle = {Memory \& Cognition},
	author = {{MacLeod}, Colin M.},
	date = {2020},
	note = {Place: Germany
Publisher: Springer},
	keywords = {Memory, Recall (Learning)},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\DNJGW65Y\\MacLeod - 2020 - Zeigarnik and von Restorff The memory effects and.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\A38AI323\\2020-26715-001.html:text/html},
}

@article{kominsky_retinotopic_2020,
	title = {Retinotopic adaptation reveals distinct categories of causal perception},
	volume = {203},
	issn = {1873-7838},
	doi = {10.1016/j.cognition.2020.104339},
	abstract = {We can perceive not only low-level features of events such as color and motion, but also seemingly higher-level properties such as causality. A prototypical example of causal perception is the ‘launching effect’: one object (A) moves toward a stationary second object (B) until they are adjacent, at which point A stops and B starts moving in the same direction. Beyond these motions themselves—and regardless of any higher-level beliefs—this display induces a vivid visual impression of causality, wherein A is seen to cause B's motion. Do such percepts reflect a unitary category of visual processing, or might there be multiple distinct forms of causal perception? While launching is often simply equated with causal perception, researchers have sometimes described other phenomena such as ‘triggering’ (in which B moves faster than A) and ‘entraining’ (in which A continues to move alongside B). We used psychophysical methods to determine whether these labels really carve visual processing at its joints, and how putatively different forms of causal perception relate to each other. Previous research demonstrated retinotopically specific adaptation to causality: exposure to causal launching makes subsequent ambiguous events in that same location more likely to be seen as non-causal ‘passing’. Here, after replicating this effect, we show that exposure to triggering also yields retinotopically specific adaptation for subsequent ambiguous launching displays, but that exposure to entraining does not. Collectively, these results reveal that visual processing distinguishes some (but not all) types of causal interactions. ({PsycInfo} Database Record (c) 2021 {APA}, all rights reserved)},
	journaltitle = {Cognition},
	author = {Kominsky, Jonathan F. and Scholl, Brian J.},
	date = {2020},
	note = {Place: Netherlands
Publisher: Elsevier Science},
	keywords = {Visual Perception, Causality, Psychophysics, Visual Displays, Motion Perception, Adaptation, Form and Shape Perception, Color Perception},
	file = {Accepted Version:C\:\\Users\\inkpe\\Zotero\\storage\\RDRYUG94\\Kominsky and Scholl - 2020 - Retinotopic adaptation reveals distinct categories.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\9IMTNXDT\\2020-64550-001.html:text/html},
}

@article{gao_wolfpack_2010,
	title = {The wolfpack effect: Perception of animacy irresistibly influences interactive behavior},
	volume = {21},
	issn = {1467-9280},
	doi = {10.1177/0956797610388814},
	shorttitle = {The wolfpack effect},
	abstract = {Imagine a pack of predators stalking their prey. The predators may not always move directly toward their target (e.g., when circling around it), but they may be consistently facing toward it. The human visual system appears to be extremely sensitive to such situations, even in displays involving simple shapes. We demonstrate this by introducing the wolfpack effect, which is found when several randomly moving, oriented shapes (darts, or discs with “eyes”) consistently point toward a moving disc. Despite the randomness of the shapes’ movement, they seem to interact with the disc—as if they are collectively pursuing it. This impairs performance in interactive tasks (including detection of actual pursuit), and observers selectively avoid such shapes when moving a disc through the display themselves. These and other results reveal that the wolfpack effect is a novel “social” cue to perceived animacy. And, whereas previous work has focused on the causes of perceived animacy, these results demonstrate its effects, showing how it irresistibly and implicitly shapes visual performance and interactive behavior. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1845--1853},
	number = {12},
	journaltitle = {Psychological Science},
	author = {Gao, Tao and {McCarthy}, Gregory and Scholl, Brian J.},
	date = {2010},
	note = {Place: {US}
Publisher: Sage Publications},
	keywords = {Visual Perception, Social Perception, Social Behavior, Form and Shape Perception},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\ZTCMN8DQ\\2010-26415-018.html:text/html},
}

@article{freeman_dont_2010,
	title = {Don't interrupt me! Task interruption depletes the self’s limited resources},
	volume = {34},
	issn = {1573-6644},
	doi = {10.1007/s11031-010-9169-6},
	abstract = {It is a common occurrence in daily life to be interrupted prior to completing a task. Such interruptions may have deleterious effects for limited self-resources, especially if they occur just prior to task completion. This hypothesis was tested in three experiments. In the first two, participants initially engaged in a card sorting task, and then subsequently performed a self-control task. In Experiment 3, participants first engaged in a word search task and then worked on an executive function task. In all instances, participants who were interrupted just prior to attaining their goal of completing the initial task, but not those who were stopped earlier in the task or who were allowed to finish, showed evidence of impairment on the subsequent measures. The findings suggest that the desire to pursue a goal increases as goal attainment draws nearer, and that the amount of self-control needed to stop working on a task is modified by situational variables such as goal distance. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {230--241},
	number = {3},
	journaltitle = {Motivation and Emotion},
	author = {Freeman, Nicholas and Muraven, Mark},
	date = {2010},
	note = {Place: Germany
Publisher: Springer},
	keywords = {Task Complexity, Executive Function, Cognitive Ability, Task Analysis},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\8BF8RKWR\\2010-17637-002.html:text/html},
}

@article{di_paula_self-esteem_2002,
	title = {Self-esteem and persistence in the face of failure},
	volume = {83},
	issn = {1939-1315},
	doi = {10.1037/0022-3514.83.3.711},
	abstract = {In 2 studies, the authors examined self-esteem, persistence, and rumination in the face of failure. Study 1 manipulated degree of failure and availability of goal alternatives. When an alternative was available, high self-esteem ({HSE}) participants persisted more than low self-esteem ({LSE}) participants after a single failure, but less after repeated failure. When no alternative was available, no self-esteem differences in persistence emerged. {LSE} participants ruminated more than {HSE} participants. Study 2 examined persistence and rumination for 10 personal goals across an academic year. {HSE} participants were better calibrated (higher within-subject correlations between perceived progress and persistence across goals), had higher overall levels of persistence, higher grade point averages, and lower levels of rumination than {LSE} participants. Although traditional views that emphasize the tenacious persistence of {HSE} individuals need revision, {HSE} people appear more effective in self-regulating goal-directed behavior. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {711--724},
	number = {3},
	journaltitle = {Journal of Personality and Social Psychology},
	author = {Di Paula, Adam and Campbell, Jennifer D.},
	date = {2002},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Goals, Persistence, Rumination (Cognitive Process), Failure, Self-Esteem, Self-Management},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\63UQ6R7U\\2002-17813-015.html:text/html;Submitted Version:C\:\\Users\\inkpe\\Zotero\\storage\\6IN49XYS\\Di Paula and Campbell - 2002 - Self-esteem and persistence in the face of failure.pdf:application/pdf},
}

@article{converse_value_2023,
	title = {The value of mere completion},
	volume = {152},
	issn = {1939-2222},
	doi = {10.1037/xge0001434},
	abstract = {The positivity of goal completion is reinforced through everyday experiences of social praise and instrumental reward. Here we investigated whether, in line with this self-regulatory emphasis, people value completion opportunities in and of themselves. Across six experiments we found that adding an arbitrary completion opportunity to a lower-reward task increased the likelihood that participants would choose to work on that task over a higher-reward alternative that did not offer a completion opportunity. This occurred for extrinsic reward tradeoffs (Experiments 1, 3, 4, and 5) and intrinsic reward tradeoffs (Experiments 2 and 6), and it persisted even when participants explicitly noted the rewards of each task (Experiment 3). We sought but did not find evidence that the tendency is moderated by participants’ stable or momentary level of concern with monitoring multiple responsibilities (Experiments 4 and 5, respectively). We did find that the opportunity to complete the final step in a sequence was particularly attractive: Setting the lower-reward task closer to completion (but with completion still out of reach) did increase its choice share, but setting the lower-reward task with completion distinctly in reach increased its choice share even more (Experiment 6). Together, the experiments imply that people sometimes behave as if they value completion itself. In everyday life, the allure of mere completion may influence the tradeoffs people make when prioritizing their goals. ({PsycInfo} Database Record (c) 2024 {APA}, all rights reserved)},
	pages = {3021--3036},
	number = {11},
	journaltitle = {Journal of Experimental Psychology: General},
	author = {Converse, Benjamin A. and Tsang, Shelly and Hennecke, Marie},
	date = {2023},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Decision Making, Rewards, Goals, Motivation, Self-Regulation},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\CIWGIFP9\\2023-80180-001.html:text/html},
}

@article{baddeley_zeigarnik-like_1963,
	title = {A Zeigarnik-like effect in the recall of anagram solutions},
	volume = {15},
	issn = {0033-555X},
	doi = {10.1080/17470216308416553},
	abstract = {Ss were asked to solve a series of 12 anagram problems. For each of these they were allowed 1 min. and if they did not solve it in this time they were told the solution. When asked to recall the solution words at the end of the series, Ss remembered items they had failed to complete almost twice as often as those they had solved. It is suggested that this phenomenon is analogous to the Zeigarnik effect, but that it has the advantage of occurring in conditions which are easy to specify and control. ({PsycInfo} Database Record (c) 2025 {APA}, all rights reserved)},
	pages = {63--64},
	number = {1},
	journaltitle = {The Quarterly Journal of Experimental Psychology},
	author = {Baddeley, A. D.},
	date = {1963},
	note = {Place: United Kingdom
Publisher: Taylor \& Francis},
	keywords = {Recall (Learning), Problem Solving, Anagrams},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\CPRUKWBX\\1963-07607-001.html:text/html},
}

@article{atkinson_achievement_1953,
	title = {The achievement motive and recall of interrupted and completed tasks},
	volume = {46},
	issn = {0022-1015},
	doi = {10.1037/h0057286},
	abstract = {Divided Ss into three groups on an interruption-of-tasks experiment on the basis of instructions presumed to vary the probability that the Ss would perceive completion as personal accomplishment and incompletion as personal failure. Each S was also classified high or low in motivation to achieve based on a thematic apperception measure of the need to achieve. Found that recall of incompletions and the tendency to show the Zeigarnik effect increased for Ss high in achievement need as instructions increased the probability that completion and incompletion would be perceived as success and failure while just the opposite trend occurred for Ss low in achievement need. An attempt is made to reconcile the contradictory results relating to the Zeigarnik effect. 22 references. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {381--390},
	number = {6},
	journaltitle = {Journal of Experimental Psychology},
	author = {Atkinson, John W.},
	date = {1953},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Recall (Learning), Probability, Achievement, Teaching, Thematic Apperception Test},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\W53HSY9E\\1954-07108-001.html:text/html},
}

@article{scholl_perceptual_2024,
	title = {Perceptual (roots of) core knowledge},
	volume = {47},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/perceptual-roots-of-core-knowledge/B0639C443A2499D8190F1ADE4C018B6F},
	doi = {10.1017/S0140525X23003023},
	abstract = {Some core knowledge may be rooted in – or even identical to – well-characterized mechanisms of mid-level visual perception and attention. In the decades since it was first proposed, this possibility has inspired (and has been supported by) several discoveries in both infant cognition and adult perception, but it also faces several challenges. To what degree does What Babies Know reflect how babies see and attend?},
	pages = {e140},
	journaltitle = {Behavioral and Brain Sciences},
	author = {Scholl, Brian J.},
	urldate = {2025-02-16},
	date = {2024-01},
	langid = {english},
}

@article{spelke_core_2007,
	title = {Core knowledge},
	volume = {10},
	rights = {© 2007 The Authors. Journal compilation © 2007 Blackwell Publishing Ltd},
	issn = {1467-7687},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-7687.2007.00569.x},
	doi = {10.1111/j.1467-7687.2007.00569.x},
	abstract = {Human cognition is founded, in part, on four systems for representing objects, actions, number, and space. It may be based, as well, on a fifth system for representing social partners. Each system has deep roots in human phylogeny and ontogeny, and it guides and shapes the mental lives of adults. Converging research on human infants, non-human primates, children and adults in diverse cultures can aid both understanding of these systems and attempts to overcome their limits.},
	pages = {89--96},
	number = {1},
	journaltitle = {Developmental Science},
	author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
	urldate = {2025-02-16},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-7687.2007.00569.x},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\HZSDYYY3\\j.1467-7687.2007.00569.html:text/html},
}

@book{spelke_what_2022,
	location = {New York, {NY}, {US}},
	title = {What babies know: Core knowledge and composition, Vol. 1},
	isbn = {978-0-19-061824-7},
	series = {What babies know: Core knowledge and composition, Vol. 1},
	shorttitle = {What babies know},
	abstract = {Human infants and young children face a formidable learning challenge. Equipped only with the universal capacities of our species, they must master all the common sense knowledge required for life in the society and culture into which they were born. Strikingly, children accomplish a good part of this task without being taught. Infants and children learn not only in families with rich adult-child interactions but also in communities in which young children spend most of their time with peers. Even in cultures like ours, where parents widely believe that their children should be stimulated and instructed as well as nurtured and loved, infants learn all sorts of things that adults do not intend to teach them. Infants' learning rests on a set of cognitive systems that we share with animals and that evolved over hundreds of millions of years. Humans have evolved one set of cognitive capacities that are unique to us: capacities to learn a natural language and to use that language for thinking, for communicating, and for grasping the thoughts of others. Drawing on more than 40 years of research, this book introduces core systems such as infants' visual perception, objects; places; number; core knowledge; forms; agents; core social cognition; and language. The author shares these insights by distilling the findings from research in developmental, comparative, and cognitive psychology, with excursions into studies of animal cognition in psychology and in systems and cognitive neuroscience, and studies in the computational cognitive sciences. Weaving across these disciplines, the author paints a picture of what young infants know, and what they quickly come to learn, about objects, places, numbers, geometry, and people's actions, social engagements, and mental states. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
	pagetotal = {xxviii, 532},
	publisher = {Oxford University Press},
	author = {Spelke, Elizabeth S.},
	date = {2022},
	doi = {10.1093/oso/9780190618247.001.0001},
	note = {Pages: xxviii, 532},
	keywords = {Learning, Cognition, Language, Knowledge (General), Culture (Anthropological), Infant Development, Thinking},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\I8BAMWG9\\2023-21045-000.html:text/html},
}

@article{spelke_precis_2024,
	title = {Précis of \textit{What Babies Know}},
	volume = {47},
	issn = {0140-525X, 1469-1825},
	url = {https://www.cambridge.org/core/product/identifier/S0140525X23002443/type/journal_article},
	doi = {10.1017/S0140525X23002443},
	abstract = {Where does human knowledge begin? Research on human infants, children, adults, and nonhuman animals, using diverse methods from the cognitive, brain, and computational sciences, provides evidence for six early emerging, domain-specific systems of core knowledge. These automatic, unconscious systems are situated between perceptual systems and systems of explicit concepts and beliefs. They emerge early in infancy, guide children’s learning, and function throughout life.},
	pages = {e120},
	journaltitle = {Behavioral and Brain Sciences},
	shortjournal = {Behav Brain Sci},
	author = {Spelke, Elizabeth S.},
	urldate = {2025-02-16},
	date = {2024},
	langid = {english},
	file = {Spelke - 2024 - Précis of What Babies Know.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\NACLHJCF\\Spelke - 2024 - Précis of What Babies Know.pdf:application/pdf},
}

@incollection{turk-browne_statistical_2012,
	location = {New York, {NY}},
	title = {Statistical learning and its consequences},
	isbn = {978-1-4614-4794-8},
	url = {https://doi.org/10.1007/978-1-4614-4794-8_6},
	abstract = {Statistical learning refers to an unconscious cognitive process in which repeated patterns, or regularities, are extracted from the sensory environment. In this chapter, I describe what is currently known about statistical learning. First, I classify types of regularities that exist in the visual environment. Second, I introduce a family of experimental paradigms that have been used to study statistical learning in the laboratory. Third, I review a series of behavioral and functional neuroimaging studies that seek to uncover the underlying nature of statistical learning. Finally, I consider ways in which statistical learning may be important for perception, attention, and visual search. The goals of this chapter are thus to highlight the prevalence of regularities, to explain how they are extracted by the mind and brain, and to suggest that the resulting knowledge has widespread consequences for other aspects of cognition.},
	pages = {117--146},
	booktitle = {The Influence of Attention, Learning, and Motivation on Visual Search},
	publisher = {Springer},
	author = {Turk-Browne, Nicholas B.},
	editor = {Dodd, Michael D. and Flowers, John H.},
	urldate = {2025-02-16},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-1-4614-4794-8_6},
	keywords = {Perception, Selective attention, {fMRI}, Generalization, Memory systems, Regularities},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\T5J64DI7\\Turk-Browne - 2012 - Statistical Learning and Its Consequences.pdf:application/pdf},
}

@article{arnell_attentional_2011,
	title = {Attentional blink and repetition blindness},
	volume = {2},
	rights = {Copyright © 2010 John Wiley \& Sons, Ltd.},
	issn = {1939-5086},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.129},
	doi = {10.1002/wcs.129},
	abstract = {When two masked, to-be-attended targets are presented within half a second of each other, report accuracy for the second target (T2) is impaired relative to when the two targets are presented farther apart in time or relative to when the first target (T1) can be ignored. This effect is known as the attentional blink ({AB}). An additional T2 accuracy deficit is observed if T1 and T2 are identical or highly similar on a task-relevant dimension. This effect is known as repetition blindness ({RB}). For both {AB} and {RB}, targets are typically imbedded in rapid serial visual presentation ({RSVP}) streams and the dual-task attention cost lasts approximately half a second. Given the high degree of superficial similarity, {AB} and {RB} are often considered to be related phenomena. Although research thus far has suggested that both phenomena reflect limits of the attentional system and how attention is allocated when needing to organize stimuli for entrance into awareness, these two phenomena are dissociable; {RB} is not simply an enhanced {AB}. Furthermore, investigations of {AB} and {RB} have taken quite different courses over the last two decades. The {AB} has been investigated extensively with a variety of experimental, behavioral, neurophysiological, and clinical approaches, and has become widely used as a paradigm of convenience with which to study other effects. In contrast, studies of {RB} have tended to manipulate the nature of the target information to understand the level of representation that supports {RB}. {WIREs} Cogni Sci 2011 2 336–344 {DOI}: 10.1002/wcs.129 This article is categorized under: Psychology {\textgreater} Attention},
	pages = {336--344},
	number = {3},
	journaltitle = {{WIREs} Cognitive Science},
	author = {Arnell, Karen M. and Shapiro, Kimron L.},
	urldate = {2025-02-16},
	date = {2011},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcs.129},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\4F9S6498\\wcs.html:text/html},
}

@book{gibson_ecological_1979,
	location = {Boston, {MA}, {US}},
	title = {The ecological approach to visual perception},
	isbn = {978-0-395-27049-3},
	series = {The ecological approach to visual perception},
	pagetotal = {xiv, 332},
	publisher = {Houghton, Mifflin and Company},
	author = {Gibson, James Jerome},
	date = {1979},
	note = {Pages: xiv, 332},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\M4Z9FTDI\\2003-00063-000.html:text/html},
}

@article{wong_unconscious_2024,
	title = {Unconscious intuitive physics: Prioritized breakthrough into visual awareness for physically unstable block towers},
	volume = {24},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.24.10.452},
	doi = {10.1167/jov.24.10.452},
	shorttitle = {Unconscious intuitive physics},
	abstract = {A central goal of perception and cognition is to predict how events in our local environments are likely to unfold: what is about to happen? And of course some of the most reliable ways of answering this question involve considering the regularities of physics. Accordingly, a great deal of recent research throughout cognitive science has explored the nature of ‘intuitive physics’. The vast majority of this work, however, has involved higher-level reasoning, rather than seeing itself—as when people are asked to deliberate about how objects might move, in response to explicit questions (“Will it fall?”). Here, in contrast, we ask whether the apprehension of certain physical properties of scenes might also occur *unconsciously*, during simple passive viewing. Moreover, we ask whether certain physical regularities are not just processed, but also visually *prioritized*—as when a tower is about to fall. Observers viewed block towers—some stable, some unstable—defined in terms of whether they would collapse as a result of external physical forces (such as gravity) alone. We used continuous flash suppression ({CFS}) to render the towers initially invisible: observers viewed them monocularly through a mirror haploscope, while a dynamic Mondrian mask was presented to their other eye. We then measured how long towers took to break through this interocular suppression, as observers indicated when they became visually aware of anything other than the mask. The results were clear and striking: unstable towers broke into visual awareness faster than stable towers. And this held even while controlling for other visual properties—e.g. while contrasting pairs of stable vs. unstable towers sharing the same convex hull, and differing only in the horizontal placement of a single block. This work shows how physical instability is both detected and prioritized, not only during overt deliberation, but also in unconscious visual processing.},
	pages = {452},
	number = {10},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Wong, Kimberly W. and Shah, Aalap and Scholl, Brian},
	urldate = {2025-02-19},
	date = {2024-09-15},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\4BFEVLPX\\article.html:text/html},
}

@article{ongchoco_unfinishedness_2023,
	title = {The “unfinishedness” of dynamic events is spontaneously extracted in visual processing: A new ‘Visual Zeigarnik Effect’},
	volume = {23},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.23.9.4974},
	doi = {10.1167/jov.23.9.4974},
	shorttitle = {The “unfinishedness” of dynamic events is spontaneously extracted in visual processing},
	abstract = {The events that occupy our thoughts in an especially persistent way are often those that are *unfinished* — half-written papers, unfolded laundry, and items not yet crossed off from to-do lists. And this factor has also been emphasized in work within higher-level cognition, as in the “Zeigarnik effect”: when people carry out various tasks, but some are never finished due to extrinsic interruptions, memory tends to be better for those tasks that were unfinished. But just how foundational is this sort of “unfinishedness” in mental life? Might such unfinishedness be spontaneously extracted and prioritized even in lower-level visual processing? To explore this, we had observers watch animations in which a dot moved through a maze, starting at one disc (the ‘startpoint’) and moving toward another disc (the ‘endpoint’). We tested the fidelity of visual memory by having probes (colored squares) appear briefly along the dot’s path; after the dot finished moving, observers simply had to indicate where the probes had appeared. On ‘Completed’ trials, the motion ended when the dot reached the endpoint, but on ‘Unfinished’ trials, the motion ended shortly *before* the dot reached the endpoint. Although this manipulation was entirely task-irrelevant, it nevertheless had a powerful influence on visual memory: observers placed probes much closer to their correct locations on Unfinished trials. This same pattern held across several different experiments, even while carefully controlling for various lower-level properties of the displays (such as the speed and duration of the dot’s motion). And the effect also generalized across different types of displays (e.g. also replicating when the moving dot left a visible trace). This new type of *Visual Zeigarnik Effect* suggests that the unfinishedness of events is not just a matter of higher-level thought and motivation, but can also be extracted as a part of visual perception itself.},
	pages = {4974},
	number = {9},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Ongchoco, Joan Danielle K. and Wong, Kimberly W. and Scholl, Brian},
	urldate = {2025-02-19},
	date = {2023-08-01},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\XDGHK2S2\\article.html:text/html},
}

@article{baillargeon_development_1992,
	title = {The development of young infants' intuitions about support},
	volume = {1},
	rights = {Copyright © 1992 John Wiley \& Sons, Ltd},
	issn = {1099-0917},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/edp.2430010203},
	doi = {10.1002/edp.2430010203},
	abstract = {Previous research has shown that 3-month-old infants, like adults, expect a box to be stable when it is in full contact with a platform, and to fall when it loses all contact with the platform. Do young infants also have expectations about what should happen when the box is only in partial contact with the platform? The present research was designed to address this question. In Experiment 1, 6.5-month-old infants saw two test events: a full-contact and a partial-contact test event. In both events, the infants watched the extended finger of a gloved hand push a box along the top of a platform. In the full-contact event, the box was pushed until its leading edge reached the end of the platform. In the partial-contact event, the box was pushed until only 15\% or 70\% of its bottom surface remained on the platform. The infants looked reliably longer at the partial-than at the full-contact event when 15\%, but not 70\%, of the box rested on the platform. These results suggested that the infants were able to judge how much contact was needed between the box and the platform for the box to be stable. A control condition provided evidence for this interpretation. In Experiment 2, 5.5- to 6-month-old infants were found to look equally at the full- and the partial-contact events, even when only 15\% of the box's bottom surface remained on the platform. This result suggested that prior to 6.5 months of age infants perceive any amount of contact between the box and the platform to be sufficient to ensure the box's stability. Interpretations of this developmental sequence are considered in the Conclusion.},
	pages = {69--78},
	number = {2},
	journaltitle = {Early Development and Parenting},
	author = {Baillargeon, Renée and Needham, Amy and Devos, Julie},
	urldate = {2025-02-19},
	date = {1992},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/edp.2430010203},
	keywords = {Infancy, cognition, knowledge, physical reasoning, support},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\PNFW4XJW\\edp.html:text/html},
}

@article{hespos_reasoning_2001,
	title = {Reasoning about containment events in very young infants},
	volume = {78},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027700001189},
	doi = {10.1016/S0010-0277(00)00118-9},
	abstract = {The present research examined very young infants' expectations about containment events. In Experiment 1, 3.5-month-old infants saw a test event in which an object was lowered inside a container with either a wide opening (open-container condition) or no opening (closed-container condition) in its top surface. The infants looked reliably longer at the closed- than at the open-container test event. These and baseline data suggested that the infants recognized that the object could be lowered inside the container with the open but not the closed top. In Experiment 2, 3.5-month-old infants saw a test event in which an object was lowered either behind (behind-container condition) or inside (inside-container condition) a container; next, the container was moved forward and to the side, revealing the object behind it. The infants looked reliably longer at the inside- than at the behind-container test event. These and baseline results suggested that the infants in the inside-container condition realized that the object could not pass through the back wall of the container and hence should have moved with it to its new location. Experiments 3 and 4 extended the results of Experiments 1 and 2 to 2.5-month-old infants. Together, the present results indicate that even very young infants possess expectations about containment events. The possible origins and development of these expectations are discussed in the context of Baillargeon's model (Advances in infancy research 9 (1995) 305. Norwood, {NJ}: Ablex) of infants' acquisition of physical knowledge, and of Spelke's proposal (Cognition 50 (1994) 431) that, from birth, infants interpret physical events in accord with a solidity principle.},
	pages = {207--245},
	number = {3},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Hespos, Susan J and Baillargeon, Renée},
	urldate = {2025-02-19},
	date = {2001-03-01},
	keywords = {Reasoning, Containment events, Very young infants},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\DGC5CMEX\\S0010027700001189.html:text/html},
}

@article{stahl_observing_2015,
	title = {Observing the unexpected enhances infants’ learning and exploration},
	volume = {348},
	issn = {0036-8075},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5861377/},
	doi = {10.1126/science.aaa3799},
	abstract = {Given the overwhelming quantity of information available from the environment, how do young learners know what to learn about and what to ignore? We found that 11-month-old infants (N = 110) used violations of prior expectations as special opportunities for learning. The infants were shown events that violated expectations about object behavior or events that were nearly identical but did not violate expectations. The sight of an object that violated expectations enhanced learning and promoted information-seeking behaviors; specifically, infants learned more effectively about objects that committed violations, explored those objects more, and engaged in hypothesis-testing behaviors that reflected the particular kind of violation seen. Thus, early in life, expectancy violations offer a wedge into the problem of what to learn.},
	pages = {91--94},
	number = {6230},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Stahl, Aimee E. and Feigenson, Lisa},
	urldate = {2025-02-19},
	date = {2015-04-03},
	pmid = {25838378},
	pmcid = {PMC5861377},
	file = {PubMed Central Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\AKMAG4P5\\Stahl and Feigenson - 2015 - Observing the unexpected enhances infants’ learnin.pdf:application/pdf},
}

@article{baillargeon_innate_2008,
	title = {Innate ideas revisited: For a principle of persistence in infants' physical reasoning},
	volume = {3},
	rights = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
	issn = {1745-6916, 1745-6924},
	url = {https://journals.sagepub.com/doi/10.1111/j.1745-6916.2008.00056.x},
	doi = {10.1111/j.1745-6916.2008.00056.x},
	shorttitle = {Innate Ideas Revisited},
	abstract = {The notion of innate ideas has long been the subject of intense debate in the fields of philosophy and cognitive science. Over the past few decades, methodological advances have made it possible for developmental researchers to begin to examine what innate ideas—what innate concepts and principles—might contribute to infants’ knowledge acquisition in various core domains. This article focuses on the domain of physical reasoning and on Spelke’s (1988, 1994) proposal that principles of continuity and cohesion guide infants’ interpretation of physical events. The article reviews recent evidence that these two principles are in fact corollaries of a single and more powerful principle of persistence, which states that objects persist, as they are, in time and space.},
	pages = {2--13},
	number = {1},
	journaltitle = {Perspectives on Psychological Science},
	shortjournal = {Perspect Psychol Sci},
	author = {Baillargeon, Renée},
	urldate = {2025-02-19},
	date = {2008-01},
	langid = {english},
	file = {Baillargeon - 2008 - Innate Ideas Revisited For a Principle of Persist.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\4FZ59EFU\\Baillargeon - 2008 - Innate Ideas Revisited For a Principle of Persist.pdf:application/pdf},
}

@article{gibson_visual_1960,
	title = {The "visual cliff."},
	volume = {202},
	issn = {0036-8733},
	doi = {10.1038/scientificamerican0460-64},
	abstract = {A simple apparatus is used to investigate depth perception in different animals. All species thus far tested seem able to perceive and avoid a sharp drop as soon as they can move about. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {64--71},
	number = {4},
	journaltitle = {Scientific American},
	author = {Gibson, Eleanor J. and Walk, Richard D.},
	date = {1960},
	note = {Place: {US}
Publisher: Scientific American, Inc.},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\9MULG4M8\\1961-00558-001.html:text/html},
}

@article{landau_young_2024,
	title = {Young children’s copying of block constructions: Significant constraints in a highly complex task},
	volume = {71},
	issn = {0885-2014},
	url = {https://www.sciencedirect.com/science/article/pii/S0885201424000480},
	doi = {10.1016/j.cogdev.2024.101463},
	shorttitle = {Young children’s copying of block constructions},
	abstract = {Block construction is ubiquitous in early development, yet is surprisingly complex, involving step-by-step sequenced actions to create specific structures. Here, we use novel analytic methods to characterize these action sequences in detail, including which individual parts of the structure (‘states’) are built and how these structures are combined, creating a fully specified build path towards the final structure. We find that, like adults tested in a previous study, 4- to 8-year-olds build by creating a small subset of possible individual states and full build paths, and that they prioritize building layer-by-layer. The individual states and build paths that children produce are strikingly similar to those of adults, resulting in structures that are more stable than other possible (but not attested) states and paths. Our approach serves as a lens into the cognitive processes underlying block building and suggests that children’s building is guided by significant cognitive constraints consistent with “computational thinking”.},
	pages = {101463},
	journaltitle = {Cognitive Development},
	shortjournal = {Cognitive Development},
	author = {Landau, Barbara and Davis, E. Emory and Cortesa, Cathryn S. and Wang, Zihan and Jones, Jonathan D. and Shelton, Amy L.},
	urldate = {2025-02-19},
	date = {2024-07-01},
	keywords = {Intuitive physics, Spatial cognition, Development, Block construction, Skilled action, Spatial skills},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\WR7L8GJC\\S0885201424000480.html:text/html;Submitted Version:C\:\\Users\\inkpe\\Zotero\\storage\\AEAJK66K\\Landau et al. - 2024 - Young children’s copying of block constructions S.pdf:application/pdf},
}

@article{wong_spontaneous_2024,
	title = {Spontaneous path tracing in task-irrelevant mazes: Spatial affordances trigger dynamic visual routines},
	volume = {153},
	issn = {1939-2222},
	doi = {10.1037/xge0001618},
	shorttitle = {Spontaneous path tracing in task-irrelevant mazes},
	abstract = {Given a maze (e.g., in a book of puzzles), you might solve it by drawing out paths with your pencil. But even without a pencil, you might naturally find yourself mentally tracing along various paths. This “mental path tracing” may intuitively seem to depend on your (overt, conscious, voluntary) goal of wanting to get out of the maze, but might it also occur spontaneously—as a result of simply seeing the maze, via a kind of dynamic visual routine? Here, observers simply had to compare the visual properties of two probes presented in a maze. The maze itself was entirely task irrelevant, but we predicted that simply seeing the maze’s visual structure would “afford” incidental mental path tracing (à la Gibson). Across four experiments, observers were slower to compare probes that were further from each other along the paths, even when controlling for lower level properties (such as the probes’ brute linear separation, ignoring the maze “walls”). These results also generalized beyond mazes to other unfamiliar displays with task-irrelevant circular obstacles. This novel combination of two prominent themes from our field—affordances and visual routines—suggests that at least some visual routines may not require voluntary goals; instead, they may operate in an automatic (incidental, stimulus-driven) fashion, as a part of visual processing itself. ({PsycInfo} Database Record (c) 2024 {APA}, all rights reserved)},
	pages = {2230--2238},
	number = {9},
	journaltitle = {Journal of Experimental Psychology: General},
	author = {Wong, Kimberly W. and Scholl, Brian J.},
	date = {2024},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Observers, Visual Stimulation, Task, Spatial Ability, Mazes, Path Analysis},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\4PD9WAU7\\2025-04687-001.html:text/html;Wong and Scholl - 2024 - Spontaneous path tracing in task-irrelevant mazes.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\3XQG3PYX\\Wong and Scholl - 2024 - Spontaneous path tracing in task-irrelevant mazes.pdf:application/pdf},
}

@article{wong_seeing_nodate,
	title = {Seeing from the ground up: Spontaneous perception of 'causal history' due to intuitive physics},
	author = {Wong, Kimberly W. and Shah, Aalap D. and Scholl, Brian J.},
}

@article{hafri_phone_2024,
	title = {A phone in a basket looks like a knife in a cup: Role-filler independence in visual processing},
	volume = {8},
	issn = {2470-2986},
	url = {https://doi.org/10.1162/opmi_a_00146},
	doi = {10.1162/opmi_a_00146},
	shorttitle = {A Phone in a Basket Looks Like a Knife in a Cup},
	abstract = {When a piece of fruit is in a bowl, and the bowl is on a table, we appreciate not only the individual objects and their features, but also the relations containment and support, which abstract away from the particular objects involved. Independent representation of roles (e.g., containers vs. supporters) and “fillers” of those roles (e.g., bowls vs. cups, tables vs. chairs) is a core principle of language and higher-level reasoning. But does such role-filler independence also arise in automatic visual processing? Here, we show that it does, by exploring a surprising error that such independence can produce. In four experiments, participants saw a stream of images containing different objects arranged in force-dynamic relations—e.g., a phone contained in a basket, a marker resting on a garbage can, or a knife sitting in a cup. Participants had to respond to a single target image (e.g., a phone in a basket) within a stream of distractors presented under time constraints. Surprisingly, even though participants completed this task quickly and accurately, they false-alarmed more often to images matching the target’s relational category than to those that did not—even when those images involved completely different objects. In other words, participants searching for a phone in a basket were more likely to mistakenly respond to a knife in a cup than to a marker on a garbage can. Follow-up experiments ruled out strategic responses and also controlled for various confounding image features. We suggest that visual processing represents relations abstractly, in ways that separate roles from fillers.},
	pages = {766--794},
	journaltitle = {Open Mind},
	shortjournal = {Open Mind},
	author = {Hafri, Alon and Bonner, Michael F. and Landau, Barbara and Firestone, Chaz},
	urldate = {2025-02-22},
	date = {2024-06-12},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\4ATKG3GJ\\Hafri et al. - 2024 - A Phone in a Basket Looks Like a Knife in a Cup R.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\ED8GBE77\\123216.html:text/html},
}

@article{langley_vertical_2023,
	title = {Vertical attention bias for tops of objects and bottoms of scenes},
	volume = {49},
	issn = {1939-1277},
	doi = {10.1037/xhp0001117},
	abstract = {Past research demonstrated a top-salience bias in object identification, with random shapes appearing more similar when they share the same top versus the same bottom. This is consistent with tops of natural objects and lifeforms tending to be more informative locations of intentionality and functionality, leading observers to favor attending to tops. However, this bias may also reflect a generic downward vantage tendency that occurs with more informative interactive aspects of scenes typically lying below the horizon. Two experiments test for this overall pattern of vertical attention bias ({VAB}) for both objects and scenes. Participants observed picture triptychs and judged if the center object or scene appeared more similar to flanking comparison figures that contain the same top versus same bottom. Experiment 1 used vertically information-balanced impoverished stimuli, either polygon objects or polygon-array scenes. Experiment 2 extended the triptych stimuli to naturalistic objects or scenes. Results generally support a {VAB} for object tops and scene bottoms that varies as a function of the informative aspects of visually attended stimuli. This pattern held for information-balanced objects but not scenes, however, with more ecologically valid naturalistic stimuli, {VAB} was large and robust, consistent with a vertical information imbalance that drives a generic downward vantage. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
	pages = {1281--1295},
	number = {10},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Langley, Matthew D. and {McBeath}, Michael K.},
	date = {2023},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Visual Attention, Attentional Bias, Eye Fixation, Object Recognition},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\5GK693J2\\2023-99570-001.html:text/html},
}

@article{langley_children_2023,
	title = {Children and adults exhibit a common vertical attention bias for object tops and scene bottoms},
	volume = {59},
	issn = {1939-0599},
	doi = {10.1037/dev0001553},
	abstract = {Adults have a vertical attention bias ({VAB}) that directs their focus toward object tops and scene bottoms. This is consistent with focusing attention on the informative aspects and affordances of the environment, and generally favoring a downward gaze. The smaller size of children, combined with their relatively limited interactions with objects and scenes, could lead them to have diminished bias that only gradually develops. Alternatively, an early coupling of attention to action space could lead to {VAB} similar to adults. The current study investigates the developmental timeline of {VAB}, comparing 4–7-year-olds to adults. Participants (N = 50 children, 53 adults; 58\% White, 22\% Asian, 6\% Black, 2\% Native American, and 12\% other) observed naturalistic photographic triptychs (48 objects, 52 scenes, all online). They made similarity judgments comparing a test figure to two flanking figures containing either the same top or same bottom. We found that (a) children and adults exhibit a common {VAB} for object tops and scene bottoms and (b) the adult bias is stronger than children’s. Exploratory analyses revealed the same age trend within children, with {VAB} increasing with age, and asymptoting at the adult level at age 8. This demonstrates that despite age and body size differences that could make the environment for young children relatively disparate from adults, their perceptual system is already largely attuned to their individual interactive action space, with only minor continuing residual development. The findings support that, like adults, young children focus their attention on their action space and body level affordances, where they interact more with tops of objects and bottoms of scenes. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
	pages = {1377--1388},
	number = {8},
	journaltitle = {Developmental Psychology},
	author = {Langley, Matthew D. and Van Houghton, Kaitlin and {McBeath}, Michael K. and Lucca, Kelsey},
	date = {2023},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, Visual Attention, Attentional Bias, Focused Attention, Childhood Development, Adult Development},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\CDP96VL6\\2023-84174-001.html:text/html},
}

@article{gilden_understanding_1989,
	title = {Understanding collision dynamics},
	volume = {15},
	issn = {1939-1277},
	doi = {10.1037/0096-1523.15.2.372},
	abstract = {In two experiments we investigated people's ability to judge the relative mass of two objects involved in a collision. It was found that judgments of relative mass were made on the basis of two heuristics. Roughly stated, these heuristics were (a) an object that ricochets backward upon impact is less massive than the object that it hit, and (b) faster moving objects are less massive. A heuristic model of judgment is proposed that postulates that different sources of information in an event may have different levels of salience for observers and that heuristic access is controlled by the rank ordering of salience. It was found that observers ranked dissimilarity in mass on the basis of the relative salience of angle and velocity information and not proportionally to the distal mass ratio. This heuristic model was contrasted with the notion that people can veridically extract dynamic properties of motion events when the kinematic data are sufficient for their specification. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {372--383},
	number = {2},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Gilden, David L. and Proffitt, Dennis R.},
	date = {1989},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Visual Perception, {HasNote}, Motion Perception, Heuristic Modeling, Size Discrimination, Velocity},
	file = {Gilden and Proffitt - Understanding Collision Dynamics.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\UEL3VWHP\\Gilden and Proffitt - Understanding Collision Dynamics.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\GBNG5L7H\\1989-31786-001.html:text/html},
}

@article{rauschenberger_masking_2001,
	title = {Masking unveils pre-amodal completion representation in visual search},
	volume = {410},
	issn = {1476-4687},
	doi = {10.1038/35066577},
	abstract = {Examined how visual search does have access to pre-completion representation, but only for a limited time that depends on the size of the occluded region. Participants performed visual search for a target that was either a notched disk abutting a square, or a notched disk standing separate from the square. A new set of 12 undergraduate students naive to the purpose of the study participated in each experiment. Findings indicated not only that pre-amodal completion information is present in the visual system along the path to a final, completed representation, but that, at least briefly, its representation is sufficiently explicit to subserve overt, conscious behaviour. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {369--372},
	number = {6826},
	journaltitle = {Nature},
	author = {Rauschenberger, Robert and Yantis, Steven},
	date = {2001},
	note = {Place: United Kingdom
Publisher: Nature Publishing Group},
	keywords = {Visual Perception, Visual Search, Perceptual Closure},
	file = {Rauschenberger and Yantis - 2001 - Masking unveils pre-amodal completion representati.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\9Q9YFL3S\\Rauschenberger and Yantis - 2001 - Masking unveils pre-amodal completion representati.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\4Q4HJWFN\\2001-00566-005.html:text/html},
}

@article{bates_humans_2015,
	title = {Humans predict liquid dynamics using probabilistic simulation},
	volume = {37},
	url = {https://escholarship.org/uc/item/6xc533j2},
	abstract = {Liquids can splash, squirt, gush, slosh, soak, drip, drain, trickle, pool, and be poured‚Äìcomplex behaviors that we can easily distinguish, imagine, describe, and, crucially, predict, despite tremendous diversity among different liquids‚Äô material and dynamical characteristics. This proficiency suggests the brain has a sophisticated cognitive mechanism for reasoning about liquids, yet to date there has been little effort to study this mechanism quantitatively or describe it computationally. Here we find evidence that people‚Äôs reasoning about how liquids move is consistent with a computational cognitive model based on approximate probabilistic simulation. In a psychophysical experiment, participants predicted how different liquids would flow around solid obstacles, and their judgments agreed with those of a family of models in which volumes of liquid are represented as collections of interacting particles, within a dynamical fluid simulation. Our model explains people‚Äôs accuracy, and their predictions‚Äô sensitivity to liquids of different viscosity. We also explored several models that did not involve simulation, and found they could not account for the experimental data as well. Our results are consistent with previous reports that people‚Äôs physical understanding of solid objects is based on simulation, but extends this thesis to the more complex and unexplored domain of reasoning about liquids},
	number = {0},
	journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
	author = {Bates, Christopher J. and Yildirim, Iker and Tenenbaum, Joshua B. and Battaglia, Peter W.},
	urldate = {2025-02-24},
	date = {2015},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\VKUHPJZH\\Bates et al. - 2015 - Humans predict liquid dynamics using probabilistic.pdf:application/pdf},
}

@article{kahneman_reviewing_1992,
	title = {The reviewing of object files: Object-specific integration of information},
	volume = {24},
	issn = {0010-0285},
	url = {https://www.sciencedirect.com/science/article/pii/001002859290007O},
	doi = {10.1016/0010-0285(92)90007-O},
	shorttitle = {The reviewing of object files},
	abstract = {A series of experiments explored a form of object-specific priming. In all experiments a preview field containing two or more letters is followed by a target letter that is to be named. The displays are designed to produce a perceptual interpretation of the target as a new state of an object that previously contained one of the primes. The link is produced in different experiments by a shared location, by a shared relative position in a moving pattern, or by successive appearance in the same moving frame. An object-specific advantage is consistently observed: naming is facilitated by a preview of the target, if (and in some cases only if) the two appearances are linked to the same object. The amount and the object specificity of the preview benefit are not affected by extending the preview duration to 1 s, or by extending the temporal gap between fields to 590 ms. The results are interpreted in terms of a reviewing process, which is triggered by the appearance of the target and retrieves just one of the previewed items. In the absence of an object link, the reviewing item is selected at random. We develop the concept of an object file as a temporary episodic representation, within which successive states of an object are linked and integrated.},
	pages = {175--219},
	number = {2},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Kahneman, Daniel and Treisman, Anne and Gibbs, Brian J},
	urldate = {2025-02-24},
	date = {1992-04-01},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\VUJY2GUN\\001002859290007O.html:text/html},
}

@incollection{nakayama_visual_1995,
	location = {Cambridge, {MA}, {US}},
	title = {Visual surface representation: A critical link between lower-level and higher-level vision},
	isbn = {978-0-262-15042-2},
	series = {An invitation to cognitive science},
	shorttitle = {Visual surface representation},
	abstract = {surveys the phenomenology of surface perception / examines experimental studies showing the importance of surfaces / presents our theoretical understanding of the mechanisms of surface perception / consider certain perceptual demonstrations . . . , which show how the viewing of very simple patterns is . . . revealing of the underlying properties of surface perception / show that surface perception requires an inferential process residing largely "within" the visual system / show that the role of surface representation is crucial in a wide variety of visual functions / demonstrate that space perception and visual attention cannot be understood independent of an explicit consideration of a surface representation / suggest a possible site in the brain where surface representation might begin and conclude in a more theoretical vein, suggesting a framework for understanding the perceptual learning of surfaces from images ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
	pages = {1--70},
	booktitle = {Visual cognition: An invitation to cognitive science, Vol. 2, 2nd ed},
	publisher = {The {MIT} Press},
	author = {Nakayama, Ken and He, Zijiang J. and Shimojo, Shinsuke},
	date = {1995},
	keywords = {Visual Perception, Recognition (Learning), Texture Perception, Neuropsychology, Pattern Discrimination},
	file = {077NKHeShimojoMIT1995b.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\5BFPUZCM\\077NKHeShimojoMIT1995b.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\3YQ7ZNQJ\\1996-97193-001.html:text/html},
}

@article{goulding_time_2025,
	title = {Time from structure: Children infer the temporal order of past events from visual arrays},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-025-02659-9},
	doi = {10.3758/s13423-025-02659-9},
	shorttitle = {Time from structure},
	abstract = {The current locations of objects are informative about the temporal order of past events. For example, by simply examining the locations of objects underground, geologists and historians can determine their relative ages. In three experiments, we explored the development of this ability to infer time from structure in children 3–6-years of age (N = 317). In all experiments, children saw pictures of object arrays (e.g., a stack of blocks) and selected the item placed first or last. Children in the final experiment also made judgments about the future (e.g., “Which block will they pick up first?”). By age 5, children were mostly accurate at inferring the order of past events. Children were more accurate when inferring first than last, and when inferring the future than the past. The findings suggest that children infer history by simulating how past events unfolded, and that 3–4-year-olds may struggle to perform these simulations.},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychon Bull Rev},
	author = {Goulding, Brandon W. and Stonehouse, Emily Elizabeth and Friedman, Ori},
	urldate = {2025-03-01},
	date = {2025-02-14},
	langid = {english},
	keywords = {Cognitive development, Historical reasoning, Spatial arrays, Temporal reasoning},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\GDXABFFX\\Goulding et al. - 2025 - Time from structure Children infer the temporal o.pdf:application/pdf},
}

@article{franchak_what_2012,
	title = {What infants know and what they do: Perceiving possibilities for walking through openings},
	volume = {48},
	issn = {1939-0599},
	doi = {10.1037/a0027530},
	shorttitle = {What infants know and what they do},
	abstract = {What infants decide to do does not necessarily reflect the extent of what they know. In the current study, 17-month-olds were encouraged to walk through openings of varying width under risk of entrapment. Infants erred by squeezing into openings that were too small and became stuck, suggesting that they did not accurately perceive whether they could fit. However, a second penalty condition revealed accurate action selection when errors resulted in falling, indicating that infants are indeed perceptually sensitive to fitting through openings. Furthermore, independent measures of perception were equivalent between the two penalty conditions, suggesting that differences in action selection resulted from different penalties, not lack of perceptual sensitivity. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1254--1261},
	number = {5},
	journaltitle = {Developmental Psychology},
	author = {Franchak, John M. and Adolph, Karen E.},
	date = {2012},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Perception, Decision Making, Walking, Infant Development, Gait, Motor Development},
	file = {Accepted Version:C\:\\Users\\inkpe\\Zotero\\storage\\FGM2P8CW\\Franchak and Adolph - 2012 - What infants know and what they do Perceiving pos.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\T8688TW3\\2012-05960-001.html:text/html},
}

@article{smith_different_2018,
	title = {Different physical intuitions exist between tasks, not domains},
	volume = {1},
	issn = {2522-087X},
	url = {https://doi.org/10.1007/s42113-018-0007-3},
	doi = {10.1007/s42113-018-0007-3},
	abstract = {Does human behavior exploit deep and accurate knowledge about how the world works, or does it rely on shallow and often inaccurate heuristics? This fundamental question is rooted in a classic dichotomy in psychology: human intuitions about even simple scenarios can be poor, yet their behaviors can exceed the capabilities of even the most advanced machines. One domain where such a dichotomy has classically been demonstrated is intuitive physics. Here we demonstrate that this dichotomy is rooted in how physical knowledge is measured: extrapolation of ballistic motion is idiosyncratic and erroneous when people draw the trajectories but consistent with accurate physical inferences under uncertainty when people use the same trajectories to catch a ball or release it to hit a target. Our results suggest that the contrast between rich and calibrated versus poor and inaccurate patterns of physical reasoning exists as a result of using different systems of knowledge across tasks, rather than being driven solely by a universal system of knowledge that is inconsistent across physical principles.},
	pages = {101--118},
	number = {2},
	journaltitle = {Computational Brain \& Behavior},
	shortjournal = {Comput Brain Behav},
	author = {Smith, Kevin A. and Battaglia, Peter W. and Vul, Edward},
	urldate = {2025-03-08},
	date = {2018-06-01},
	langid = {english},
	keywords = {Intuitive physics, Heuristics, Domains of behavior, Domains of knowledge, Rationality},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\MWN2BVSN\\Smith et al. - 2018 - Different Physical Intuitions Exist Between Tasks,.pdf:application/pdf},
}

@article{schmidt_visual_2019,
	title = {Visual perception of shape-transforming processes: ‘Shape Scission’},
	volume = {189},
	issn = {0010-0277},
	url = {https://www.sciencedirect.com/science/article/pii/S0010027719300903},
	doi = {10.1016/j.cognition.2019.04.006},
	shorttitle = {Visual perception of shape-transforming processes},
	abstract = {Shape-deforming processes (e.g., squashing, bending, twisting) can radically alter objects’ shapes. After such a transformation, some features are due to the object’s original form, while others are due to the transformation, yet it is challenging to separate the two. We tested whether observers can distinguish the causal origin of different features, teasing apart the characteristics of the original shape from those imposed by transformations, a process we call ‘shape scission’. Using computer graphics, we created 8 unfamiliar objects and subjected each to 8 transformations (e.g., “twisted”, “inflated”, “melted”). One group of participants named transformations consistently. A second group arranged cards depicting the objects into classes according to either (i) the original shape or (ii) the type of transformation. They could do this almost perfectly, suggesting that they readily distinguish the causal origin of shape features. Another group used a digital painting interface to indicate which locations on the objects appeared transformed, with responses suggesting they can localise features caused by transformations. Finally, we parametrically varied the magnitude of the transformations, and asked another group to rate the degree of transformation. Ratings correlated strongly with transformation magnitude with a tendency to overestimate small magnitudes. Responses were predicted by both the magnitude and area affected by the transformation. Together, the findings suggest that observers can scission object shapes into original shape and transformation features and access the resulting representational layers at will.},
	pages = {167--180},
	journaltitle = {Cognition},
	shortjournal = {Cognition},
	author = {Schmidt, Filipp and Phillips, Flip and Fleming, Roland W.},
	urldate = {2025-03-08},
	date = {2019-08-01},
	keywords = {Vision, Perceptual organization, Objects, Categorization, Recognition, Gestalt},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\L52DQ8W3\\S0010027719300903.html:text/html},
}

@article{mitko_visual_2023,
	title = {Visual attention flows downhill},
	volume = {23},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.23.9.5987},
	doi = {10.1167/jov.23.9.5987},
	abstract = {On a daily basis, we are confronted with a plethora of information about physical properties and physical interactions that we must quickly use to make predictions and take action. Imagine seeing a sled coming down a steep hill toward a crowd of people. We might expect the sled to continue barreling downhill, but does this expectation pull spatial attention along with it? In this case, it would be beneficial to direct attention to locations down the hill to warn people of the incoming sled. Representational momentum work has shown that our memory of an object’s location can be influenced by physical properties of a scene, but is the same true for in-the-moment attention? Here, we tested whether attention is pulled to where an object will be in a physical scene, and whether this pull is automatic. In two experiments, subjects were shown a colored ball in the middle of a ramp. On every trial, the ball disappeared and reappeared elsewhere on the ramp and subjects were required to respond to whether the ball was the same or different color than when it initially appeared. Even though the ball’s location on the ramp was irrelevant to the color change, subjects were quicker to respond when the ball reappeared slightly downhill on the ramp. This suggests that attention was automatically drawn downhill; but is this effect really due to the physical properties of the scene? To examine this, in a second experiment, we added barriers to the ramp that would hinder the ball from rolling downhill. Consequentially, the addition of the barriers abolished downhill attentional priming, suggesting the effect adhered to the physical aspects of the scene. These findings contribute to a deeper understanding of how expectations about physical interactions may automatically shape spatial attention.},
	pages = {5987},
	number = {9},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Mitko, Alex and Fischer, Jason},
	urldate = {2025-03-09},
	date = {2023-08-01},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\F8KZCYIN\\article.html:text/html},
}

@article{deeb_velocity_2024,
	title = {Velocity – not perceived as such: The role of perceived mass on motion estimation},
	volume = {24},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.24.10.665},
	doi = {10.1167/jov.24.10.665},
	shorttitle = {Velocity– not Perceived as such},
	abstract = {In physics, velocity is conventionally defined as the first derivative of an object's position with respect to time. However, a longstanding assumption within vision science has equated the visual hierarchy of object motion with the principles of Newtonian mechanics– treating velocity as a unitary and fundamental variable, akin to its role in physics. This assumption has persisted despite compelling evidence suggesting that the human visual system is biased in perceiving velocity, influenced by factors such as viewing distance and angle. Contrary to the presumed universality of velocity as a visual primitive, numerous studies have revealed pronounced biases in human observers' ability to discern object motion, particularly influenced by the size of moving objects. Notably, larger objects are consistently perceived as moving more slowly. Building upon these findings, our study investigates the impact of perceived mass on the perceived speed of moving objects. Through a 2-{AFC} paradigm involving objects of varying sizes and materials, our findings unveil a discernible trend: as objects increase in perceived mass due to size or apparent density, their perceived speed decreases. In light of these observations, we challenge the prevalent assumption that velocity operates as a visual primitive. Instead, we contend that momentum, rather than velocity, may offer a more suitable conceptual framework within object motion perception, acknowledging the inherent integration of information about mass in the visual processing of motion.},
	pages = {665},
	number = {10},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Deeb, Abdul-Rahim and Fischer, Jason},
	urldate = {2025-03-09},
	date = {2024-09-15},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\G29B8IIU\\article.html:text/html},
}

@article{kaiser_intuitive_1986,
	title = {Intuitive reasoning about abstract and familiar physics problems},
	volume = {14},
	issn = {0090-502X},
	doi = {10.3758/bf03202508},
	pages = {308--312},
	number = {4},
	journaltitle = {Memory \& Cognition},
	shortjournal = {Mem Cognit},
	author = {Kaiser, M. K. and Jonides, J. and Alexander, J.},
	date = {1986-07},
	pmid = {3762384},
	keywords = {Humans, Adult, Female, Male, Concept Formation, Physics, Problem Solving, Physical Phenomena, Set, Psychology},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\UYPC62NK\\Kaiser et al. - 1986 - Intuitive reasoning about abstract and familiar ph.pdf:application/pdf},
}

@article{little_whats_2020,
	title = {What’s behind the curtain? Visual priming by draped objects},
	volume = {20},
	issn = {1534-7362},
	url = {https://doi.org/10.1167/jov.20.11.1592},
	doi = {10.1167/jov.20.11.1592},
	shorttitle = {What’s behind the curtain?},
	abstract = {Perhaps the most foundational assumption in perception research is that our experience of the world goes beyond the light reaching our eyes. This principle is familiar from visual illusions, perceptual constancies, and amodal completion — as when we perceive the continuity of an object behind an occluding surface. What is the limit to such phenomena? In particular, could we ever experience objects that are occluded completely? In fact, we frequently do: When a cloth or other fabric is draped over an object, we can often appreciate which properties the draped object might have, even when no part of the object is directly visible (Yildirim et al., 2016) — e.g., when a car is placed under a weather-protective covering, or when a child wears a bedsheet to dress up as a ghost. What is the nature of this experience? Do we only infer such hidden properties through thought and reflection? Or might we see such properties as part of automatic visual processing? Here, we investigate this latter possibility using visual priming. On each trial, one of two volumetric shapes (e.g., a cube or sphere) appeared suddenly, and subjects indicated which shape was shown. Crucially, each shape was preceded by a brief ‘cue’: A rendering of one of the shapes with a cloth draped over it. There were thus two types of trials: congruent-cued and incongruent-cued. Even though this cue was completely invalid and task-irrelevant, it facilitated subjects’ responses: They were faster to report the identity of the displayed shape when its draped cue was congruent vs. when it was incongruent. We suggest that the mind automatically represents objects even when they reflect no light whatsoever onto our eyes, such that visual processing computes the properties of completely occluded objects.},
	pages = {1592},
	number = {11},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Little, Patrick and Firestone, Chaz},
	urldate = {2025-03-10},
	date = {2020-10-20},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\SFP4EVNS\\article.html:text/html},
}

@article{jacobs_learning_2001,
	title = {Learning to visually perceive the relative mass of colliding balls in globally and locally constrained task ecologies},
	volume = {27},
	issn = {0096-1523},
	doi = {10.1037//0096-1523.27.5.1019},
	abstract = {Novice observers differ from each other in the kinematic variables they use for the perception of kinetic properties, but they converge on more useful variables after practice with feedback. The colliding-balls paradigm was used to investigate how the convergence depends on the relations between the candidate variables and the to-be-perceived property, relative mass. Experiment 1 showed that observers do not change in the variables they use if the variables with which they start allow accurate performance. Experiment 2 showed that, at least for some observers, convergence can be facilitated by reducing the correlations between commonly used nonspecifying variables and relative mass but not by keeping those variables constant. Experiments 3a and 3b further demonstrated that observers learn not to rely on a particular nonspecifying variable if the correlation between that variable and relative mass is reduced.},
	pages = {1019--1038},
	number = {5},
	journaltitle = {Journal of Experimental Psychology. Human Perception and Performance},
	shortjournal = {J Exp Psychol Hum Percept Perform},
	author = {Jacobs, D. M. and Runeson, S. and Michaels, C. F.},
	date = {2001-10},
	pmid = {11642693},
	keywords = {Learning, Visual Perception, Humans, Judgment, Motion Perception, Environment, Random Allocation, Biomechanical Phenomena, Weight Perception},
	file = {Jacobs et al. - Learning to Visually Perceive the Relative Mass of.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\FVNAR45P\\Jacobs et al. - Learning to Visually Perceive the Relative Mass of.pdf:application/pdf},
}

@article{bonner_computational_2018,
	title = {Computational mechanisms underlying cortical responses to the affordance properties of visual scenes},
	volume = {14},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006111},
	doi = {10.1371/journal.pcbi.1006111},
	abstract = {Biologically inspired deep convolutional neural networks ({CNNs}), trained for computer vision tasks, have been found to predict cortical responses with remarkable accuracy. However, the internal operations of these models remain poorly understood, and the factors that account for their success are unknown. Here we develop a set of techniques for using {CNNs} to gain insights into the computational mechanisms underlying cortical responses. We focused on responses in the occipital place area ({OPA}), a scene-selective region of dorsal occipitoparietal cortex. In a previous study, we showed that {fMRI} activation patterns in the {OPA} contain information about the navigational affordances of scenes; that is, information about where one can and cannot move within the immediate environment. We hypothesized that this affordance information could be extracted using a set of purely feedforward computations. To test this idea, we examined a deep {CNN} with a feedforward architecture that had been previously trained for scene classification. We found that responses in the {CNN} to scene images were highly predictive of {fMRI} responses in the {OPA}. Moreover the {CNN} accounted for the portion of {OPA} variance relating to the navigational affordances of scenes. The {CNN} could thus serve as an image-computable candidate model of affordance-related responses in the {OPA}. We then ran a series of in silico experiments on this model to gain insights into its internal operations. These analyses showed that the computation of affordance-related features relied heavily on visual information at high-spatial frequencies and cardinal orientations, both of which have previously been identified as low-level stimulus preferences of scene-selective visual cortex. These computations also exhibited a strong preference for information in the lower visual field, which is consistent with known retinotopic biases in the {OPA}. Visualizations of feature selectivity within the {CNN} suggested that affordance-based responses encoded features that define the layout of the spatial environment, such as boundary-defining junctions and large extended surfaces. Together, these results map the sensory functions of the {OPA} onto a fully quantitative model that provides insights into its visual computations. More broadly, they advance integrative techniques for understanding visual cortex across multiple level of analysis: from the identification of cortical sensory functions to the modeling of their underlying algorithms.},
	pages = {e1006111},
	number = {4},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Bonner, Michael F. and Epstein, Russell A.},
	urldate = {2025-03-10},
	date = {2018-04-23},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Neural networks, Sensory perception, Vision, Navigation, Algorithms, Coding mechanisms, Functional magnetic resonance imaging, Visual cortex},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\SW3T96LH\\Bonner and Epstein - 2018 - Computational mechanisms underlying cortical respo.pdf:application/pdf},
}

@incollection{gregorians_affordances_2022,
	location = {Cham},
	title = {Affordances for spatial navigation},
	isbn = {978-3-031-08629-8},
	url = {https://doi.org/10.1007/978-3-031-08629-8_10},
	abstract = {Successful navigation often requires detecting and exploiting a range of affordances in the environment. These can be visible affordances such as a path enabling efficient travel, a landmark to distinguish the direction, or a boundary to locate a goal. Other affordances require greater integration of sensory information with stored knowledge, such as determining that a novel path will be a shortcut, or being able to infer that the current region of the environment has strong global connections due to its long line of sight and central location in the broader space. This essay reviews studies exploring affordances for navigation and their neural underpinnings. We highlight recent discoveries indicating a role of the occipital place area in detecting path affordances, the retrosplenial cortex in landmark processing, and the hippocampus in processing path connections. Finally, we extend our consideration to affordances of an environment that impact affect, where layout or features could induce negative affect such as fear, and the reverse where affordances can enhance positive affect by, for example, offering a sense of safety. Such alterations in the emotional state may impact navigation and learning of an environment, and we suggest new avenues for research to explore this.},
	pages = {99--112},
	booktitle = {Affordances in Everyday Life: A Multidisciplinary Collection of Essays},
	publisher = {Springer International Publishing},
	author = {Gregorians, Lara and Spiers, Hugo J.},
	editor = {Djebbara, Zakaria},
	urldate = {2025-03-10},
	date = {2022},
	langid = {english},
	doi = {10.1007/978-3-031-08629-8_10},
	keywords = {Boundaries, Landmarks, Line of sight, Paths, Spatial navigation},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\WJDVINBI\\Gregorians and Spiers - 2022 - Affordances for Spatial Navigation.pdf:application/pdf},
}

@article{grondin_timing_2010,
	title = {Timing and time perception: a review of recent behavioral and neuroscience findings and theoretical directions},
	volume = {72},
	issn = {1943-393X},
	doi = {10.3758/APP.72.3.561},
	shorttitle = {Timing and time perception},
	abstract = {The aim of the present review article is to guide the reader through portions of the human time perception, or temporal processing, literature. After distinguishing the main contemporary issues related to time perception, the article focuses on the main findings and explanations that are available in the literature on explicit judgments about temporal intervals. The review emphasizes studies that are concerned with the processing of intervals lasting a few milliseconds to several seconds and covers studies issuing from either a behavioral or a neuroscience approach. It also discusses the question of whether there is an internal clock (pacemaker counter or oscillator device) that is dedicated to temporal processing and reports the main hypotheses regarding the involvement of biological structures in time perception.},
	pages = {561--582},
	number = {3},
	journaltitle = {Attention, Perception \& Psychophysics},
	shortjournal = {Atten Percept Psychophys},
	author = {Grondin, Simon},
	date = {2010-04},
	pmid = {20348562},
	keywords = {Humans, Time Perception, Psychological Theory, Behavioral Medicine, Neurosciences, Time Factors},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\NAYPIYE3\\Grondin - 2010 - Timing and time perception a review of recent beh.pdf:application/pdf},
}

@article{matthews_time_2014,
	title = {Time perception: the bad news and the good},
	volume = {5},
	issn = {1939-5086},
	doi = {10.1002/wcs.1298},
	shorttitle = {Time perception},
	abstract = {Time perception is fundamental and heavily researched, but the field faces a number of obstacles to theoretical progress. In this advanced review, we focus on three pieces of 'bad news' for time perception research: temporal perception is highly labile across changes in experimental context and task; there are pronounced individual differences not just in overall performance but in the use of different timing strategies and the effect of key variables; and laboratory studies typically bear little relation to timing in the 'real world'. We describe recent examples of these issues and in each case offer some 'good news' by showing how new research is addressing these challenges to provide rich insights into the neural and information-processing bases of timing and time perception. {WIREs} Cogn Sci 2014, 5:429-446. doi: 10.1002/wcs.1298 This article is categorized under: Psychology {\textgreater} Perception and Psychophysics Neuroscience {\textgreater} Cognition.},
	pages = {429--446},
	number = {4},
	journaltitle = {Wiley Interdisciplinary Reviews. Cognitive Science},
	shortjournal = {Wiley Interdiscip Rev Cogn Sci},
	author = {Matthews, William J. and Meck, Warren H.},
	date = {2014-07},
	pmid = {25210578},
	pmcid = {PMC4142010},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\9VJ8KCTP\\Matthews and Meck - 2014 - Time perception the bad news and the good.pdf:application/pdf},
}

@article{block_troubles_1978,
	title = {Troubles with functionalism},
	volume = {9},
	pages = {261--325},
	journaltitle = {Minnesota Studies in the Philosophy of Science},
	author = {Block, Ned},
	date = {1978},
	note = {Publisher: University of Minnesota Press},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\5WQTK484\\BLOTWF.html:text/html},
}

@article{pariyadath_brief_2008,
	title = {Brief subjective durations contract with repetition},
	volume = {8},
	issn = {1534-7362},
	doi = {10.1167/8.16.11},
	abstract = {Neural responses to a repeated stimulus typically diminish, an effect known as repetition suppression. We here demonstrate what appear to be parallel effects of repetition on subjective duration, even when stimuli are presented too rapidly for explicit temporal judgments. When a brief visual stimulus (e.g., a letter, word, object, or face) was serially flashed in different locations, several stimuli appeared to be present simultaneously due to persistence of vision—we term this the Proliferation Effect. Critically, fewer stimuli were perceived to be simultaneously present when the same stimulus was flashed repeatedly than when a different stimulus was used for each flash, indicating that persistence of vision (and hence subjective duration) shrinks for predictable stimuli. These short-timescale experiments demonstrate that subjective durations are computed at a preconscious and implicit level of processing, thereby changing the temporal interpretation of visual scenes. Further, these findings suggest a new, instant diagnostic test for deficits in repetition suppression, such as those found in schizophrenia. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {1--6},
	number = {16},
	journaltitle = {Journal of Vision},
	author = {Pariyadath, Vani and Eagleman, David M.},
	date = {2008},
	note = {Place: {US}
Publisher: Assn for Research in Vision \& Ophthalmology ({ARVO})},
	keywords = {Stimulus Duration, Visual Stimulation, Neurons, Responses, Time Estimation},
	file = {Accepted Version:C\:\\Users\\inkpe\\Zotero\\storage\\C7VM2L4I\\Pariyadath and Eagleman - 2008 - Brief subjective durations contract with repetitio.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\CUWFSRYX\\2009-00282-007.html:text/html},
}

@article{liverence_discrete_2012,
	title = {Discrete events as units of perceived time},
	volume = {38},
	issn = {1939-1277},
	doi = {10.1037/a0027228},
	abstract = {In visual images, we perceive both space (as a continuous visual medium) and objects (that inhabit space). Similarly, in dynamic visual experience, we perceive both continuous time and discrete events. What is the relationship between these units of experience? The most intuitive answer may be similar to the spatial case: time is perceived as an underlying medium, which is later segmented into discrete event representations. Here we explore the opposite possibility--that our subjective experience of time itself can be influenced by how durations are temporally segmented, beyond more general effects of change and complexity. We show that the way in which a continuous dynamic display is segmented into discrete units (via a path shuffling manipulation) greatly influences duration judgments, independent of psychophysical factors previously implicated in time perception, such as overall stimulus energy, attention and predictability. It seems that we may use the passage of discrete events--and the boundaries between them--in our subjective experience as part of the raw material for inferring the strength of the underlying "current" of time.},
	pages = {549--554},
	number = {3},
	journaltitle = {Journal of Experimental Psychology. Human Perception and Performance},
	shortjournal = {J Exp Psychol Hum Percept Perform},
	author = {Liverence, Brandon M. and Scholl, Brian J.},
	date = {2012-06},
	pmid = {22369229},
	keywords = {Attention, Visual Perception, Humans, Judgment, Time Perception, Motion Perception, Photic Stimulation},
}

@article{macar_controlled_1994,
	title = {Controlled attention sharing influences time estimation},
	volume = {22},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/BF03209252},
	doi = {10.3758/BF03209252},
	abstract = {A seminal attentional model of time estimation predicts that subjective duration will be positively correlated to the amount of attention given to temporal processing. This prediction holds under prospective conditions, in which one is forewarned that judgments of time will be asked, in contrast to retrospective conditions, in which such judgments are required after the relevant period without any prior warning. In three experiments, an attention-sharing method was used. Subjects were asked to control the amount of attention that they devoted to one or the other component of a dual-task paradigm. The first experiment involved word categorization and reproduction of duration. The following experiments, based on signal detection theory, required discrimination of both the duration and the intensity of a single stimulus, in the visual (Experiment 2) or the auditory (Experiment 3) modality. The results indicate that when the attention is directly controlled by the subject, the subjective duration shortens as the amount of attention devoted to the temporal task diminishes. The implications of these results for the possible existence of an internal timer are considered.},
	pages = {673--686},
	number = {6},
	journaltitle = {Memory \& Cognition},
	shortjournal = {Memory \& Cognition},
	author = {Macar, Françoise and Grondin, Simon and Casini, Laurence},
	urldate = {2025-03-10},
	date = {1994-11-01},
	langid = {english},
	keywords = {Time Perception, Attentional Model, Duration Task, Temporal Judgment, Time Judgment},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\BKLUJ93B\\Macar et al. - 1994 - Controlled attention sharing influences time estim.pdf:application/pdf},
}

@article{tse_attention_2004,
	title = {Attention and the subjective expansion of time},
	volume = {66},
	issn = {0031-5117},
	doi = {10.3758/bf03196844},
	abstract = {During brief, dangerous events, such as car accidents and robberies, many people report that events seem to pass in slow motion, as if time had slowed down. We have measured a similar, although less dramatic, effect in response to unexpected, nonthreatening events. We attribute the subjective expansion of time to the engagement of attention and its influence on the amount of perceptual information processed. We term the effect time's subjective expansion ({TSE}) and examine here the objective temporal dynamics of these distortions. When a series of stimuli are shown in succession, the low-probability oddball stimulus in the series tends to last subjectively longer than the high-probability stimulus even when they last the same objective duration. In particular, (1) there is a latency of at least 120 msec between stimulus onset and the onset of {TSE}, which may be preceded by subjective temporal contraction; (2) there is a peak in {TSE} at which subjective time is particularly distorted at a latency of 225 msec after stimulus onset; and (3) the temporal dynamics of {TSE} are approximately the same in the visual and the auditory domains. Two control experiments (in which the methods of magnitude estimation and stimulus reproduction were used) replicated the temporal dynamics of {TSE} revealed by the method of constant stimuli, although the initial peak was not apparent with these methods. In addition, a third, control experiment (in which the method of single stimuli was used) showed that {TSE} in the visual domain can occur because of semantic novelty, rather than image novelty per se. Overall, the results support the view that attentional orienting underlies distortions in perceived duration.},
	pages = {1171--1189},
	number = {7},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Percept Psychophys},
	author = {Tse, Peter Ulric and Intriligator, James and Rivest, Josée and Cavanagh, Patrick},
	date = {2004-10},
	pmid = {15751474},
	keywords = {Attention, Humans, Reaction Time, Adult, Female, Male, Time Perception, Psychomotor Performance, Psychophysics, Size Perception, Pattern Recognition, Visual, Discrimination Learning, Perceptual Distortion},
	file = {Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\6Y8MGGDK\\Tse et al. - 2004 - Attention and the subjective expansion of time.pdf:application/pdf},
}

@article{hespos_five-month-old_2016,
	title = {Five-month-old infants have general knowledge of how nonsolid substances behave and interact},
	volume = {27},
	issn = {1467-9280},
	doi = {10.1177/0956797615617897},
	abstract = {Experience puts people in touch with nonsolid substances, such as water, blood, and milk, which are crucial to survival. People must be able to understand the behavior of these substances and to differentiate their properties from those of solid objects. We investigated whether infants represent nonsolid substances as a conceptual category distinct from solid objects on the basis of differences in cohesiveness. Experiment 1 established that infants can distinguish water from a perceptually matched solid and can correctly predict whether the item will pass through or be trapped by a grid. Experiments 2 and 3 showed that infants extend this knowledge to less familiar granular substances. These experiments indicate that concepts of cohesive and noncohesive material appear early in development, apply across several types of nonsolid substances, and may serve as the basis of later knowledge of physical phases.},
	pages = {244--256},
	number = {2},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Hespos, Susan J. and Ferry, Alissa L. and Anderson, Erin M. and Hollenbeck, Emily N. and Rips, Lance J.},
	date = {2016-02},
	pmid = {26744069},
	keywords = {Humans, Female, Male, Concept Formation, Pattern Recognition, Visual, Child Development, Infant, cognitive development, Habituation, Psychophysiologic, infant development, Psychology, Child, Psychology, Developmental},
}

@article{hespos_five-month-old_2009,
	title = {Five-month-old infants have different expectations for solids and liquids},
	volume = {20},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/j.1467-9280.2009.02331.x},
	doi = {10.1111/j.1467-9280.2009.02331.x},
	abstract = {Many studies have established that 2-month-old infants have knowledge of solid objects' basic physical properties. Evidence about infants' understanding of nonsolid substances, however, is relatively sparse and equivocal. We present two experiments demonstrating that 5-month-old infants have distinct expectations for how solids and liquids behave. Experiment 1 showed that infants use the motion cues from the surface of a contained liquid or solid to predict whether it will pour or tumble from a cup if the cup is upended. Experiment 2 extended these findings to show that motion cues lead to distinct expectations about whether a new object will pass through or remain on top of a substance. Together, these experiments demonstrate that 5-month-old infants are able to use movement cues and solidity to discriminate a liquid from an object of similar appearance, providing the earliest evidence that infants can reason about nonsolid substances.},
	pages = {603--611},
	number = {5},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Hespos, Susan J. and Ferry, Alissa L. and Rips, Lance J.},
	urldate = {2025-03-10},
	date = {2009-05-01},
	note = {Publisher: {SAGE} Publications Inc},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\F6ZN5WHR\\Hespos et al. - 2009 - Five-Month-Old Infants Have Different Expectations.pdf:application/pdf},
}

@article{hespos_physics_2012,
	title = {Physics for infants: characterizing the origins of knowledge about objects, substances, and number},
	volume = {3},
	rights = {Copyright © 2011 John Wiley \& Sons, Ltd.},
	issn = {1939-5086},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.157},
	doi = {10.1002/wcs.157},
	shorttitle = {Physics for infants},
	abstract = {Adults possess a great deal of knowledge about how objects behave and interact in our every day environment, yet several puzzles remain unsolved regarding how we manage this ubiquitous skill. The notion of intuitive physics has been a central focus of research on cognitive development in infancy. This article focuses on the origins of knowledge about objects, substances, and number concepts in infancy. The article reviews common themes of solidity, continuity, cohesion, and property changes as they have been studied with regard to infants' knowledge about objects and more recently with regard to infants' knowledge about substances. In addition, we review how object and substance knowledge interfaces with number knowledge systems. The evidence supports the view that certain core principles about these domains are present as early as we can test for them and the nature of the underlying representation is best characterized as primitive initial concepts that are elaborated and refined through learning and experience. {WIREs} Cogn Sci 2012, 3:19–27. doi: 10.1002/wcs.157 This article is categorized under: Psychology {\textgreater} Development and Aging},
	pages = {19--27},
	number = {1},
	journaltitle = {{WIREs} Cognitive Science},
	author = {Hespos, Susan J. and {vanMarle}, Kristy},
	urldate = {2025-03-10},
	date = {2012},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcs.157},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\Q42VDFU2\\wcs.html:text/html},
}

@incollection{adolph_infants_2012,
	location = {Thousand Oaks, {CA}},
	title = {Infants on the edge: Beyond the visual cliff},
	isbn = {978-0-85702-758-0},
	series = {Psychology: Revisiting the classic studies},
	shorttitle = {Infants on the edge},
	abstract = {Regardless of the source of inspiration for the paradigm, in the 1950s, rearing animals under altered environmental conditions was a popular method for assessing the role of experience in development. The visual cliff, conceived by Gibson and Walk as a test of visual depth perception in dark-reared rats, seemed an appropriate way of addressing the age-old question, of whether perception of space requires visual experience. Their first publication reported findings from the dark-reared rats, and on its heels came the 1960 Scientific American article with the famous photographs of infants and kittens on a checkerboard surface peering over the edge of a precipice. Their most scholarly work, the 1961 monograph, described all of their comparative studies. ({PsycInfo} Database Record (c) 2022 {APA}, all rights reserved)},
	pages = {36--55},
	booktitle = {Developmental psychology: Revisiting the classic studies},
	publisher = {Sage Publications Ltd},
	author = {Adolph, Karen E. and Kretch, Kari S.},
	date = {2012},
	keywords = {Visual Perception, Perceptual Development, Depth Perception, Animals, Infant Development, Rats},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\5IUIH66E\\2013-03062-003.html:text/html},
}

@article{kingsnorth_walking_2000,
	title = {Walking skill versus walking experience as a predictor of barrier crossing in toddlers},
	volume = {23},
	issn = {0163-6383},
	url = {https://www.sciencedirect.com/science/article/pii/S0163638301000480},
	doi = {10.1016/S0163-6383(01)00048-0},
	abstract = {The aim of this study was to examine the roles of body size parameters, walking skill, and locomotor experience in determining the abilities of 14-, 18-, 24-, and 30-month-old toddlers to cross a barrier varying in height. Thresholds for barrier crossing were measured using a modified psychophysical staircase procedure, walking skill was assessed using a footprint analysis of gait, and locomotor experience via parental report. Overall, older children surpassed younger children in measures of body size, walking skill, locomotor experience, and crossing thresholds. Analyses relating the various body size, skill, and experiential parameters to crossing thresholds revealed that, replicating earlier findings, barrier crossing was most strongly related to walking experience. These findings are discussed in terms of the limitations of different forms of skill assessment as predictors of visually guided locomotor ability.},
	pages = {331--350},
	number = {3},
	journaltitle = {Infant Behavior and Development},
	shortjournal = {Infant Behavior and Development},
	author = {Kingsnorth, Shauna and Schmuckler, Mark A},
	urldate = {2025-03-10},
	date = {2000-03-04},
	keywords = {Barrier crossing, Independent locomotion, Perception-action coupling},
	file = {ScienceDirect Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\DC32ZWEK\\S0163638301000480.html:text/html;Submitted Version:C\:\\Users\\inkpe\\Zotero\\storage\\RTM8AAHH\\Kingsnorth and Schmuckler - 2000 - Walking skill versus walking experience as a predi.pdf:application/pdf},
}

@article{adolph_crawling_1993,
	title = {Crawling versus walking infants' perception of affordances for locomotion over sloping surfaces},
	volume = {64},
	issn = {1467-8624},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8624.1993.tb04193.x},
	doi = {10.1111/j.1467-8624.1993.tb04193.x},
	abstract = {14-month-old toddlers vs. 8.5-month-old crawling infants were encouraged to ascend and descend a sloping walkway (10°, 20°, 30°, and 40°). Infants in both locomotor groups overestimated their ability to ascend slopes. However, on descending trials where falling was more aversive, most toddlers switched from walking to sliding positions for safe descent, but crawlers plunged down headfirst and many fell at each increment. Toddlers touched and hesitated most before descending 10° and 20° slopes, and they explored alternative means for descent by testing out different sliding positions before leaving the starting platform. In contrast, crawlers touched and hesitated most before descending 30° and 40° slopes, and they never explored alternative sliding positions. In addition, we analyzed measures of locomotor skill and experience in relation to children's ability to perceive affordances. Findings indicate that children must learn to perceive affordances for locomotion over slopes and that learning may begin by fine-tuning of exploratory activity.},
	pages = {1158--1174},
	number = {4},
	journaltitle = {Child Development},
	author = {Adolph, Karen E. and Eppler, Marion A. and Gibson, Eleanor J.},
	urldate = {2025-03-10},
	date = {1993},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8624.1993.tb04193.x},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\7S4B4HDU\\j.1467-8624.1993.tb04193.html:text/html},
}

@article{ongchoco_whats_2024,
	title = {What's next?: Time is subjectively dilated not only for 'oddball' events, but also for events immediately after oddballs},
	volume = {86},
	issn = {1943-393X},
	doi = {10.3758/s13414-023-02800-7},
	shorttitle = {What's next?},
	abstract = {Our experience of time is strikingly plastic: Depending on contextual factors, the same objective duration can seem to fly by or drag on. Perhaps the most direct demonstration of such subjective time dilation is the oddball effect: when seeing identical objects appear one after another, followed by an "oddball" (e.g., a disc that suddenly grows in size, in a sequence of otherwise static discs), observers experience this oddball as having lasted longer than its nonoddball counterparts. Despite extensive work on this phenomenon, a surprisingly foundational question remains unasked: What actually gets dilated? Beyond the oddball, are the objects just before (or just after) the oddball also dilated? As in previous studies, observers viewed sequences of colored discs, one of which could be the oddball-and subsequently reproduced the oddball's duration. Unlike previous studies, however, there were also critical trials in which observers instead reproduced the duration of the disc immediately before or after the oddball. A clear pattern emerged: oddball-induced time dilation extended to the post-oddball disc, but not the pre-oddball disc. Whence this temporal asymmetry? We suggest that an oddball's sudden appearance may induce uncertainty about what will happen next, heightening attention until after the uncertainty is resolved.},
	pages = {16--21},
	number = {1},
	journaltitle = {Attention, Perception \& Psychophysics},
	shortjournal = {Atten Percept Psychophys},
	author = {Ongchoco, Joan Danielle K. and Wong, Kimberly W. and Scholl, Brian J.},
	date = {2024-01},
	pmid = {37872431},
	keywords = {Attention, Humans, Time perception, Oddball effect, Time Perception, Uncertainty, Time dilation},
}

@incollection{ferguson_mind_2013,
	location = {New York, {NY}, {US}},
	title = {The mind in motivation: A social cognitive perspective on the role of consciousness in goal pursuit},
	isbn = {978-0-19-973001-8},
	series = {Oxford library of psychology},
	shorttitle = {The mind in motivation},
	abstract = {This chapter summarizes and critically evaluates recent social cognitive work on the construct of human goals. The authors begin by defining goals from a social cognitive perspective, and then introduce what they believe is one of the most important outstanding questions in contemporary research on goal pursuit: What is the role of consciousness? The authors identify the conceptual landscape of this question and summarize what current evidence indicates as well as outstanding theoretical issues and unexplored questions. A number of interesting avenues for future research are identified. ({PsycInfo} Database Record (c) 2020 {APA}, all rights reserved)},
	pages = {476--496},
	booktitle = {The Oxford handbook of social cognition},
	publisher = {Oxford University Press},
	author = {Ferguson, Melissa and Cone, Jeremy},
	date = {2013},
	keywords = {Social Cognition, Goals, Motivation, Consciousness States},
	file = {Ferguson and Cone - 2013 - The Mind in Motivation A Social Cognitive Perspec.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\XA3L6QK4\\Ferguson and Cone - 2013 - The Mind in Motivation A Social Cognitive Perspec.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\5XYP68BZ\\2013-34444-023.html:text/html},
}

@article{poort_role_2012,
	title = {The role of attention in figure-ground segregation in areas V1 and V4 of the visual cortex},
	volume = {75},
	issn = {1097-4199},
	doi = {10.1016/j.neuron.2012.04.032},
	abstract = {Our visual system segments images into objects and background. Figure-ground segregation relies on the detection of feature discontinuities that signal boundaries between the figures and the background and on a complementary region-filling process that groups together image regions with similar features. The neuronal mechanisms for these processes are not well understood and it is unknown how they depend on visual attention. We measured neuronal activity in V1 and V4 in a task where monkeys either made an eye movement to texture-defined figures or ignored them. V1 activity predicted the timing and the direction of the saccade if the figures were task relevant. We found that boundary detection is an early process that depends little on attention, whereas region filling occurs later and is facilitated by visual attention, which acts in an object-based manner. Our findings are explained by a model with local, bottom-up computations for boundary detection and feedback processing for region filling.},
	pages = {143--156},
	number = {1},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Poort, Jasper and Raudies, Florian and Wannig, Aurel and Lamme, Victor A. F. and Neumann, Heiko and Roelfsema, Pieter R.},
	date = {2012-07-12},
	pmid = {22794268},
	keywords = {Attention, Psychomotor Performance, Photic Stimulation, Visual Cortex, Pattern Recognition, Visual, Eye Movements, Visual Pathways, Animals, Haplorhini},
}

@article{watt_function_2000,
	title = {The function of dynamic grouping in vision},
	volume = {4},
	issn = {1364-6613, 1879-307X},
	url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(00)01553-9},
	doi = {10.1016/S1364-6613(00)01553-9},
	pages = {447--454},
	number = {12},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Watt, Roger J. and Phillips, William A.},
	urldate = {2025-03-12},
	date = {2000-12-01},
	pmid = {11115758},
	note = {Publisher: Elsevier},
	keywords = {Visual attention, Gestalt, Contours, Dynamic grouping, Neuronal synchronization, Surfaces, Visual description},
}

@book{block_border_2023,
	location = {Oxford, New York},
	title = {The border between seeing and thinking},
	isbn = {978-0-19-762222-3},
	series = {Philosophy of Mind},
	abstract = {Philosopher Ned Block argues in this book that there is a "joint in nature" between perception and cognition and that by exploring the nature of that joint, one can solve mysteries of the mind. The first half of the book introduces a methodology for discovering what the fundamental differences are between cognition and perception and then applies that methodology to isolate how perception and cognition differ in format and content. The second half draws consequences for theories of consciousness, using results of the first half to argue against cognitive theories of consciousness that focus on prefrontal cortex. Along the way, Block tackles questions such as: Is perception conceptual and propositional? Is perception iconic or more akin to language in being discursive? What is the difference between the format and content of perception, and do perception and cognition have different formats? Is perception probabilistic, and if so, why are we not normally aware of this probabilistic nature of perception? Are the basic features of mind known as "core cognition" a third category in between perception and cognition? This book explores these questions not by appeals to "intuitions," as is common in philosophy, but to empirical evidence, including experiments in neuroscience and psychology.  This is an open access publication, available online and distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives 4.0 International licence ({CC} {BY}-{NC}-{ND} 4.0), a copy of which is available at http://creativecommons.org/licenses/by-nc-nd/4.0/. Enquiries concerning use outside the scope of the licence terms should be sent to the Rights Department, Oxford University Press. 
            ,  
             Philosopher Ned Block argues in this book that there is a "joint in nature" between perception and cognition and that by exploring the nature of that joint, one can solve mysteries of the mind. The first half of the book introduces a methodology for discovering what the fundamental differences are between cognition and perception and then applies that methodology to isolate how perception and cognition differ in format and content. The second half draws consequences for theories of consciousness, using results of the first half to argue against cognitive theories of consciousness that focus on prefrontal cortex. Along the way, Block tackles questions such as: Is perception conceptual and propositional? Is perception iconic or more akin to language in being discursive? What is the difference between the format and content of perception, and do perception and cognition have different formats? Is perception probabilistic, and if so, why are we not normally aware of this probabilistic nature of perception? Are the basic features of mind known as "core cognition" a third category in between perception and cognition? This book explores these questions not by appeals to "intuitions," as is common in philosophy, but to empirical evidence, including experiments in neuroscience and psychology.  This is an open access publication, available online and distributed under the terms of the Creative Commons Attribution-Non Commercial-No Derivatives 4.0 International licence ({CC} {BY}-{NC}-{ND} 4.0), a copy of which is available at http://creativecommons.org/licenses/by-nc-nd/4.0/. Enquiries concerning use outside the scope of the licence terms should be sent to the Rights Department, Oxford University Press.},
	pagetotal = {560},
	publisher = {Oxford University Press},
	author = {Block, Ned},
	date = {2023},
	file = {Block - 2023 - The Border Between Seeing and Thinking.pdf:C\:\\Users\\inkpe\\Zotero\\storage\\LPDEKX5A\\Block - 2023 - The Border Between Seeing and Thinking.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\U54ZE223\\the-border-between-seeing-and-thinking-9780197622223.html:text/html},
}

@incollection{stein_breaking_2019,
	location = {New York, {NY}, {US}},
	title = {The breaking continuous flash suppression paradigm: Review, evaluation, and outlook},
	isbn = {978-1-138-60226-7},
	series = {Current issues in consciousness research},
	shorttitle = {The breaking continuous flash suppression paradigm},
	abstract = {Understanding the function and neural basis of conscious awareness is one of the major challenges of cognitive psychology and neuroscience. One promising approach is to map out those perceptual and cognitive functions that can take place outside of conscious awareness, i.e. unconsciously. In the domain of vision, the development of a novel psychophysical technique, named continuous flash suppression ({CFS}) has sparked a tidal wave of interest in unconscious processing. While many studies have combined {CFS} with traditional dissociation paradigms for studying unconscious processing, the technique also inspired the development of a novel paradigm, the so-called "breaking {CFS}" paradigm. This chapter compares the rationale of the b-{CFS} paradigm to classic dissociation paradigms. It reviews how the paradigm has been applied to study unconscious processing, including an overview of the most common b-{CFS} tasks and measures. The chapter includes a critical evaluation of what can be concluded from findings obtained with b-{CFS}, and how control conditions and additional paradigms might or might not be helpful in interpreting b-{CFS} results. It proposes possible future avenues for embedding the b-{CFS} paradigm in the classical dissociation framework. ({PsycInfo} Database Record (c) 2023 {APA}, all rights reserved)},
	pages = {1--38},
	booktitle = {Transitions between consciousness and unconsciousness, 1st ed},
	publisher = {Routledge/Taylor \& Francis Group},
	author = {Stein, Timo},
	date = {2019},
	doi = {10.4324/9780429469688-1},
	keywords = {Cognitive Processes, Cognitive Psychology, Visual Stimulation, Neurosciences, Consciousness States, Evaluation, Unconsciousness},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\9X5QLXWU\\Stein - 2019 - The Breaking Continuous Flash Suppression Paradigm.pdf:application/pdf;Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\349PT4YN\\2019-48774-001.html:text/html},
}

@article{intraub_wide-angle_1989,
	title = {Wide-angle memories of close-up scenes},
	volume = {15},
	issn = {1939-1285},
	doi = {10.1037/0278-7393.15.2.179},
	abstract = {We report a picture-memory phenomenon in which subjects' recall and recognition of photographed scenes reveal a pronounced extension of the pictures' boundaries. After viewing 20 pictures for 15 s each, 37 undergraduates exhibited this striking distortion; 95\% of their drawings included information that had not been physically present but that would have been likely to have existed just outside the camera's field of view (Experiment 1). To determine if boundary extension is limited to recall and drawing ability, Experiment 2 tested recognition memory for boundaries. Eighty-five undergraduates rated targets and distractors on a boundary-placement scale. Subjects rated target pictures as being closer up than before and frequently mistook extended-boundary distractors as targets. Results are discussed in terms of picture comprehension and memory. In addition to its theoretical value, discovery of the phenomenon demonstrates the importance of more widespread use of open-ended tests in picture-memory methodology. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {179--187},
	number = {2},
	journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
	author = {Intraub, Helene and Richardson, Michael},
	date = {1989},
	note = {Place: {US}
Publisher: American Psychological Association},
	keywords = {Imagery, Memory, Pictorial Stimuli, Recall (Learning), Recognition (Learning)},
	file = {Snapshot:C\:\\Users\\inkpe\\Zotero\\storage\\YLXGSHJJ\\1989-24876-001.html:text/html},
}

@article{hubbard_boundary_2010,
	title = {Boundary extension: Findings and theories},
	volume = {63},
	issn = {1747-0218},
	url = {https://doi.org/10.1080/17470210903511236},
	doi = {10.1080/17470210903511236},
	shorttitle = {Boundary extension},
	abstract = {A view of a scene is often remembered as containing information that might have been present just beyond the actual boundaries of that view, and this is referred to as boundary extension. Characteristics of the view (e.g., scene or nonscene; close-up or wide-angle; whether objects are cropped, static, or in motion, emotionally neutral or emotionally charged), display (e.g., aperture shape and size; target duration; retention interval; whether probes of memory involve magnification/minification or change in physical distance), and observer (e.g., allocation of attention; age; planned fixation, gaze direction, and eye movements; monocular or binocular viewing; prior exposure; neurological correlates) that influence boundary extension are reviewed. Proposed mechanisms of boundary extension (perceptual, memory, or motion schema; extension–normalization; attentional selection; errors in source monitoring) are discussed, and possible relationships of boundary extension to other cognitive processes (e.g., representational momentum; remembered distance and remembered size; amodal completion; transsaccadic memory) are briefly addressed.},
	pages = {1467--1494},
	number = {8},
	journaltitle = {Quarterly Journal of Experimental Psychology},
	author = {Hubbard, Timothy L. and Hutchison, Joanna L. and Courtney, Jon R.},
	urldate = {2025-03-31},
	date = {2010-08-01},
	note = {Publisher: {SAGE} Publications},
	file = {SAGE PDF Full Text:C\:\\Users\\inkpe\\Zotero\\storage\\HA3AU73B\\Hubbard et al. - 2010 - Boundary extension Findings and theories.pdf:application/pdf},
}

@article{fischer_serial_2014,
	title = {Serial dependence in visual perception},
	volume = {17},
	rights = {2014 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3689},
	doi = {10.1038/nn.3689},
	abstract = {Visual input is often noisy and discontinuous, even though the physical environment is generally stable. The authors show that the visual system trades off change sensitivity to capitalize on physical continuity via serial dependence: present perception is biased toward past visual input. This bias is modulated by attention and governed by a spatiotemporally-tuned operator, a continuity field.},
	pages = {738--743},
	number = {5},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Fischer, Jason and Whitney, David},
	urldate = {2025-03-31},
	date = {2014-05},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Object vision, Pattern vision},
	file = {Accepted Version:C\:\\Users\\inkpe\\Zotero\\storage\\3PRHHSPZ\\Fischer and Whitney - 2014 - Serial dependence in visual perception.pdf:application/pdf},
}

@article{hubbard_representational_2005,
	title = {Representational momentum and related displacements in spatial memory: A review of the findings},
	volume = {12},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/BF03196775},
	doi = {10.3758/BF03196775},
	shorttitle = {Representational momentum and related displacements in spatial memory},
	abstract = {Memory for the final location of a moving target is often displaced in the direction of target motion, and this has been referred to asrepresentational momentum. Characteristics of the target (e.g., velocity, size, direction, and identity), display (e.g., target format, retention interval, and response method), context (landmarks, expectations, and attribution of motion source), and observer (e.g., allocation of attention, eye movements, and psychopathology) that influence the direction and magnitude of displacement are reviewed. Specific conclusions regarding numerous variables that influence displacement (e.g., presence of landmarks or surrounding context), as well as broad-based conclusions regarding displacement in general (e.g., displacement does not reflect objective physical principles, may reflect aspects of naive physics, does not solely reflect eye movements, may involve some modular processing, and reflects high-level processes) are drawn. A possible computational theory of displacement is suggested in which displacement (1) helps bridge the gap between perception and action and (2) plays a critical part in localizing stimuli in the environment.},
	pages = {822--851},
	number = {5},
	journaltitle = {Psychonomic Bulletin \& Review},
	shortjournal = {Psychonomic Bulletin \& Review},
	author = {Hubbard, Timothy L.},
	urldate = {2025-03-31},
	date = {2005-10-01},
	langid = {english},
	keywords = {Forward Displacement, Probe Judgment, Representational Momentum, Retention Interval, Target Motion},
	file = {Full Text PDF:C\:\\Users\\inkpe\\Zotero\\storage\\6KN2NHUB\\Hubbard - 2005 - Representational momentum and related displacement.pdf:application/pdf},
}
